{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting-up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:08:48.351521Z",
     "iopub.status.busy": "2023-12-02T10:08:48.350933Z",
     "iopub.status.idle": "2023-12-02T10:08:54.455989Z",
     "shell.execute_reply": "2023-12-02T10:08:54.454966Z",
     "shell.execute_reply.started": "2023-12-02T10:08:48.351463Z"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/MaurizioFD/RecSys_Course_AT_PoliMi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:08:54.459432Z",
     "iopub.status.busy": "2023-12-02T10:08:54.458955Z",
     "iopub.status.idle": "2023-12-02T10:08:55.587507Z",
     "shell.execute_reply": "2023-12-02T10:08:55.585699Z",
     "shell.execute_reply.started": "2023-12-02T10:08:54.459356Z"
    }
   },
   "outputs": [],
   "source": [
    "!mv RecSys_Course_AT_PoliMi/* /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:08:55.590382Z",
     "iopub.status.busy": "2023-12-02T10:08:55.589820Z",
     "iopub.status.idle": "2023-12-02T10:16:42.657030Z",
     "shell.execute_reply": "2023-12-02T10:16:42.654627Z",
     "shell.execute_reply.started": "2023-12-02T10:08:55.590310Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:16:42.664165Z",
     "iopub.status.busy": "2023-12-02T10:16:42.663661Z",
     "iopub.status.idle": "2023-12-02T10:20:07.876278Z",
     "shell.execute_reply": "2023-12-02T10:20:07.874807Z",
     "shell.execute_reply.started": "2023-12-02T10:16:42.664119Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python run_compile_all_cython.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:07.879147Z",
     "iopub.status.busy": "2023-12-02T10:20:07.878568Z",
     "iopub.status.idle": "2023-12-02T10:20:28.896262Z",
     "shell.execute_reply": "2023-12-02T10:20:28.894929Z",
     "shell.execute_reply.started": "2023-12-02T10:20:07.879093Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install lightfm tqdm optuna ipykernel matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:28.899782Z",
     "iopub.status.busy": "2023-12-02T10:20:28.899336Z",
     "iopub.status.idle": "2023-12-02T10:20:29.877600Z",
     "shell.execute_reply": "2023-12-02T10:20:29.876395Z",
     "shell.execute_reply.started": "2023-12-02T10:20:28.899741Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pyplot\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import loguniform\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score, precision_at_k\n",
    "import time\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:29.881635Z",
     "iopub.status.busy": "2023-12-02T10:20:29.881196Z",
     "iopub.status.idle": "2023-12-02T10:20:30.058909Z",
     "shell.execute_reply": "2023-12-02T10:20:30.057306Z",
     "shell.execute_reply.started": "2023-12-02T10:20:29.881597Z"
    }
   },
   "outputs": [],
   "source": [
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "from Recommenders.Similarity.Compute_Similarity_Python import Compute_Similarity_Python\n",
    "from Recommenders.KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "from Recommenders.NonPersonalizedRecommender import TopPop\n",
    "from Recommenders.KNN.UserKNNCFRecommender import UserKNNCFRecommender\n",
    "from Recommenders.GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "from Recommenders.KNN.UserKNNCFRecommender import UserKNNCFRecommender\n",
    "from Recommenders.KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "from Recommenders.KNN.ItemKNNCustomSimilarityRecommender import ItemKNNCustomSimilarityRecommender\n",
    "#----remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:30.060934Z",
     "iopub.status.busy": "2023-12-02T10:20:30.060538Z",
     "iopub.status.idle": "2023-12-02T10:20:30.069011Z",
     "shell.execute_reply": "2023-12-02T10:20:30.067753Z",
     "shell.execute_reply.started": "2023-12-02T10:20:30.060898Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 69\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:30.071374Z",
     "iopub.status.busy": "2023-12-02T10:20:30.070899Z",
     "iopub.status.idle": "2023-12-02T10:20:33.417407Z",
     "shell.execute_reply": "2023-12-02T10:20:33.416189Z",
     "shell.execute_reply.started": "2023-12-02T10:20:30.071322Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import training data\n",
    "URM_path = \"../input/data-books/data_train.csv\"\n",
    "URM_all_dataframe = pd.read_csv(filepath_or_buffer=URM_path,\n",
    "                                header=0,\n",
    "                                dtype={0:int, 1:int, 2:int},\n",
    "                                engine='python')\n",
    "\n",
    "URM_all_dataframe.columns = [\"user_id\", \"item_id\", \"interaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:33.424285Z",
     "iopub.status.busy": "2023-12-02T10:20:33.423891Z",
     "iopub.status.idle": "2023-12-02T10:20:33.497090Z",
     "shell.execute_reply": "2023-12-02T10:20:33.495845Z",
     "shell.execute_reply.started": "2023-12-02T10:20:33.424252Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import target users\n",
    "target_path = \"../input/data-books/data_target_users_test.csv\"\n",
    "target_dataframe= pd.read_csv(filepath_or_buffer=target_path,\n",
    "                                header=0,\n",
    "                                dtype={0:int},\n",
    "                                engine='python')\n",
    "target_dataframe.columns = [\"user_id\"]\n",
    "target_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:33.498992Z",
     "iopub.status.busy": "2023-12-02T10:20:33.498623Z",
     "iopub.status.idle": "2023-12-02T10:20:33.510883Z",
     "shell.execute_reply": "2023-12-02T10:20:33.509626Z",
     "shell.execute_reply.started": "2023-12-02T10:20:33.498959Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(ratings: pd.DataFrame):\n",
    "    unique_users = ratings.user_id.unique()\n",
    "    unique_items = ratings.item_id.unique()\n",
    "\n",
    "    num_users, min_user_id, max_user_id = unique_users.size, unique_users.min(), unique_users.max()\n",
    "    num_items, min_item_id, max_item_id = unique_items.size, unique_items.min(), unique_items.max()\n",
    "\n",
    "    print(num_users, min_user_id, max_user_id)\n",
    "    print(num_items, min_item_id, max_item_id)\n",
    "\n",
    "    mapping_user_id = pd.DataFrame({\"mapped_user_id\": np.arange(num_users), \"user_id\": unique_users})\n",
    "    mapping_item_id = pd.DataFrame({\"mapped_item_id\": np.arange(num_items), \"item_id\": unique_items})\n",
    "\n",
    "    ratings = pd.merge(left=ratings,\n",
    "                       right=mapping_user_id,\n",
    "                       how=\"inner\",\n",
    "                       on=\"user_id\")\n",
    "\n",
    "    ratings = pd.merge(left=ratings,\n",
    "                       right=mapping_item_id,\n",
    "                       how=\"inner\",\n",
    "                       on=\"item_id\")\n",
    "\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:33.512643Z",
     "iopub.status.busy": "2023-12-02T10:20:33.512235Z",
     "iopub.status.idle": "2023-12-02T10:20:33.686692Z",
     "shell.execute_reply": "2023-12-02T10:20:33.684471Z",
     "shell.execute_reply.started": "2023-12-02T10:20:33.512606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Call preprocess data function\n",
    "ratings = preprocess_data(URM_all_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From DF to Sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:33.691315Z",
     "iopub.status.busy": "2023-12-02T10:20:33.690911Z",
     "iopub.status.idle": "2023-12-02T10:20:33.704258Z",
     "shell.execute_reply": "2023-12-02T10:20:33.702444Z",
     "shell.execute_reply.started": "2023-12-02T10:20:33.691277Z"
    }
   },
   "outputs": [],
   "source": [
    "URM = sps.coo_matrix((ratings.interaction.values, (ratings.mapped_user_id.values, ratings.mapped_item_id.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:33.706509Z",
     "iopub.status.busy": "2023-12-02T10:20:33.706030Z",
     "iopub.status.idle": "2023-12-02T10:20:36.300603Z",
     "shell.execute_reply": "2023-12-02T10:20:36.299419Z",
     "shell.execute_reply.started": "2023-12-02T10:20:33.706470Z"
    }
   },
   "outputs": [],
   "source": [
    "urm_train, urm_test = split_train_in_two_percentage_global_sample(URM, train_percentage = 0.80)\n",
    "urm_train, urm_validation = split_train_in_two_percentage_global_sample(urm_train, train_percentage = 0.80)\n",
    "\n",
    "evaluator_validation = EvaluatorHoldout(urm_validation, cutoff_list=[10])\n",
    "evaluator_test = EvaluatorHoldout(urm_test, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:36.302609Z",
     "iopub.status.busy": "2023-12-02T10:20:36.302234Z",
     "iopub.status.idle": "2023-12-02T10:20:36.313933Z",
     "shell.execute_reply": "2023-12-02T10:20:36.312852Z",
     "shell.execute_reply.started": "2023-12-02T10:20:36.302576Z"
    }
   },
   "outputs": [],
   "source": [
    "class ScoresHybridRecommender(BaseRecommender):\n",
    "    \"\"\" ScoresHybridRecommender\n",
    "    Hybrid of two prediction scores R = R1*alpha + R2*(1-alpha)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"ScoresHybridRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, recommender_1, recommender_2):\n",
    "        super(ScoresHybridRecommender, self).__init__(URM_train)\n",
    "\n",
    "        self.URM_train = sps.csr_matrix(URM_train)\n",
    "        self.recommender_1 = recommender_1\n",
    "        self.recommender_2 = recommender_2\n",
    "\n",
    "\n",
    "    def fit(self, alpha=0.5):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute):\n",
    "\n",
    "        # In a simple extension this could be a loop over a list of pretrained recommender objects\n",
    "        item_weights_1 = self.recommender_1._compute_item_score(user_id_array)\n",
    "        item_weights_2 = self.recommender_2._compute_item_score(user_id_array)\n",
    "\n",
    "        item_weights = item_weights_1*self.alpha + item_weights_2*(1-self.alpha)\n",
    "\n",
    "        return item_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:36.316130Z",
     "iopub.status.busy": "2023-12-02T10:20:36.315694Z",
     "iopub.status.idle": "2023-12-02T10:20:36.331211Z",
     "shell.execute_reply": "2023-12-02T10:20:36.329824Z",
     "shell.execute_reply.started": "2023-12-02T10:20:36.316090Z"
    }
   },
   "outputs": [],
   "source": [
    "class LightFMCFRecommender(BaseRecommender):\n",
    "    \"\"\"LightFMCFRecommender\"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"LightFMCFRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train):\n",
    "        super(LightFMCFRecommender, self).__init__(URM_train)\n",
    "    \n",
    "    \n",
    "    def fit(self, epochs = 300, user_alpha=1e-6, item_alpha = 1e-6, n_factors = 10, n_threads = 4, max_sampled=3, loss='warp', learning_schedule='adagrad'):\n",
    "        \n",
    "        # Let's fit a WARP model\n",
    "        self.lightFM_model = LightFM(loss=loss,\n",
    "                                     user_alpha=user_alpha,\n",
    "                                     item_alpha=item_alpha,\n",
    "                                     no_components=n_factors,\n",
    "                                     max_sampled=max_sampled,\n",
    "                                     learning_schedule=learning_schedule)\n",
    "\n",
    "        self.lightFM_model = self.lightFM_model.fit(self.URM_train, \n",
    "                                       epochs=epochs,\n",
    "                                       num_threads=n_threads,\n",
    "                                       verbose=True)\n",
    "\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute = None):\n",
    "        \n",
    "        # Create a single (n_items, ) array with the item score, then copy it for every user\n",
    "        items_to_compute = np.arange(self.n_items)\n",
    "        \n",
    "        item_scores = - np.ones((len(user_id_array), self.n_items)) * np.inf\n",
    "\n",
    "        for user_index, user_id in enumerate(user_id_array):\n",
    "            item_scores[user_index] = self.lightFM_model.predict(int(user_id), \n",
    "                                                                 items_to_compute)\n",
    "\n",
    "        return item_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:36.333470Z",
     "iopub.status.busy": "2023-12-02T10:20:36.333045Z",
     "iopub.status.idle": "2023-12-02T10:20:36.348621Z",
     "shell.execute_reply": "2023-12-02T10:20:36.347285Z",
     "shell.execute_reply.started": "2023-12-02T10:20:36.333409Z"
    }
   },
   "outputs": [],
   "source": [
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "\n",
    "class GeneralizedLinearHybridRecommender(BaseRecommender):\n",
    "    \"\"\"\n",
    "    This recommender merges N recommendes by weighting their ratings\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"GeneralizedLinearHybridRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, recommenders: list, verbose=True):\n",
    "        self.RECOMMENDER_NAME = ''\n",
    "        for recommender in recommenders:\n",
    "            self.RECOMMENDER_NAME = self.RECOMMENDER_NAME + recommender.RECOMMENDER_NAME[:-11]\n",
    "        self.RECOMMENDER_NAME = self.RECOMMENDER_NAME + 'HybridRecommender'\n",
    "\n",
    "        super(GeneralizedLinearHybridRecommender, self).__init__(URM_train, verbose=verbose)\n",
    "\n",
    "        self.recommenders = recommenders\n",
    "\n",
    "    def fit(self, alphas=None):\n",
    "        self.alphas = alphas\n",
    "\n",
    "    def save_model(self, folder_path, file_name=None):\n",
    "        pass\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute=None):\n",
    "        result = self.alphas[0]*self.recommenders[0]._compute_item_score(user_id_array,items_to_compute)\n",
    "        for index in range(1,len(self.alphas)):\n",
    "            result = result + self.alphas[index]*self.recommenders[index]._compute_item_score(user_id_array,items_to_compute)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:36.371561Z",
     "iopub.status.busy": "2023-12-02T10:20:36.371059Z",
     "iopub.status.idle": "2023-12-02T10:20:36.380029Z",
     "shell.execute_reply": "2023-12-02T10:20:36.378996Z",
     "shell.execute_reply.started": "2023-12-02T10:20:36.371521Z"
    }
   },
   "outputs": [],
   "source": [
    "ItemKNN_params = {\n",
    "    'topK': 6,\n",
    "    'shrink': 15,\n",
    "    'similarity': 'jaccard',\n",
    "    'normalize': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:36.382767Z",
     "iopub.status.busy": "2023-12-02T10:20:36.382260Z",
     "iopub.status.idle": "2023-12-02T10:20:36.393917Z",
     "shell.execute_reply": "2023-12-02T10:20:36.392667Z",
     "shell.execute_reply.started": "2023-12-02T10:20:36.382721Z"
    }
   },
   "outputs": [],
   "source": [
    "RP3beta_params = {\n",
    "    'alpha': 0.307953246083667, \n",
    "    'beta': 0.3073797221110665, \n",
    "    'topK': 59, \n",
    "    'normalize_similarity': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:36.408260Z",
     "iopub.status.busy": "2023-12-02T10:20:36.407754Z",
     "iopub.status.idle": "2023-12-02T10:20:36.420682Z",
     "shell.execute_reply": "2023-12-02T10:20:36.419440Z",
     "shell.execute_reply.started": "2023-12-02T10:20:36.408209Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha_itemknn_rp3beta=0.7381515719042592"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:36.439934Z",
     "iopub.status.busy": "2023-12-02T10:20:36.439533Z",
     "iopub.status.idle": "2023-12-02T10:20:36.450457Z",
     "shell.execute_reply": "2023-12-02T10:20:36.449178Z",
     "shell.execute_reply.started": "2023-12-02T10:20:36.439900Z"
    }
   },
   "outputs": [],
   "source": [
    "UserKNN_params = {\n",
    "    'topK': 470,\n",
    "    'shrink': 0,\n",
    "    'similarity': 'cosine',\n",
    "    'normalize': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:36.470165Z",
     "iopub.status.busy": "2023-12-02T10:20:36.469050Z",
     "iopub.status.idle": "2023-12-02T10:20:36.478488Z",
     "shell.execute_reply": "2023-12-02T10:20:36.477073Z",
     "shell.execute_reply.started": "2023-12-02T10:20:36.470110Z"
    }
   },
   "outputs": [],
   "source": [
    "LightFM_params = {\n",
    "                  'n_factors': 482,\n",
    "                  'max_sampled': 5,\n",
    "                  'user_alpha': 0.00023989649900734266,\n",
    "                  'item_alpha': 9.740651135253414e-05\n",
    "                 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:36.480977Z",
     "iopub.status.busy": "2023-12-02T10:20:36.479987Z",
     "iopub.status.idle": "2023-12-02T10:20:40.773779Z",
     "shell.execute_reply": "2023-12-02T10:20:40.772509Z",
     "shell.execute_reply.started": "2023-12-02T10:20:36.480935Z"
    }
   },
   "outputs": [],
   "source": [
    "itemKNNCF = ItemKNNCFRecommender(urm_train)\n",
    "itemKNNCF.fit(**ItemKNN_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:40.780516Z",
     "iopub.status.busy": "2023-12-02T10:20:40.780066Z",
     "iopub.status.idle": "2023-12-02T10:20:54.155478Z",
     "shell.execute_reply": "2023-12-02T10:20:54.153902Z",
     "shell.execute_reply.started": "2023-12-02T10:20:40.780478Z"
    }
   },
   "outputs": [],
   "source": [
    "rp3beta = RP3betaRecommender(urm_train)\n",
    "rp3beta.fit(**RP3beta_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:54.157527Z",
     "iopub.status.busy": "2023-12-02T10:20:54.157108Z",
     "iopub.status.idle": "2023-12-02T10:20:54.188262Z",
     "shell.execute_reply": "2023-12-02T10:20:54.186853Z",
     "shell.execute_reply.started": "2023-12-02T10:20:54.157489Z"
    }
   },
   "outputs": [],
   "source": [
    "new_similarity = (1 - alpha_itemknn_rp3beta) * itemKNNCF.W_sparse + alpha_itemknn_rp3beta * rp3beta.W_sparse\n",
    "    \n",
    "itemKNN_rp3beta = ItemKNNCustomSimilarityRecommender(urm_train)\n",
    "itemKNN_rp3beta.fit(new_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:54.190117Z",
     "iopub.status.busy": "2023-12-02T10:20:54.189757Z",
     "iopub.status.idle": "2023-12-02T10:20:56.868780Z",
     "shell.execute_reply": "2023-12-02T10:20:56.867476Z",
     "shell.execute_reply.started": "2023-12-02T10:20:54.190086Z"
    }
   },
   "outputs": [],
   "source": [
    "userKNNCF = UserKNNCFRecommender(urm_train)\n",
    "userKNNCF.fit(**UserKNN_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:20:56.871134Z",
     "iopub.status.busy": "2023-12-02T10:20:56.870633Z",
     "iopub.status.idle": "2023-12-02T10:23:59.191610Z",
     "shell.execute_reply": "2023-12-02T10:23:59.190091Z",
     "shell.execute_reply.started": "2023-12-02T10:20:56.871084Z"
    }
   },
   "outputs": [],
   "source": [
    "lightfm = LightFMCFRecommender(urm_train)\n",
    "lightfm.fit(**LightFM_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T10:23:59.193864Z",
     "iopub.status.busy": "2023-12-02T10:23:59.193507Z",
     "iopub.status.idle": "2023-12-02T10:23:59.202831Z",
     "shell.execute_reply": "2023-12-02T10:23:59.201260Z",
     "shell.execute_reply.started": "2023-12-02T10:23:59.193832Z"
    }
   },
   "outputs": [],
   "source": [
    "class SaveResults(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.results_df = pd.DataFrame(columns=[\"result\"])\n",
    "\n",
    "    def __call__(self, optuna_study, optuna_trial):\n",
    "        hyperparam_dict = optuna_trial.params.copy()\n",
    "        hyperparam_dict[\"result\"] = optuna_trial.values[0]\n",
    "\n",
    "        # Create a DataFrame from the current trial's results\n",
    "        trial_df = pd.DataFrame([hyperparam_dict])\n",
    "\n",
    "        # Use concat instead of append\n",
    "        self.results_df = pd.concat([self.results_df, trial_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Alpha for full hybrid (Low perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T23:14:20.045595Z",
     "iopub.status.busy": "2023-12-01T23:14:20.044608Z",
     "iopub.status.idle": "2023-12-01T23:14:20.051239Z",
     "shell.execute_reply": "2023-12-01T23:14:20.050001Z",
     "shell.execute_reply.started": "2023-12-01T23:14:20.045545Z"
    }
   },
   "outputs": [],
   "source": [
    "recommenders = [itemKNN_rp3beta, userKNNCF, lightfm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T23:14:20.423270Z",
     "iopub.status.busy": "2023-12-01T23:14:20.422351Z",
     "iopub.status.idle": "2023-12-01T23:14:20.430201Z",
     "shell.execute_reply": "2023-12-01T23:14:20.429200Z",
     "shell.execute_reply.started": "2023-12-01T23:14:20.423226Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective_function_hybrid_full(optuna_trial):\n",
    "    alphas = [optuna_trial.suggest_float(\"alpha_itemKNN_rp3beta\", 0, 2), optuna_trial.suggest_float(\"alpha_userKNN\", 0, 2), optuna_trial.suggest_float(\"alpha_lightfm\", 0, 2)]\n",
    "    recommender_instance = GeneralizedLinearHybridRecommender(URM_train=urm_train, recommenders=recommenders)\n",
    "    recommender_instance.fit(\n",
    "                             alphas\n",
    "                            )\n",
    "\n",
    "    result_df, _ = evaluator_validation.evaluateRecommender(recommender_instance)\n",
    "\n",
    "    return result_df.loc[10][\"MAP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T23:14:27.440860Z",
     "iopub.status.busy": "2023-12-01T23:14:27.440421Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optuna_study_hybrid_full = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "save_results_hybrid_full = SaveResults()\n",
    "\n",
    "optuna_study_hybrid_full.optimize(objective_function_hybrid_full,\n",
    "                      callbacks=[save_results_hybrid_full],\n",
    "                      n_trials = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_trials = [t for t in optuna_study_hybrid_full.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in optuna_study_hybrid_full.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(optuna_study_hybrid_full.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(\"  Value Validation: \", optuna_study_hybrid_full.best_trial.value)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(optuna_study_hybrid_full.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Pair-wise alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ItemKNN + RP3beta] + UserKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T11:50:08.661863Z",
     "iopub.status.busy": "2023-12-02T11:50:08.660934Z",
     "iopub.status.idle": "2023-12-02T11:50:08.669313Z",
     "shell.execute_reply": "2023-12-02T11:50:08.668387Z",
     "shell.execute_reply.started": "2023-12-02T11:50:08.661812Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective_function_hybrid_1(optuna_trial):\n",
    "    alpha = optuna_trial.suggest_float(\"alpha_itemrp3_userknn\", 0, 1)\n",
    "    recommender_instance = ScoresHybridRecommender(URM_train=urm_train, recommender_1=itemKNN_rp3beta, recommender_2=lightfm)\n",
    "    recommender_instance.fit(\n",
    "                             alpha\n",
    "                            )\n",
    "\n",
    "    result_df, _ = evaluator_validation.evaluateRecommender(recommender_instance)\n",
    "\n",
    "    return result_df.loc[10][\"MAP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T11:50:08.848117Z",
     "iopub.status.busy": "2023-12-02T11:50:08.847249Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optuna_study_hybrid_1 = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "save_results_hybrid_1 = SaveResults()\n",
    "\n",
    "optuna_study_hybrid_1.optimize(objective_function_hybrid_1,\n",
    "                      callbacks=[save_results_hybrid_1],\n",
    "                      n_trials = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_trials = [t for t in optuna_study_hybrid_1.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in optuna_study_hybrid_1.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(optuna_study_hybrid_1.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(\"  Value Validation: \", optuna_study_hybrid_1.best_trial.value)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(optuna_study_hybrid_1.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Hybrid 1] + LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T11:36:37.874958Z",
     "iopub.status.busy": "2023-12-02T11:36:37.873671Z",
     "iopub.status.idle": "2023-12-02T11:36:37.891610Z",
     "shell.execute_reply": "2023-12-02T11:36:37.890397Z",
     "shell.execute_reply.started": "2023-12-02T11:36:37.874913Z"
    }
   },
   "outputs": [],
   "source": [
    "hybrid_1 = ScoresHybridRecommender(URM_train=urm_train, recommender_1=itemKNN_rp3beta, recommender_2=userKNNCF)\n",
    "hybrid_1.fit(optuna_study_hybrid_1.best_trial.params['alpha_itemrp3_userknn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T11:36:37.895077Z",
     "iopub.status.busy": "2023-12-02T11:36:37.894556Z",
     "iopub.status.idle": "2023-12-02T11:36:37.903579Z",
     "shell.execute_reply": "2023-12-02T11:36:37.901913Z",
     "shell.execute_reply.started": "2023-12-02T11:36:37.895028Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def objective_function_hybrid_2(optuna_trial):\n",
    "    alpha = optuna_trial.suggest_float(\"alpha_hybrid1_lightfm\", 0, 1)\n",
    "    recommender_instance = ScoresHybridRecommender(URM_train=urm_train, recommender_1=hybrid_1, recommender_2=userKNNCF)\n",
    "    recommender_instance.fit(\n",
    "                             alpha\n",
    "                            )\n",
    "\n",
    "    result_df, _ = evaluator_validation.evaluateRecommender(recommender_instance)\n",
    "\n",
    "    return result_df.loc[10][\"MAP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna_study_hybrid_2 = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "save_results_hybrid_2 = SaveResults()\n",
    "\n",
    "optuna_study_hybrid_2.optimize(objective_function_hybrid_2,\n",
    "                      callbacks=[save_results_hybrid_2],\n",
    "                      n_trials = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_trials = [t for t in optuna_study_hybrid_2.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in optuna_study_hybrid_2.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(optuna_study_hybrid_2.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(\"  Value Validation: \", optuna_study_hybrid_2.best_trial.value)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(optuna_study_hybrid_2.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urm_t_v = urm_train+urm_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemKNNCF = ItemKNNCFRecommender(urm_t_v)\n",
    "itemKNNCF.fit(**ItemKNN_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp3beta = RP3betaRecommender(urm_t_v)\n",
    "rp3beta.fit(**RP3beta_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_similarity = (1 - alpha_itemknn_rp3beta) * itemKNNCF.W_sparse + alpha_itemknn_rp3beta * rp3beta.W_sparse\n",
    "    \n",
    "itemKNN_rp3beta = ItemKNNCustomSimilarityRecommender(urm_t_v)\n",
    "itemKNN_rp3beta.fit(new_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userKNNCF = UserKNNCFRecommender(urm_t_v)\n",
    "userKNNCF.fit(**UserKNN_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightfm = LightFMCFRecommender(urm_t_v)\n",
    "lightfm.fit(**LightFM_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommenders_with_validation = [itemKNN_rp3beta,userKNNCF, lightfm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T23:08:25.373546Z",
     "iopub.status.busy": "2023-12-01T23:08:25.373042Z",
     "iopub.status.idle": "2023-12-01T23:08:25.380850Z",
     "shell.execute_reply": "2023-12-01T23:08:25.379256Z",
     "shell.execute_reply.started": "2023-12-01T23:08:25.373509Z"
    }
   },
   "outputs": [],
   "source": [
    "#best_params = {'alpha_itemKNN_rp3beta': 0.7012429402081097, 'alpha_userKNN': 0.02667849644983973, 'alpha_lightfm': 0.0017208279240408797}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid = GeneralizedLinearHybridRecommender(URM_train=urm_train+urm_validation, recommenders=recommenders_with_validation)\n",
    "hybrid.fit(list(optuna_study_hybrid_full.best_trial.params.values())) # TODO fix here if change fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df, _ = evaluator_test.evaluateRecommender(hybrid)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T22:55:23.060560Z",
     "iopub.status.busy": "2023-12-01T22:55:23.059819Z",
     "iopub.status.idle": "2023-12-01T22:55:23.075384Z",
     "shell.execute_reply": "2023-12-01T22:55:23.074141Z",
     "shell.execute_reply.started": "2023-12-01T22:55:23.060523Z"
    }
   },
   "outputs": [],
   "source": [
    "urm_full = urm_train+urm_validation+urm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T22:55:23.186337Z",
     "iopub.status.busy": "2023-12-01T22:55:23.185846Z",
     "iopub.status.idle": "2023-12-01T22:55:23.212501Z",
     "shell.execute_reply": "2023-12-01T22:55:23.211008Z",
     "shell.execute_reply.started": "2023-12-01T22:55:23.186294Z"
    }
   },
   "outputs": [],
   "source": [
    "top_pop_final = TopPop(urm_full)\n",
    "top_pop_final.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T22:55:23.332932Z",
     "iopub.status.busy": "2023-12-01T22:55:23.332469Z",
     "iopub.status.idle": "2023-12-01T22:55:28.446448Z",
     "shell.execute_reply": "2023-12-01T22:55:28.445105Z",
     "shell.execute_reply.started": "2023-12-01T22:55:23.332891Z"
    }
   },
   "outputs": [],
   "source": [
    "itemKNNCF = ItemKNNCFRecommender(urm_full)\n",
    "itemKNNCF.fit(**ItemKNN_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T22:55:28.450340Z",
     "iopub.status.busy": "2023-12-01T22:55:28.449433Z",
     "iopub.status.idle": "2023-12-01T22:55:43.062339Z",
     "shell.execute_reply": "2023-12-01T22:55:43.060861Z",
     "shell.execute_reply.started": "2023-12-01T22:55:28.450283Z"
    }
   },
   "outputs": [],
   "source": [
    "rp3beta = RP3betaRecommender(urm_full)\n",
    "rp3beta.fit(**RP3beta_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T22:55:43.064648Z",
     "iopub.status.busy": "2023-12-01T22:55:43.063922Z",
     "iopub.status.idle": "2023-12-01T22:55:46.579037Z",
     "shell.execute_reply": "2023-12-01T22:55:46.577864Z",
     "shell.execute_reply.started": "2023-12-01T22:55:43.064590Z"
    }
   },
   "outputs": [],
   "source": [
    "userKNNCF = UserKNNCFRecommender(urm_full)\n",
    "userKNNCF.fit(**UserKNN_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T22:55:46.581877Z",
     "iopub.status.busy": "2023-12-01T22:55:46.581500Z",
     "iopub.status.idle": "2023-12-01T23:01:48.901924Z",
     "shell.execute_reply": "2023-12-01T23:01:48.900437Z",
     "shell.execute_reply.started": "2023-12-01T22:55:46.581843Z"
    }
   },
   "outputs": [],
   "source": [
    "lightfm = LightFMCFRecommender(urm_full)\n",
    "lightfm.fit(**LightFM_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T23:01:48.903998Z",
     "iopub.status.busy": "2023-12-01T23:01:48.903620Z",
     "iopub.status.idle": "2023-12-01T23:01:48.931957Z",
     "shell.execute_reply": "2023-12-01T23:01:48.929608Z",
     "shell.execute_reply.started": "2023-12-01T23:01:48.903964Z"
    }
   },
   "outputs": [],
   "source": [
    "hybrid = GeneralizedLinearHybridRecommender(URM_train=urm_full, recommenders=recommenders)\n",
    "hybrid.fit(list(best_params)) # TODO fix here if change fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-01T23:01:48.932934Z",
     "iopub.status.idle": "2023-12-01T23:01:48.933441Z",
     "shell.execute_reply": "2023-12-01T23:01:48.933231Z",
     "shell.execute_reply.started": "2023-12-01T23:01:48.933199Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_submission(ratings: pd.DataFrame, users_to_recommend: np.array, urm_train: sps.csr_matrix, recommender: BaseRecommender, recommendation_length):\n",
    "    users_ids_and_mappings = ratings[ratings.user_id.isin(users_to_recommend)][[\"user_id\", \"mapped_user_id\"]].drop_duplicates()\n",
    "    mapping_to_item_id = dict(zip(ratings.mapped_item_id, ratings.item_id))\n",
    "\n",
    "    submission = []\n",
    "\n",
    "    rec_users_arr = users_ids_and_mappings.mapped_user_id.to_numpy()\n",
    "    recommendations = recommender.recommend(user_id_array= rec_users_arr, cutoff=recommendation_length)\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for idx, row in users_ids_and_mappings.iterrows():\n",
    "        user_id = row.user_id\n",
    "        mapped_user_id = row.mapped_user_id\n",
    "\n",
    "        submission.append((user_id, [mapping_to_item_id[item_id] for item_id in recommendations[i]]))\n",
    "        i+=1\n",
    "\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-01T23:01:48.934828Z",
     "iopub.status.idle": "2023-12-01T23:01:48.935317Z",
     "shell.execute_reply": "2023-12-01T23:01:48.935078Z",
     "shell.execute_reply.started": "2023-12-01T23:01:48.935058Z"
    }
   },
   "outputs": [],
   "source": [
    "users_to_recommend = target_dataframe.to_numpy().flatten()\n",
    "users_to_recommend.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-01T23:01:48.937026Z",
     "iopub.status.idle": "2023-12-01T23:01:48.937506Z",
     "shell.execute_reply": "2023-12-01T23:01:48.937309Z",
     "shell.execute_reply.started": "2023-12-01T23:01:48.937288Z"
    }
   },
   "outputs": [],
   "source": [
    "mapping_to_item_id = dict(zip(ratings.mapped_item_id, ratings.item_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-01T23:01:48.939249Z",
     "iopub.status.idle": "2023-12-01T23:01:48.939700Z",
     "shell.execute_reply": "2023-12-01T23:01:48.939502Z",
     "shell.execute_reply.started": "2023-12-01T23:01:48.939481Z"
    }
   },
   "outputs": [],
   "source": [
    "urm_ids = np.unique(ratings.user_id)\n",
    "missing_users = set([i for i in users_to_recommend]) - set([i for i in urm_ids])\n",
    "missing_users = np.array([x for x in missing_users])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-01T23:01:48.941675Z",
     "iopub.status.idle": "2023-12-01T23:01:48.942125Z",
     "shell.execute_reply": "2023-12-01T23:01:48.941920Z",
     "shell.execute_reply.started": "2023-12-01T23:01:48.941900Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-01T23:01:48.944525Z",
     "iopub.status.idle": "2023-12-01T23:01:48.945203Z",
     "shell.execute_reply": "2023-12-01T23:01:48.944884Z",
     "shell.execute_reply.started": "2023-12-01T23:01:48.944852Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_submission(submissions, name):\n",
    "    with open(f\"/kaggle/working/Results/{name}.csv\", \"w\") as f:\n",
    "        f.write(\"user_id,item_list\\n\")\n",
    "        for user_id, items in submissions:\n",
    "            f.write(f\"{user_id},{' '.join([str(item) for item in items])}\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-01T23:01:48.946778Z",
     "iopub.status.idle": "2023-12-01T23:01:48.947412Z",
     "shell.execute_reply": "2023-12-01T23:01:48.947102Z",
     "shell.execute_reply.started": "2023-12-01T23:01:48.947072Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = prepare_submission(ratings, users_to_recommend, urm_full, hybrid, recommendation_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-01T23:01:48.949806Z",
     "iopub.status.idle": "2023-12-01T23:01:48.950254Z",
     "shell.execute_reply": "2023-12-01T23:01:48.950038Z",
     "shell.execute_reply.started": "2023-12-01T23:01:48.950018Z"
    }
   },
   "outputs": [],
   "source": [
    "rec_missing = top_pop_final.recommend(missing_users, cutoff=10, remove_seen_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-01T23:01:48.951764Z",
     "iopub.status.idle": "2023-12-01T23:01:48.952215Z",
     "shell.execute_reply": "2023-12-01T23:01:48.951997Z",
     "shell.execute_reply.started": "2023-12-01T23:01:48.951978Z"
    }
   },
   "outputs": [],
   "source": [
    "for user_id in missing_users:\n",
    "  submission.append((user_id, [mapping_to_item_id[item_id] for item_id in rec_missing[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-01T23:01:48.953625Z",
     "iopub.status.idle": "2023-12-01T23:01:48.954083Z",
     "shell.execute_reply": "2023-12-01T23:01:48.953877Z",
     "shell.execute_reply.started": "2023-12-01T23:01:48.953856Z"
    }
   },
   "outputs": [],
   "source": [
    "(len(submission), len(users_to_recommend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-01T23:01:48.955510Z",
     "iopub.status.idle": "2023-12-01T23:01:48.955960Z",
     "shell.execute_reply": "2023-12-01T23:01:48.955766Z",
     "shell.execute_reply.started": "2023-12-01T23:01:48.955745Z"
    }
   },
   "outputs": [],
   "source": [
    "write_submission(submission, \"submission_hybrid_3-fold_individual_e\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4086250,
     "sourceId": 7091045,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30350,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
