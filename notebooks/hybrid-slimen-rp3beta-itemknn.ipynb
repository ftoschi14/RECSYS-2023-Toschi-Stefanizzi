{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting-up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-09T17:38:58.943701Z",
     "iopub.status.busy": "2023-12-09T17:38:58.943105Z",
     "iopub.status.idle": "2023-12-09T17:39:05.606627Z",
     "shell.execute_reply": "2023-12-09T17:39:05.605419Z",
     "shell.execute_reply.started": "2023-12-09T17:38:58.943661Z"
    }
   },
   "outputs": [],
   "source": [
    "!cp -r ../input/updated-code-3-7/* /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:05:48.567465Z",
     "iopub.status.busy": "2023-12-08T21:05:48.567055Z",
     "iopub.status.idle": "2023-12-08T21:06:05.947996Z",
     "shell.execute_reply": "2023-12-08T21:06:05.946646Z",
     "shell.execute_reply.started": "2023-12-08T21:05:48.567431Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:39:05.608963Z",
     "iopub.status.busy": "2023-12-09T17:39:05.608660Z",
     "iopub.status.idle": "2023-12-09T17:39:27.719876Z",
     "shell.execute_reply": "2023-12-09T17:39:27.718634Z",
     "shell.execute_reply.started": "2023-12-09T17:39:05.608935Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install lightfm tqdm optuna ipykernel matplotlib implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:39:27.721983Z",
     "iopub.status.busy": "2023-12-09T17:39:27.721567Z",
     "iopub.status.idle": "2023-12-09T17:41:38.581477Z",
     "shell.execute_reply": "2023-12-09T17:41:38.580247Z",
     "shell.execute_reply.started": "2023-12-09T17:39:27.721941Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python run_compile_all_cython.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:41:38.584172Z",
     "iopub.status.busy": "2023-12-09T17:41:38.583858Z",
     "iopub.status.idle": "2023-12-09T17:41:40.402895Z",
     "shell.execute_reply": "2023-12-09T17:41:40.401950Z",
     "shell.execute_reply.started": "2023-12-09T17:41:38.584142Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "from scipy.sparse import vstack, csr_matrix\n",
    "from scipy.stats import loguniform\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score, precision_at_k\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:41:40.404425Z",
     "iopub.status.busy": "2023-12-09T17:41:40.403979Z",
     "iopub.status.idle": "2023-12-09T17:41:41.226898Z",
     "shell.execute_reply": "2023-12-09T17:41:41.226100Z",
     "shell.execute_reply.started": "2023-12-09T17:41:40.404395Z"
    }
   },
   "outputs": [],
   "source": [
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "from Recommenders.BaseMatrixFactorizationRecommender import BaseMatrixFactorizationRecommender\n",
    "from Recommenders.NonPersonalizedRecommender import TopPop\n",
    "\n",
    "#---- CF\n",
    "from Recommenders.KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "from Recommenders.KNN.UserKNNCFRecommender import UserKNNCFRecommender\n",
    "from Recommenders.GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "from Recommenders.KNN.ItemKNNCustomSimilarityRecommender import ItemKNNCustomSimilarityRecommender\n",
    "\n",
    "#---- Matrix Factorization\n",
    "from Recommenders.MatrixFactorization.NMFRecommender import NMFRecommender\n",
    "\n",
    "#---- CF w/ ML\n",
    "from Recommenders.SLIM.SLIMElasticNetRecommender import SLIMElasticNetRecommender, MultiThreadSLIM_SLIMElasticNetRecommender\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "#---- Others\n",
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "from Recommenders.Recommender_utils import check_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:41:41.228696Z",
     "iopub.status.busy": "2023-12-09T17:41:41.228170Z",
     "iopub.status.idle": "2023-12-09T17:41:41.233187Z",
     "shell.execute_reply": "2023-12-09T17:41:41.232318Z",
     "shell.execute_reply.started": "2023-12-09T17:41:41.228660Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 69\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:21.116981Z",
     "iopub.status.busy": "2023-12-09T17:42:21.116038Z",
     "iopub.status.idle": "2023-12-09T17:42:24.102286Z",
     "shell.execute_reply": "2023-12-09T17:42:24.101456Z",
     "shell.execute_reply.started": "2023-12-09T17:42:21.116944Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import training data\n",
    "URM_path = \"../input/data-books/data_train.csv\"\n",
    "URM_all_dataframe = pd.read_csv(filepath_or_buffer=URM_path,\n",
    "                                header=0,\n",
    "                                dtype={0:int, 1:int, 2:int},\n",
    "                                engine='python')\n",
    "\n",
    "URM_all_dataframe.columns = [\"user_id\", \"item_id\", \"interaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:24.104477Z",
     "iopub.status.busy": "2023-12-09T17:42:24.104065Z",
     "iopub.status.idle": "2023-12-09T17:42:24.161300Z",
     "shell.execute_reply": "2023-12-09T17:42:24.160318Z",
     "shell.execute_reply.started": "2023-12-09T17:42:24.104440Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import target users\n",
    "target_path = \"../input/data-books/data_target_users_test.csv\"\n",
    "target_dataframe= pd.read_csv(filepath_or_buffer=target_path,\n",
    "                                header=0,\n",
    "                                dtype={0:int},\n",
    "                                engine='python')\n",
    "target_dataframe.columns = [\"user_id\"]\n",
    "target_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:24.162585Z",
     "iopub.status.busy": "2023-12-09T17:42:24.162329Z",
     "iopub.status.idle": "2023-12-09T17:42:24.169844Z",
     "shell.execute_reply": "2023-12-09T17:42:24.168994Z",
     "shell.execute_reply.started": "2023-12-09T17:42:24.162561Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(ratings: pd.DataFrame):\n",
    "    unique_users = ratings.user_id.unique()\n",
    "    unique_items = ratings.item_id.unique()\n",
    "\n",
    "    num_users, min_user_id, max_user_id = unique_users.size, unique_users.min(), unique_users.max()\n",
    "    num_items, min_item_id, max_item_id = unique_items.size, unique_items.min(), unique_items.max()\n",
    "\n",
    "    print(num_users, min_user_id, max_user_id)\n",
    "    print(num_items, min_item_id, max_item_id)\n",
    "\n",
    "    mapping_user_id = pd.DataFrame({\"mapped_user_id\": np.arange(num_users), \"user_id\": unique_users})\n",
    "    mapping_item_id = pd.DataFrame({\"mapped_item_id\": np.arange(num_items), \"item_id\": unique_items})\n",
    "\n",
    "    ratings = pd.merge(left=ratings,\n",
    "                       right=mapping_user_id,\n",
    "                       how=\"inner\",\n",
    "                       on=\"user_id\")\n",
    "\n",
    "    ratings = pd.merge(left=ratings,\n",
    "                       right=mapping_item_id,\n",
    "                       how=\"inner\",\n",
    "                       on=\"item_id\")\n",
    "\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:24.796832Z",
     "iopub.status.busy": "2023-12-09T17:42:24.796384Z",
     "iopub.status.idle": "2023-12-09T17:42:24.926537Z",
     "shell.execute_reply": "2023-12-09T17:42:24.925565Z",
     "shell.execute_reply.started": "2023-12-09T17:42:24.796792Z"
    }
   },
   "outputs": [],
   "source": [
    "# Call preprocess data function\n",
    "ratings = preprocess_data(URM_all_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion to Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:25.739322Z",
     "iopub.status.busy": "2023-12-09T17:42:25.738972Z",
     "iopub.status.idle": "2023-12-09T17:42:25.746913Z",
     "shell.execute_reply": "2023-12-09T17:42:25.745693Z",
     "shell.execute_reply.started": "2023-12-09T17:42:25.739294Z"
    }
   },
   "outputs": [],
   "source": [
    "URM = sps.coo_matrix((ratings.interaction.values, (ratings.mapped_user_id.values, ratings.mapped_item_id.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:26.530148Z",
     "iopub.status.busy": "2023-12-09T17:42:26.529292Z",
     "iopub.status.idle": "2023-12-09T17:42:27.771958Z",
     "shell.execute_reply": "2023-12-09T17:42:27.770968Z",
     "shell.execute_reply.started": "2023-12-09T17:42:26.530105Z"
    }
   },
   "outputs": [],
   "source": [
    "urm_train, urm_validation = split_train_in_two_percentage_global_sample(URM, train_percentage = 0.80)\n",
    "#urm_train, urm_validation = split_train_in_two_percentage_global_sample(urm_train, train_percentage = 0.80)\n",
    "\n",
    "evaluator_validation = EvaluatorHoldout(urm_validation, cutoff_list=[10])\n",
    "#evaluator_test = EvaluatorHoldout(urm_test, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Custom Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T18:19:33.670945Z",
     "iopub.status.busy": "2023-12-09T18:19:33.669713Z",
     "iopub.status.idle": "2023-12-09T18:19:33.678732Z",
     "shell.execute_reply": "2023-12-09T18:19:33.677872Z",
     "shell.execute_reply.started": "2023-12-09T18:19:33.670905Z"
    }
   },
   "outputs": [],
   "source": [
    "class ScoresHybridRecommender(BaseRecommender):\n",
    "    \"\"\" ScoresHybridRecommender\n",
    "    Hybrid of two prediction scores R = R1*alpha + R2*(1-alpha)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"ScoresHybridRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, recommender_1, recommender_2):\n",
    "        super(ScoresHybridRecommender, self).__init__(URM_train)\n",
    "\n",
    "        self.URM_train = sps.csr_matrix(URM_train)\n",
    "        self.recommender_1 = recommender_1\n",
    "        self.recommender_2 = recommender_2\n",
    "\n",
    "\n",
    "    def fit(self, alpha=0.5):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute):\n",
    "\n",
    "        # In a simple extension this could be a loop over a list of pretrained recommender objects\n",
    "        item_weights_1 = self.recommender_1._compute_item_score(user_id_array)\n",
    "        item_weights_2 = self.recommender_2._compute_item_score(user_id_array)\n",
    "        \n",
    "        item_weights_2 = item_weights_2 - np.array(item_weights_2).mean()\n",
    "        print(item_weights_2.shape)\n",
    "        item_weights_2[item_weights_2 < 0] = 0\n",
    "        item_weights_2[item_weights_2 > 1] = 0.99\n",
    "\n",
    "        item_weights = item_weights_1*self.alpha + item_weights_2*(1-self.alpha)\n",
    "\n",
    "        return item_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:27.784311Z",
     "iopub.status.busy": "2023-12-09T17:42:27.784000Z",
     "iopub.status.idle": "2023-12-09T17:42:27.794766Z",
     "shell.execute_reply": "2023-12-09T17:42:27.793891Z",
     "shell.execute_reply.started": "2023-12-09T17:42:27.784276Z"
    }
   },
   "outputs": [],
   "source": [
    "class DifferentLossScoresHybridRecommender(BaseRecommender):\n",
    "    \"\"\" ScoresHybridRecommender\n",
    "    Hybrid of two prediction scores R = R1/norm*alpha + R2/norm*(1-alpha) where R1 and R2 come from\n",
    "    algorithms trained on different loss functions.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"DifferentLossScoresHybridRecommender\"\n",
    "\n",
    "\n",
    "    def __init__(self, URM_train, recommender_1, recommender_2):\n",
    "        super(DifferentLossScoresHybridRecommender, self).__init__(URM_train)\n",
    "\n",
    "        self.URM_train = sps.csr_matrix(URM_train)\n",
    "        self.recommender_1 = recommender_1\n",
    "        self.recommender_2 = recommender_2\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit(self, norm, alpha = 0.5):\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.norm = norm\n",
    "\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute):\n",
    "        \n",
    "        item_weights_1 = self.recommender_1._compute_item_score(user_id_array)\n",
    "        item_weights_2 = self.recommender_2._compute_item_score(user_id_array)\n",
    "\n",
    "        norm_item_weights_1 = LA.norm(item_weights_1, self.norm)\n",
    "        norm_item_weights_2 = LA.norm(item_weights_2, self.norm)\n",
    "        \n",
    "        \n",
    "        if norm_item_weights_1 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 1 is zero. Avoiding division by zero\".format(self.norm))\n",
    "        \n",
    "        if norm_item_weights_2 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 2 is zero. Avoiding division by zero\".format(self.norm))\n",
    "        \n",
    "        item_weights = item_weights_1 / norm_item_weights_1 * self.alpha + item_weights_2 / norm_item_weights_2 * (1-self.alpha)\n",
    "\n",
    "        return item_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:27.845364Z",
     "iopub.status.busy": "2023-12-09T17:42:27.845064Z",
     "iopub.status.idle": "2023-12-09T17:42:27.854148Z",
     "shell.execute_reply": "2023-12-09T17:42:27.853156Z",
     "shell.execute_reply.started": "2023-12-09T17:42:27.845338Z"
    }
   },
   "outputs": [],
   "source": [
    "class LightFMCFRecommender(BaseRecommender):\n",
    "    \"\"\"LightFMCFRecommender\"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"LightFMCFRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train):\n",
    "        super(LightFMCFRecommender, self).__init__(URM_train)\n",
    "    \n",
    "    \n",
    "    def fit(self, epochs = 300, user_alpha=1e-6, item_alpha = 1e-6, n_factors = 10, n_threads = 4, max_sampled=3, loss='warp', learning_schedule='adagrad'):\n",
    "        \n",
    "        # Let's fit a WARP model\n",
    "        self.lightFM_model = LightFM(loss=loss,\n",
    "                                     user_alpha=user_alpha,\n",
    "                                     item_alpha=item_alpha,\n",
    "                                     no_components=n_factors,\n",
    "                                     max_sampled=max_sampled,\n",
    "                                     learning_schedule=learning_schedule)\n",
    "\n",
    "        self.lightFM_model = self.lightFM_model.fit(self.URM_train, \n",
    "                                       epochs=epochs,\n",
    "                                       num_threads=n_threads,\n",
    "                                       verbose=True)\n",
    "\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute = None):\n",
    "        \n",
    "        # Create a single (n_items, ) array with the item score, then copy it for every user\n",
    "        items_to_compute = np.arange(self.n_items)\n",
    "        \n",
    "        item_scores = - np.ones((len(user_id_array), self.n_items)) * np.inf\n",
    "\n",
    "        for user_index, user_id in enumerate(user_id_array):\n",
    "            item_scores[user_index] = self.lightFM_model.predict(int(user_id), \n",
    "                                                                 items_to_compute)\n",
    "\n",
    "        return item_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:27.973095Z",
     "iopub.status.busy": "2023-12-09T17:42:27.972400Z",
     "iopub.status.idle": "2023-12-09T17:42:27.981559Z",
     "shell.execute_reply": "2023-12-09T17:42:27.980506Z",
     "shell.execute_reply.started": "2023-12-09T17:42:27.973060Z"
    }
   },
   "outputs": [],
   "source": [
    "class GeneralizedLinearHybridRecommender(BaseRecommender):\n",
    "    \"\"\"\n",
    "    This recommender merges N recommendes by weighting their ratings\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"GeneralizedLinearHybridRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, recommenders: list, verbose=True):\n",
    "        self.RECOMMENDER_NAME = ''\n",
    "        for recommender in recommenders:\n",
    "            self.RECOMMENDER_NAME = self.RECOMMENDER_NAME + recommender.RECOMMENDER_NAME[:-11]\n",
    "        self.RECOMMENDER_NAME = self.RECOMMENDER_NAME + 'HybridRecommender'\n",
    "\n",
    "        super(GeneralizedLinearHybridRecommender, self).__init__(URM_train, verbose=verbose)\n",
    "\n",
    "        self.recommenders = recommenders\n",
    "\n",
    "    def fit(self, alphas=None):\n",
    "        self.alphas = alphas\n",
    "\n",
    "    def save_model(self, folder_path, file_name=None):\n",
    "        pass\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute=None):\n",
    "        result = self.alphas[0]*self.recommenders[0]._compute_item_score(user_id_array,items_to_compute)\n",
    "        for index in range(1,len(self.alphas)):\n",
    "            result = result + self.alphas[index]*self.recommenders[index]._compute_item_score(user_id_array,items_to_compute)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T18:04:46.352071Z",
     "iopub.status.busy": "2023-12-09T18:04:46.350920Z",
     "iopub.status.idle": "2023-12-09T18:04:46.367238Z",
     "shell.execute_reply": "2023-12-09T18:04:46.366296Z",
     "shell.execute_reply.started": "2023-12-09T18:04:46.352028Z"
    }
   },
   "outputs": [],
   "source": [
    "class FastIALSRecommender(BaseMatrixFactorizationRecommender):\n",
    "    RECOMMENDER_NAME = \"FastIALSRecommender\"\n",
    "\n",
    "    AVAILABLE_CONFIDENCE_SCALING = [\"linear\", \"log\"]\n",
    "    \n",
    "    def __init__(self, URM_train, verbose=True):\n",
    "        super().__init__(URM_train, verbose=verbose)\n",
    "        \n",
    "    def fit(self,\n",
    "            factors=20,\n",
    "            regularization=1e-3,\n",
    "            iterations=100,\n",
    "            calculate_training_loss=False,\n",
    "            num_threads=0,\n",
    "            confidence_scaling='linear',\n",
    "            alpha=1.0,\n",
    "            epsilon=0,\n",
    "            #---- Do not change\n",
    "            use_native=True,\n",
    "            use_cg=True,\n",
    "            use_gpu=True):\n",
    "        if confidence_scaling not in self.AVAILABLE_CONFIDENCE_SCALING:\n",
    "           raise ValueError(\"Value for 'confidence_scaling' not recognized. Acceptable values are {}, provided was '{}'\".format(self.AVAILABLE_CONFIDENCE_SCALING, confidence_scaling))\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.num_factors = factors\n",
    "        self.reg = regularization\n",
    "        \n",
    "        self.USER_factors = self._init_factors(self.n_users, False)  # don't need values, will compute them\n",
    "        self.ITEM_factors = self._init_factors(self.n_items)\n",
    "        \n",
    "        self.recommender = AlternatingLeastSquares(factors=factors, regularization=regularization,\n",
    "                                                        use_native=use_native, use_cg=use_cg, use_gpu=use_gpu,\n",
    "                                                        iterations=iterations,\n",
    "                                                        calculate_training_loss=calculate_training_loss,\n",
    "                                                        num_threads=num_threads)\n",
    "        \n",
    "        self._build_confidence_matrix(confidence_scaling)\n",
    "        self.recommender.fit(self.C, show_progress=self.verbose)\n",
    "        \n",
    "        self.USER_factors = self.recommender.user_factors.to_numpy()\n",
    "        self.ITEM_factors = self.recommender.item_factors.to_numpy()\n",
    "        \n",
    "    \n",
    "    def _linear_scaling_confidence(self):\n",
    "\n",
    "        C = check_matrix(self.URM_train, format=\"csr\", dtype = np.float32)\n",
    "        C.data = 1.0 + self.alpha*C.data\n",
    "\n",
    "        return C\n",
    "\n",
    "    def _log_scaling_confidence(self):\n",
    "\n",
    "        C = check_matrix(self.URM_train, format=\"csr\", dtype = np.float32)\n",
    "        C.data = 1.0 + self.alpha * np.log(1.0 + C.data / self.epsilon)\n",
    "\n",
    "        return C\n",
    "    \n",
    "    def _build_confidence_matrix(self, confidence_scaling):\n",
    "\n",
    "        if confidence_scaling == 'linear':\n",
    "            self.C = self._linear_scaling_confidence()\n",
    "        else:\n",
    "            self.C = self._log_scaling_confidence()\n",
    "\n",
    "        self.C_csc= check_matrix(self.C.copy(), format=\"csc\", dtype = np.float32)\n",
    "    \n",
    "    def _init_factors(self, num_factors, assign_values=True):\n",
    "\n",
    "        if assign_values:\n",
    "            return self.num_factors**-0.5*np.random.random_sample((num_factors, self.num_factors))\n",
    "\n",
    "        else:\n",
    "            return np.empty((num_factors, self.num_factors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:28.293169Z",
     "iopub.status.busy": "2023-12-09T17:42:28.292495Z",
     "iopub.status.idle": "2023-12-09T17:42:28.302825Z",
     "shell.execute_reply": "2023-12-09T17:42:28.301980Z",
     "shell.execute_reply.started": "2023-12-09T17:42:28.293138Z"
    }
   },
   "outputs": [],
   "source": [
    "class RankHybridRecommender(BaseRecommender):\n",
    "    \"\"\" RankHybridRecommender\n",
    "    Hybrid of two Recommendations using weighted borda count\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"RankHybridRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, recommender_1, recommender_2):\n",
    "        super(RankHybridRecommender, self).__init__(URM_train)\n",
    "\n",
    "        self.URM_train = sps.csr_matrix(URM_train)\n",
    "        self.recommender_1 = recommender_1\n",
    "        self.recommender_2 = recommender_2\n",
    "\n",
    "\n",
    "    def fit(self, alpha=0.5):\n",
    "        self.alpha = alpha\n",
    "        \n",
    "\n",
    "    def recommend(self, user_id_array, cutoff = None, remove_seen_flag=True, items_to_compute = None, \n",
    "                  remove_top_pop_flag = False, remove_custom_items_flag = False, return_scores = False):\n",
    "        recommendations_rec1, scores_batch_rec1 = self.recommender_1.recommend(user_id_array, cutoff, remove_seen_flag, items_to_compute, remove_top_pop_flag, remove_custom_items_flag, return_scores)\n",
    "        recommendations_rec2, scores_batch_rec2 = self.recommender_2.recommend(user_id_array, cutoff, remove_seen_flag, items_to_compute, remove_top_pop_flag, remove_custom_items_flag, return_scores)\n",
    "        #print(np.shape(recommendations_rec1))\n",
    "        rankings = [recommendations_rec1, recommendations_rec2]\n",
    "        #print(np.shape(rankings))\n",
    "        weights = [self.alpha, 1-self.alpha] \n",
    "        \n",
    "        items_to_compute = np.arange(self.n_items)\n",
    "        \n",
    "        final_recommendations = weighted_borda_count(np.array(rankings), weights)\n",
    "        if return_scores:\n",
    "            return final_recommendations, np.zeros(shape=(len(user_id_array), len(items_to_compute)))\n",
    "\n",
    "        else:\n",
    "            return final_recommendations\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:28.437719Z",
     "iopub.status.busy": "2023-12-09T17:42:28.436920Z",
     "iopub.status.idle": "2023-12-09T17:42:28.446466Z",
     "shell.execute_reply": "2023-12-09T17:42:28.445469Z",
     "shell.execute_reply.started": "2023-12-09T17:42:28.437680Z"
    }
   },
   "outputs": [],
   "source": [
    "def weighted_borda_count(rankings, weights):\n",
    "    \"\"\"\n",
    "    Aggregate rankings using the weighted Borda count method for multiple recommenders and users,\n",
    "    considering unique recommendations from each recommender.\n",
    "    \n",
    "    :param rankings: A 3D list or array of rankings, shape (n_recommenders, n_users, n_recommendations)\n",
    "    :param weights: A list of weights corresponding to each recommender's importance.\n",
    "    :return: An aggregated ranking list for each user.\n",
    "    \"\"\"\n",
    "    if rankings.shape[0] != len(weights):\n",
    "        raise ValueError(\"Number of recommenders in rankings must match the number of weights.\")\n",
    "\n",
    "    n_recommenders, n_users, n_recommendations = rankings.shape\n",
    "    \n",
    "    # Initialize a list to store the total Borda count for each item for each user\n",
    "    borda_scores = [{} for _ in range(n_users)]\n",
    "\n",
    "    # Loop through each recommender, user, and their rankings\n",
    "    for recommender_index, weight in enumerate(weights):\n",
    "        for user_index in range(n_users):\n",
    "            # Get the maximum possible Borda count in current recommender's list\n",
    "            max_borda_count = n_recommendations * weight\n",
    "            for rank_index, item_id in enumerate(rankings[recommender_index, user_index]):\n",
    "                # The Borda count for the current rank and weight\n",
    "                points = (max_borda_count - rank_index * weight)\n",
    "                if item_id in borda_scores[user_index]:\n",
    "                    borda_scores[user_index][item_id] += points\n",
    "                else:\n",
    "                    borda_scores[user_index][item_id] = points\n",
    "\n",
    "    # Sort the items for each user by their Borda count in descending order\n",
    "    aggregated_rankings = []\n",
    "    for user_index in range(n_users):\n",
    "        user_ranking = sorted(borda_scores[user_index].items(), key=lambda x: x[1], reverse=True)\n",
    "        # Extract the item IDs from the sorted tuples\n",
    "        aggregated_rankings.append([item_id for item_id, _ in user_ranking])\n",
    "\n",
    "    # Return the aggregated rankings for each user\n",
    "    return aggregated_rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Best Model Params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:29.304475Z",
     "iopub.status.busy": "2023-12-09T17:42:29.303590Z",
     "iopub.status.idle": "2023-12-09T17:42:29.308581Z",
     "shell.execute_reply": "2023-12-09T17:42:29.307659Z",
     "shell.execute_reply.started": "2023-12-09T17:42:29.304437Z"
    }
   },
   "outputs": [],
   "source": [
    "ItemKNN_params = {\n",
    " 'topK': 21,\n",
    " 'shrink': 1462,\n",
    " 'similarity': 'tanimoto',\n",
    " 'normalize': False,\n",
    " 'feature_weighting': 'BM25'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:29.513962Z",
     "iopub.status.busy": "2023-12-09T17:42:29.513552Z",
     "iopub.status.idle": "2023-12-09T17:42:29.518477Z",
     "shell.execute_reply": "2023-12-09T17:42:29.517594Z",
     "shell.execute_reply.started": "2023-12-09T17:42:29.513932Z"
    }
   },
   "outputs": [],
   "source": [
    "RP3Beta_params = {\n",
    " 'alpha': 0.3302958327908062,\n",
    " 'beta': 0.14271386569051958,\n",
    " 'topK': 29,\n",
    " 'normalize_similarity': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:29.906170Z",
     "iopub.status.busy": "2023-12-09T17:42:29.905793Z",
     "iopub.status.idle": "2023-12-09T17:42:29.911648Z",
     "shell.execute_reply": "2023-12-09T17:42:29.910653Z",
     "shell.execute_reply.started": "2023-12-09T17:42:29.906133Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha_itemknn_rp3beta=0.7381515719042592"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:30.060836Z",
     "iopub.status.busy": "2023-12-09T17:42:30.060455Z",
     "iopub.status.idle": "2023-12-09T17:42:30.065154Z",
     "shell.execute_reply": "2023-12-09T17:42:30.064196Z",
     "shell.execute_reply.started": "2023-12-09T17:42:30.060807Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha_slim_rp3beta = 0.5356582511094522"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:30.204651Z",
     "iopub.status.busy": "2023-12-09T17:42:30.204269Z",
     "iopub.status.idle": "2023-12-09T17:42:30.209368Z",
     "shell.execute_reply": "2023-12-09T17:42:30.208460Z",
     "shell.execute_reply.started": "2023-12-09T17:42:30.204597Z"
    }
   },
   "outputs": [],
   "source": [
    "UserKNN_params = {\n",
    " 'topK': 387,\n",
    " 'shrink': 1,\n",
    " 'similarity': 'cosine',\n",
    " 'normalize': True,\n",
    " 'feature_weighting': 'TF-IDF'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:30.360939Z",
     "iopub.status.busy": "2023-12-09T17:42:30.359995Z",
     "iopub.status.idle": "2023-12-09T17:42:30.364957Z",
     "shell.execute_reply": "2023-12-09T17:42:30.364117Z",
     "shell.execute_reply.started": "2023-12-09T17:42:30.360903Z"
    }
   },
   "outputs": [],
   "source": [
    "LightFM_params = {\n",
    "                  'n_factors': 482,\n",
    "                  'max_sampled': 5,\n",
    "                  'user_alpha': 0.00023989649900734266,\n",
    "                  'item_alpha': 9.740651135253414e-05\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:30.799061Z",
     "iopub.status.busy": "2023-12-09T17:42:30.798029Z",
     "iopub.status.idle": "2023-12-09T17:42:30.804084Z",
     "shell.execute_reply": "2023-12-09T17:42:30.803036Z",
     "shell.execute_reply.started": "2023-12-09T17:42:30.799015Z"
    }
   },
   "outputs": [],
   "source": [
    "SLIM_params = {\n",
    " 'l1_ratio': 0.04324773367371399,\n",
    " 'alpha': 0.001220701931267383,\n",
    " 'topK': 971\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:31.065365Z",
     "iopub.status.busy": "2023-12-09T17:42:31.064544Z",
     "iopub.status.idle": "2023-12-09T17:42:31.069851Z",
     "shell.execute_reply": "2023-12-09T17:42:31.068860Z",
     "shell.execute_reply.started": "2023-12-09T17:42:31.065331Z"
    }
   },
   "outputs": [],
   "source": [
    "NMF_params = {\n",
    "    'l1_ratio': 0.005734775635120469,\n",
    "    'num_factors': 134,\n",
    "    'beta_loss': 'frobenius',\n",
    "    'init_type': 'nndsvda',\n",
    "    'solver': 'multiplicative_update'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T18:04:52.881539Z",
     "iopub.status.busy": "2023-12-09T18:04:52.881171Z",
     "iopub.status.idle": "2023-12-09T18:04:52.886487Z",
     "shell.execute_reply": "2023-12-09T18:04:52.885507Z",
     "shell.execute_reply.started": "2023-12-09T18:04:52.881509Z"
    }
   },
   "outputs": [],
   "source": [
    "IALS_params = {\n",
    "'factors': 216, \n",
    "'confidence_scaling': 'linear', \n",
    "'alpha': 2.971319492415353, \n",
    "'epsilon': 0.27505837539726546, \n",
    "'regularization': 0.0062196937352773235\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:32.540749Z",
     "iopub.status.busy": "2023-12-09T17:42:32.540353Z",
     "iopub.status.idle": "2023-12-09T17:42:36.725022Z",
     "shell.execute_reply": "2023-12-09T17:42:36.723969Z",
     "shell.execute_reply.started": "2023-12-09T17:42:32.540717Z"
    }
   },
   "outputs": [],
   "source": [
    "itemKNNCF = ItemKNNCFRecommender(urm_train)\n",
    "itemKNNCF.fit(**ItemKNN_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:36.727197Z",
     "iopub.status.busy": "2023-12-09T17:42:36.726714Z",
     "iopub.status.idle": "2023-12-09T17:42:50.026648Z",
     "shell.execute_reply": "2023-12-09T17:42:50.025834Z",
     "shell.execute_reply.started": "2023-12-09T17:42:36.727170Z"
    }
   },
   "outputs": [],
   "source": [
    "rp3beta = RP3betaRecommender(urm_train)\n",
    "rp3beta.fit(**RP3Beta_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T17:42:50.028250Z",
     "iopub.status.busy": "2023-12-09T17:42:50.027859Z",
     "iopub.status.idle": "2023-12-09T18:03:50.219092Z",
     "shell.execute_reply": "2023-12-09T18:03:50.217884Z",
     "shell.execute_reply.started": "2023-12-09T17:42:50.028198Z"
    }
   },
   "outputs": [],
   "source": [
    "slim = MultiThreadSLIM_SLIMElasticNetRecommender(urm_train)\n",
    "slim.fit(**SLIM_params, workers = int(cpu_count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 0\n",
    "\n",
    "rp3beta_scores = rp3beta._compute_item_score(user_id).flatten()\n",
    "slim_scores = slim._compute_item_score(user_id).flatten()\n",
    "itemknn_scores = itemKNNCF._compute_item_score(user_id).flatten()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16,7))\n",
    "ax = sns.scatterplot(data=rp3beta_scores, alpha=0.5, color = \"red\")\n",
    "ax = sns.scatterplot(data=slim_scores, alpha=0.5, color = \"blue\")\n",
    "#ax = sns.scatterplot(data=itemknn_scores, alpha=0.5, color = \"green\")\n",
    "ax.legend(['rp3beta', 'slim'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T18:06:50.254534Z",
     "iopub.status.busy": "2023-12-09T18:06:50.253813Z",
     "iopub.status.idle": "2023-12-09T18:06:50.352805Z",
     "shell.execute_reply": "2023-12-09T18:06:50.351784Z",
     "shell.execute_reply.started": "2023-12-09T18:06:50.254498Z"
    }
   },
   "outputs": [],
   "source": [
    "new_similarity = (1 - alpha_slim_rp3beta) * slim.W_sparse + alpha_slim_rp3beta * rp3beta.W_sparse\n",
    "    \n",
    "slim_rp3beta = ItemKNNCustomSimilarityRecommender(urm_train)\n",
    "slim_rp3beta.fit(new_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T18:05:17.796809Z",
     "iopub.status.busy": "2023-12-09T18:05:17.796172Z",
     "iopub.status.idle": "2023-12-09T18:05:17.802729Z",
     "shell.execute_reply": "2023-12-09T18:05:17.801807Z",
     "shell.execute_reply.started": "2023-12-09T18:05:17.796774Z"
    }
   },
   "outputs": [],
   "source": [
    "class SaveResults(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.results_df = pd.DataFrame(columns=[\"result\"])\n",
    "\n",
    "    def __call__(self, optuna_study, optuna_trial):\n",
    "        hyperparam_dict = optuna_trial.params.copy()\n",
    "        hyperparam_dict[\"result\"] = optuna_trial.values[0]\n",
    "\n",
    "        # Create a DataFrame from the current trial's results\n",
    "        trial_df = pd.DataFrame([hyperparam_dict])\n",
    "\n",
    "        # Use concat instead of append\n",
    "        self.results_df = pd.concat([self.results_df, trial_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_slim_rp3beta(optuna_trial):\n",
    "    alpha_slim_rp3beta = optuna_trial.suggest_float(\"alpha_slim_rp3beta\", 0.50, 0.67)\n",
    "    new_similarity = (1 - alpha_slim_rp3beta) * slim.W_sparse + alpha_slim_rp3beta * rp3beta.W_sparse\n",
    "    recommender_instance = ItemKNNCustomSimilarityRecommender(urm_train)\n",
    "    recommender_instance.fit(new_similarity)\n",
    "\n",
    "    result_df, _ = evaluator_validation.evaluateRecommender(recommender_instance)\n",
    "\n",
    "    return result_df.loc[10][\"MAP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optuna_study_slim_rp3beta = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "save_results_slim_rp3beta = SaveResults()\n",
    "\n",
    "optuna_study_slim_rp3beta.optimize(objective_function_slim_rp3beta,\n",
    "                      callbacks=[save_results_slim_rp3beta],\n",
    "                      n_trials = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:13:06.218120Z",
     "iopub.status.busy": "2023-12-08T21:13:06.217605Z",
     "iopub.status.idle": "2023-12-08T21:13:06.223735Z",
     "shell.execute_reply": "2023-12-08T21:13:06.222734Z",
     "shell.execute_reply.started": "2023-12-08T21:13:06.218080Z"
    }
   },
   "outputs": [],
   "source": [
    "#alpha_slim_rp3beta = 0.5815552360509464\n",
    "#alpha_slim_rp3beta = 0.522113314123003\n",
    "alpha_slim_rp3beta = 0.5356582511094522"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_trials = [t for t in optuna_study_slim_rp3beta.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in optuna_study_slim_rp3beta.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(optuna_study_slim_rp3beta.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(\"  Value Validation: \", optuna_study_slim_rp3beta.best_trial.value)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(optuna_study_slim_rp3beta.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def objective_function_hybrid_item_rp3beta(optuna_trial):\n",
    "    alpha = optuna_trial.suggest_float(\"alpha\", 0, 1)\n",
    "    \n",
    "    recommender_instance = ScoresHybridRecommender(urm_train, itemKNN_rp3beta, slim)\n",
    "    recommender_instance.fit(alpha)\n",
    "\n",
    "    result_df, _ = evaluator_validation.evaluateRecommender(recommender_instance)\n",
    "\n",
    "    return result_df.loc[10][\"MAP\"]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim_rp3beta = ItemKNNCustomSimilarityRecommender(urm_train)\n",
    "new_similarity = (1 - alpha_slim_rp3beta) * slim.W_sparse + alpha_slim_rp3beta * rp3beta.W_sparse\n",
    "slim_rp3beta.fit(new_similarity, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df, _ = evaluator_test.evaluateRecommender(slim_rp3beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df, _ = evaluator_validation.evaluateRecommender(slim_rp3beta)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding iALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T18:05:01.400552Z",
     "iopub.status.busy": "2023-12-09T18:05:01.399661Z",
     "iopub.status.idle": "2023-12-09T18:05:06.974398Z",
     "shell.execute_reply": "2023-12-09T18:05:06.973656Z",
     "shell.execute_reply.started": "2023-12-09T18:05:01.400518Z"
    }
   },
   "outputs": [],
   "source": [
    "ials = FastIALSRecommender(urm_train)\n",
    "ials.fit(**IALS_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T18:19:46.765776Z",
     "iopub.status.busy": "2023-12-09T18:19:46.764992Z",
     "iopub.status.idle": "2023-12-09T18:19:46.770844Z",
     "shell.execute_reply": "2023-12-09T18:19:46.769958Z",
     "shell.execute_reply.started": "2023-12-09T18:19:46.765741Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective_function_hybrid(optuna_trial):\n",
    "    alpha = optuna_trial.suggest_float(\"alpha\", 0, 1)\n",
    "    \n",
    "    recommender_instance = ScoresHybridRecommender(urm_train, slim_rp3beta, ials)\n",
    "    recommender_instance.fit(alpha)\n",
    "\n",
    "    result_df, _ = evaluator_validation.evaluateRecommender(recommender_instance)\n",
    "\n",
    "    return result_df.loc[10][\"MAP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T18:19:46.910648Z",
     "iopub.status.busy": "2023-12-09T18:19:46.910320Z",
     "iopub.status.idle": "2023-12-09T18:26:09.319812Z",
     "shell.execute_reply": "2023-12-09T18:26:09.318210Z",
     "shell.execute_reply.started": "2023-12-09T18:19:46.910605Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optuna_study_hybrid = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "save_results_hybrid = SaveResults()\n",
    "\n",
    "optuna_study_hybrid.optimize(objective_function_hybrid,\n",
    "                      callbacks=[save_results_hybrid],\n",
    "                      n_trials = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:13:10.984283Z",
     "iopub.status.busy": "2023-12-08T21:13:10.983893Z",
     "iopub.status.idle": "2023-12-08T21:13:10.994039Z",
     "shell.execute_reply": "2023-12-08T21:13:10.992412Z",
     "shell.execute_reply.started": "2023-12-08T21:13:10.984252Z"
    }
   },
   "outputs": [],
   "source": [
    "urm_full = urm_train+urm_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:13:11.730910Z",
     "iopub.status.busy": "2023-12-08T21:13:11.730443Z",
     "iopub.status.idle": "2023-12-08T21:13:11.759320Z",
     "shell.execute_reply": "2023-12-08T21:13:11.757784Z",
     "shell.execute_reply.started": "2023-12-08T21:13:11.730872Z"
    }
   },
   "outputs": [],
   "source": [
    "top_pop_final = TopPop(urm_full)\n",
    "top_pop_final.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:13:12.783974Z",
     "iopub.status.busy": "2023-12-08T21:13:12.783542Z",
     "iopub.status.idle": "2023-12-08T21:13:29.181070Z",
     "shell.execute_reply": "2023-12-08T21:13:29.179652Z",
     "shell.execute_reply.started": "2023-12-08T21:13:12.783930Z"
    }
   },
   "outputs": [],
   "source": [
    "rp3beta = RP3betaRecommender(urm_full)\n",
    "rp3beta.fit(**RP3Beta_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:13:29.184395Z",
     "iopub.status.busy": "2023-12-08T21:13:29.183841Z",
     "iopub.status.idle": "2023-12-08T21:41:23.187463Z",
     "shell.execute_reply": "2023-12-08T21:41:23.185339Z",
     "shell.execute_reply.started": "2023-12-08T21:13:29.184348Z"
    }
   },
   "outputs": [],
   "source": [
    "slim = MultiThreadSLIM_SLIMElasticNetRecommender(urm_full)\n",
    "slim.fit(**SLIM_params, workers = int(cpu_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:41:23.191527Z",
     "iopub.status.busy": "2023-12-08T21:41:23.190948Z",
     "iopub.status.idle": "2023-12-08T21:41:23.350309Z",
     "shell.execute_reply": "2023-12-08T21:41:23.349107Z",
     "shell.execute_reply.started": "2023-12-08T21:41:23.191475Z"
    }
   },
   "outputs": [],
   "source": [
    "slim_rp3beta = ItemKNNCustomSimilarityRecommender(urm_full)\n",
    "new_similarity = (1 - alpha_slim_rp3beta) * slim.W_sparse + alpha_slim_rp3beta * rp3beta.W_sparse\n",
    "slim_rp3beta.fit(new_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:41:23.354476Z",
     "iopub.status.busy": "2023-12-08T21:41:23.353983Z",
     "iopub.status.idle": "2023-12-08T21:41:23.366760Z",
     "shell.execute_reply": "2023-12-08T21:41:23.365451Z",
     "shell.execute_reply.started": "2023-12-08T21:41:23.354429Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_submission(ratings: pd.DataFrame, users_to_recommend: np.array, urm_train: sps.csr_matrix, recommender: BaseRecommender, recommendation_length):\n",
    "    users_ids_and_mappings = ratings[ratings.user_id.isin(users_to_recommend)][[\"user_id\", \"mapped_user_id\"]].drop_duplicates()\n",
    "    mapping_to_item_id = dict(zip(ratings.mapped_item_id, ratings.item_id))\n",
    "\n",
    "    submission = []\n",
    "\n",
    "    rec_users_arr = users_ids_and_mappings.mapped_user_id.to_numpy()\n",
    "    recommendations = recommender.recommend(user_id_array= rec_users_arr, cutoff=recommendation_length)\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for idx, row in users_ids_and_mappings.iterrows():\n",
    "        user_id = row.user_id\n",
    "        mapped_user_id = row.mapped_user_id\n",
    "\n",
    "        submission.append((user_id, [mapping_to_item_id[item_id] for item_id in recommendations[i]]))\n",
    "        i+=1\n",
    "\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:41:23.369392Z",
     "iopub.status.busy": "2023-12-08T21:41:23.368864Z",
     "iopub.status.idle": "2023-12-08T21:41:23.382726Z",
     "shell.execute_reply": "2023-12-08T21:41:23.381222Z",
     "shell.execute_reply.started": "2023-12-08T21:41:23.369339Z"
    }
   },
   "outputs": [],
   "source": [
    "users_to_recommend = target_dataframe.to_numpy().flatten()\n",
    "users_to_recommend.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:41:23.385157Z",
     "iopub.status.busy": "2023-12-08T21:41:23.384494Z",
     "iopub.status.idle": "2023-12-08T21:41:23.584282Z",
     "shell.execute_reply": "2023-12-08T21:41:23.583322Z",
     "shell.execute_reply.started": "2023-12-08T21:41:23.385104Z"
    }
   },
   "outputs": [],
   "source": [
    "mapping_to_item_id = dict(zip(ratings.mapped_item_id, ratings.item_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:41:23.585929Z",
     "iopub.status.busy": "2023-12-08T21:41:23.585437Z",
     "iopub.status.idle": "2023-12-08T21:41:23.656429Z",
     "shell.execute_reply": "2023-12-08T21:41:23.654578Z",
     "shell.execute_reply.started": "2023-12-08T21:41:23.585882Z"
    }
   },
   "outputs": [],
   "source": [
    "urm_ids = np.unique(ratings.user_id)\n",
    "missing_users = set([i for i in users_to_recommend]) - set([i for i in urm_ids])\n",
    "missing_users = np.array([x for x in missing_users])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:41:23.657933Z",
     "iopub.status.busy": "2023-12-08T21:41:23.657555Z",
     "iopub.status.idle": "2023-12-08T21:41:24.791600Z",
     "shell.execute_reply": "2023-12-08T21:41:24.789433Z",
     "shell.execute_reply.started": "2023-12-08T21:41:23.657901Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir /kaggle/working/Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:41:24.794132Z",
     "iopub.status.busy": "2023-12-08T21:41:24.793670Z",
     "iopub.status.idle": "2023-12-08T21:41:24.801933Z",
     "shell.execute_reply": "2023-12-08T21:41:24.800613Z",
     "shell.execute_reply.started": "2023-12-08T21:41:24.794091Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_submission(submissions, name):\n",
    "    with open(f\"/kaggle/working/Results/{name}.csv\", \"w\") as f:\n",
    "        f.write(\"user_id,item_list\\n\")\n",
    "        for user_id, items in submissions:\n",
    "            f.write(f\"{user_id},{' '.join([str(item) for item in items])}\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:41:24.806474Z",
     "iopub.status.busy": "2023-12-08T21:41:24.805832Z",
     "iopub.status.idle": "2023-12-08T21:41:37.120455Z",
     "shell.execute_reply": "2023-12-08T21:41:37.119147Z",
     "shell.execute_reply.started": "2023-12-08T21:41:24.806429Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = prepare_submission(ratings, users_to_recommend, urm_full, slim_rp3beta, recommendation_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:41:37.122254Z",
     "iopub.status.busy": "2023-12-08T21:41:37.121895Z",
     "iopub.status.idle": "2023-12-08T21:41:37.227015Z",
     "shell.execute_reply": "2023-12-08T21:41:37.225828Z",
     "shell.execute_reply.started": "2023-12-08T21:41:37.122222Z"
    }
   },
   "outputs": [],
   "source": [
    "rec_missing = top_pop_final.recommend(missing_users, cutoff=10, remove_seen_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:41:37.229051Z",
     "iopub.status.busy": "2023-12-08T21:41:37.228626Z",
     "iopub.status.idle": "2023-12-08T21:41:37.237313Z",
     "shell.execute_reply": "2023-12-08T21:41:37.235866Z",
     "shell.execute_reply.started": "2023-12-08T21:41:37.229013Z"
    }
   },
   "outputs": [],
   "source": [
    "for user_id in missing_users:\n",
    "    submission.append((user_id, [mapping_to_item_id[item_id] for item_id in rec_missing[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:41:37.239192Z",
     "iopub.status.busy": "2023-12-08T21:41:37.238831Z",
     "iopub.status.idle": "2023-12-08T21:41:37.252089Z",
     "shell.execute_reply": "2023-12-08T21:41:37.250792Z",
     "shell.execute_reply.started": "2023-12-08T21:41:37.239161Z"
    }
   },
   "outputs": [],
   "source": [
    "(len(submission), len(users_to_recommend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:41:37.254473Z",
     "iopub.status.busy": "2023-12-08T21:41:37.254079Z",
     "iopub.status.idle": "2023-12-08T21:41:37.311038Z",
     "shell.execute_reply": "2023-12-08T21:41:37.309672Z",
     "shell.execute_reply.started": "2023-12-08T21:41:37.254439Z"
    }
   },
   "outputs": [],
   "source": [
    "write_submission(submission, \"slim_rp3beta\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4086250,
     "sourceId": 7091045,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4108263,
     "sourceId": 7122350,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4120115,
     "sourceId": 7139099,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
