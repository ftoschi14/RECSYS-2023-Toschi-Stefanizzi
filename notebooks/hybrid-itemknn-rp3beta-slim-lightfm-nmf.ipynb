{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting-up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/MaurizioFD/RecSys_Course_AT_PoliMi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv RecSys_Course_AT_PoliMi/* /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r ../input/updated-code-3-2/* /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python run_compile_all_cython.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install lightfm tqdm optuna ipykernel matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pyplot\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import loguniform\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score, precision_at_k\n",
    "import time\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../input/updated-code-2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Recommenders.KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "from Recommenders.NonPersonalizedRecommender import TopPop\n",
    "from Recommenders.KNN.UserKNNCFRecommender import UserKNNCFRecommender\n",
    "from Recommenders.GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "from Recommenders.KNN.UserKNNCFRecommender import UserKNNCFRecommender\n",
    "from Recommenders.KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "from Recommenders.KNN.ItemKNNCustomSimilarityRecommender import ItemKNNCustomSimilarityRecommender\n",
    "from Recommenders.MatrixFactorization.NMFRecommender import NMFRecommender\n",
    "\n",
    "#----remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "from Recommenders.SLIM.SLIMElasticNetRecommender import SLIMElasticNetRecommender, MultiThreadSLIM_SLIMElasticNetRecommender\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 69\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training data\n",
    "URM_path = \"../data-books/data_train.csv\"\n",
    "URM_all_dataframe = pd.read_csv(filepath_or_buffer=URM_path,\n",
    "                                header=0,\n",
    "                                dtype={0:int, 1:int, 2:int},\n",
    "                                engine='python')\n",
    "\n",
    "URM_all_dataframe.columns = [\"user_id\", \"item_id\", \"interaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import target users\n",
    "target_path = \"../data-books/data_target_users_test.csv\"\n",
    "target_dataframe= pd.read_csv(filepath_or_buffer=target_path,\n",
    "                                header=0,\n",
    "                                dtype={0:int},\n",
    "                                engine='python')\n",
    "target_dataframe.columns = [\"user_id\"]\n",
    "target_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(ratings: pd.DataFrame):\n",
    "    unique_users = ratings.user_id.unique()\n",
    "    unique_items = ratings.item_id.unique()\n",
    "\n",
    "    num_users, min_user_id, max_user_id = unique_users.size, unique_users.min(), unique_users.max()\n",
    "    num_items, min_item_id, max_item_id = unique_items.size, unique_items.min(), unique_items.max()\n",
    "\n",
    "    print(num_users, min_user_id, max_user_id)\n",
    "    print(num_items, min_item_id, max_item_id)\n",
    "\n",
    "    mapping_user_id = pd.DataFrame({\"mapped_user_id\": np.arange(num_users), \"user_id\": unique_users})\n",
    "    mapping_item_id = pd.DataFrame({\"mapped_item_id\": np.arange(num_items), \"item_id\": unique_items})\n",
    "\n",
    "    ratings = pd.merge(left=ratings,\n",
    "                       right=mapping_user_id,\n",
    "                       how=\"inner\",\n",
    "                       on=\"user_id\")\n",
    "\n",
    "    ratings = pd.merge(left=ratings,\n",
    "                       right=mapping_item_id,\n",
    "                       how=\"inner\",\n",
    "                       on=\"item_id\")\n",
    "\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call preprocess data function\n",
    "ratings = preprocess_data(URM_all_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From DF to Sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URM = sps.coo_matrix((ratings.interaction.values, (ratings.mapped_user_id.values, ratings.mapped_item_id.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urm_train, urm_test = split_train_in_two_percentage_global_sample(URM, train_percentage = 0.80)\n",
    "urm_train, urm_validation = split_train_in_two_percentage_global_sample(urm_train, train_percentage = 0.80)\n",
    "\n",
    "evaluator_validation = EvaluatorHoldout(urm_validation, cutoff_list=[10])\n",
    "evaluator_test = EvaluatorHoldout(urm_test, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoresHybridRecommender(BaseRecommender):\n",
    "    \"\"\" ScoresHybridRecommender\n",
    "    Hybrid of two prediction scores R = R1*alpha + R2*(1-alpha)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"ScoresHybridRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, recommender_1, recommender_2):\n",
    "        super(ScoresHybridRecommender, self).__init__(URM_train)\n",
    "\n",
    "        self.URM_train = sps.csr_matrix(URM_train)\n",
    "        self.recommender_1 = recommender_1\n",
    "        self.recommender_2 = recommender_2\n",
    "\n",
    "\n",
    "    def fit(self, alpha=0.5):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute):\n",
    "\n",
    "        # In a simple extension this could be a loop over a list of pretrained recommender objects\n",
    "        item_weights_1 = self.recommender_1._compute_item_score(user_id_array)\n",
    "        item_weights_2 = self.recommender_2._compute_item_score(user_id_array)\n",
    "\n",
    "        item_weights = item_weights_1*self.alpha + item_weights_2*(1-self.alpha)\n",
    "\n",
    "        return item_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightFMCFRecommender(BaseRecommender):\n",
    "    \"\"\"LightFMCFRecommender\"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"LightFMCFRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train):\n",
    "        super(LightFMCFRecommender, self).__init__(URM_train)\n",
    "    \n",
    "    \n",
    "    def fit(self, epochs = 300, user_alpha=1e-6, item_alpha = 1e-6, n_factors = 10, n_threads = 4, max_sampled=3, loss='warp', learning_schedule='adagrad'):\n",
    "        \n",
    "        # Let's fit a WARP model\n",
    "        self.lightFM_model = LightFM(loss=loss,\n",
    "                                     user_alpha=user_alpha,\n",
    "                                     item_alpha=item_alpha,\n",
    "                                     no_components=n_factors,\n",
    "                                     max_sampled=max_sampled,\n",
    "                                     learning_schedule=learning_schedule)\n",
    "\n",
    "        self.lightFM_model = self.lightFM_model.fit(self.URM_train, \n",
    "                                       epochs=epochs,\n",
    "                                       num_threads=n_threads,\n",
    "                                       verbose=True)\n",
    "\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute = None):\n",
    "        \n",
    "        # Create a single (n_items, ) array with the item score, then copy it for every user\n",
    "        items_to_compute = np.arange(self.n_items)\n",
    "        \n",
    "        item_scores = - np.ones((len(user_id_array), self.n_items)) * np.inf\n",
    "\n",
    "        for user_index, user_id in enumerate(user_id_array):\n",
    "            item_scores[user_index] = self.lightFM_model.predict(int(user_id), \n",
    "                                                                 items_to_compute)\n",
    "\n",
    "        return item_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "\n",
    "class GeneralizedLinearHybridRecommender(BaseRecommender):\n",
    "    \"\"\"\n",
    "    This recommender merges N recommendes by weighting their ratings\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"GeneralizedLinearHybridRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, recommenders: list, verbose=True):\n",
    "        self.RECOMMENDER_NAME = ''\n",
    "        for recommender in recommenders:\n",
    "            self.RECOMMENDER_NAME = self.RECOMMENDER_NAME + recommender.RECOMMENDER_NAME[:-11]\n",
    "        self.RECOMMENDER_NAME = self.RECOMMENDER_NAME + 'HybridRecommender'\n",
    "\n",
    "        super(GeneralizedLinearHybridRecommender, self).__init__(URM_train, verbose=verbose)\n",
    "\n",
    "        self.recommenders = recommenders\n",
    "\n",
    "    def fit(self, alphas=None):\n",
    "        self.alphas = alphas\n",
    "\n",
    "    def save_model(self, folder_path, file_name=None):\n",
    "        pass\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute=None):\n",
    "        result = self.alphas[0]*self.recommenders[0]._compute_item_score(user_id_array,items_to_compute)\n",
    "        for index in range(1,len(self.alphas)):\n",
    "            result = result + self.alphas[index]*self.recommenders[index]._compute_item_score(user_id_array,items_to_compute)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ItemKNN_params = {\n",
    "    'topK': 11,\n",
    "    'shrink': 8\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ItemKNN_params = {\n",
    "    'topK': 6,\n",
    "    'shrink': 15,\n",
    "    'similarity': 'jaccard',\n",
    "    'normalize': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RP3beta_params = {\n",
    "    'alpha': 0.307953246083667, \n",
    "    'beta': 0.3073797221110665, \n",
    "    'topK': 59, \n",
    "    'normalize_similarity': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha_itemknn_rp3beta=0.8726915476982722"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_itemknn_rp3beta=0.7381515719042592"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''UserKNN_params = {\n",
    "    'shrink':0,\n",
    "    'topK':313\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserKNN_params = {\n",
    "    'topK': 470,\n",
    "    'shrink': 0,\n",
    "    'similarity': 'cosine',\n",
    "    'normalize': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''LightFM_params = {\n",
    "    'alpha': 9.874597034935863e-05,\n",
    "    'n_factors': 365,\n",
    "    'max_sampled':3,\n",
    "    'loss':'warp',\n",
    "    'learning_schedule':'adagrad'\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LightFM_params = {\n",
    "                  'n_factors': 482,\n",
    "                  'max_sampled': 5,\n",
    "                  'user_alpha': 0.00023989649900734266,\n",
    "                  'item_alpha': 9.740651135253414e-05\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLIM_params = {\n",
    "    'l1_ratio': 0.013752256221164005,\n",
    "    'alpha': 0.0031943927190071775,\n",
    "    'topK': 622\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMF_params = {\n",
    "    'l1_ratio': 0.005734775635120469,\n",
    "    'num_factors': 134,\n",
    "    'beta_loss': 'frobenius',\n",
    "    'init_type': 'nndsvda',\n",
    "    'solver': 'multiplicative_update'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemKNNCF = ItemKNNCFRecommender(urm_train)\n",
    "itemKNNCF.fit(**ItemKNN_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp3beta = RP3betaRecommender(urm_train)\n",
    "rp3beta.fit(**RP3beta_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_similarity = (1 - alpha_itemknn_rp3beta) * itemKNNCF.W_sparse + alpha_itemknn_rp3beta * rp3beta.W_sparse\n",
    "    \n",
    "itemKNN_rp3beta = ItemKNNCustomSimilarityRecommender(urm_train)\n",
    "itemKNN_rp3beta.fit(new_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#userKNNCF = UserKNNCFRecommender(urm_train)\n",
    "#userKNNCF.fit(**UserKNN_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightfm = LightFMCFRecommender(urm_train)\n",
    "lightfm.fit(**LightFM_params, n_threads=int(cpu_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim = MultiThreadSLIM_SLIMElasticNetRecommender(urm_train)\n",
    "slim.fit(**SLIM_params, workers = int(cpu_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMFRecommender(urm_train)\n",
    "nmf_model.fit(**NMF_params, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/kaggle/working/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Alpha for full hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveResults(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.results_df = pd.DataFrame(columns=[\"result\"])\n",
    "\n",
    "    def __call__(self, optuna_study, optuna_trial):\n",
    "        hyperparam_dict = optuna_trial.params.copy()\n",
    "        hyperparam_dict[\"result\"] = optuna_trial.values[0]\n",
    "\n",
    "        # Create a DataFrame from the current trial's results\n",
    "        trial_df = pd.DataFrame([hyperparam_dict])\n",
    "\n",
    "        # Use concat instead of append\n",
    "        self.results_df = pd.concat([self.results_df, trial_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommenders = [itemKNN_rp3beta, slim, lightfm, nmf_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_hybrid_full(optuna_trial):\n",
    "    alphas = [\n",
    "        optuna_trial.suggest_float(\"alpha_itemKNN_rp3beta\", 0, 2),\n",
    "        optuna_trial.suggest_float(\"alpha_SLIM\", 0, 2),\n",
    "        optuna_trial.suggest_float(\"alpha_lightfm\", 0, 2),\n",
    "        optuna_trial.suggest_float(\"alpha_nmf\", 0, 2)\n",
    "    ]\n",
    "    recommender_instance = GeneralizedLinearHybridRecommender(URM_train=urm_train, recommenders=recommenders)\n",
    "    recommender_instance.fit(\n",
    "                             alphas\n",
    "                            )\n",
    "\n",
    "    result_df, _ = evaluator_validation.evaluateRecommender(recommender_instance)\n",
    "\n",
    "    return result_df.loc[10][\"MAP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optuna_study_hybrid_full = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "save_results_hybrid_full = SaveResults()\n",
    "\n",
    "optuna_study_hybrid_full.optimize(objective_function_hybrid_full,\n",
    "                      callbacks=[save_results_hybrid_full],\n",
    "                      n_trials = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Trial 43 finished with value: 0.0317516106162691 and parameters: {'alpha_itemKNN_rp3beta': 1.4677480416401336, 'alpha_SLIM': 1.0085607578989502, 'alpha_lightfm': 0.08166189287323965, 'alpha_nmf': 0.005271968578302977}. Best is trial 43 with value: 0.0317516106162691."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_trials = [t for t in optuna_study_hybrid_full.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in optuna_study_hybrid_full.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(optuna_study_hybrid_full.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(\"  Value Validation: \", optuna_study_hybrid_full.best_trial.value)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(optuna_study_hybrid_full.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(optuna_study_hybrid_full.best_trial.params.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'alpha_itemKNN_rp3beta': 1.4677480416401336, 'alpha_SLIM': 1.0085607578989502, 'alpha_lightfm': 0.08166189287323965, 'alpha_nmf': 0.005271968578302977}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid = GeneralizedLinearHybridRecommender(URM_train=urm_train+urm_validation, recommenders=recommenders)\n",
    "hybrid.fit(list(alphas.values())) # TODO fix here if change fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df, _ = evaluator_test.evaluateRecommender(hybrid)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urm_full = urm_train+urm_validation+urm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_pop_final = TopPop(urm_full)\n",
    "top_pop_final.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemKNNCF = ItemKNNCFRecommender(urm_full)\n",
    "itemKNNCF.fit(**ItemKNN_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp3beta = RP3betaRecommender(urm_full)\n",
    "rp3beta.fit(**RP3beta_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userKNNCF = UserKNNCFRecommender(urm_full)\n",
    "userKNNCF.fit(**UserKNN_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_similarity = (1 - alpha_itemknn_rp3beta) * itemKNNCF.W_sparse + alpha_itemknn_rp3beta * rp3beta.W_sparse\n",
    "    \n",
    "itemKNN_rp3beta = ItemKNNCustomSimilarityRecommender(urm_full)\n",
    "itemKNN_rp3beta.fit(new_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightfm = LightFMCFRecommender(urm_full)\n",
    "lightfm.fit(**LightFM_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim = MultiThreadSLIM_SLIMElasticNetRecommender(urm_full)\n",
    "slim.fit(**SLIM_params, workers = int(cpu_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMFRecommender(urm_full)\n",
    "nmf_model.fit(**NMF_params, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommenders = [itemKNN_rp3beta, slim, lightfm, nmf_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid = GeneralizedLinearHybridRecommender(URM_train=urm_full, recommenders=recommenders)\n",
    "hybrid.fit(list(alphas.values())) # TODO fix here if change fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_submission(ratings: pd.DataFrame, users_to_recommend: np.array, urm_train: sps.csr_matrix, recommender: BaseRecommender, recommendation_length):\n",
    "    users_ids_and_mappings = ratings[ratings.user_id.isin(users_to_recommend)][[\"user_id\", \"mapped_user_id\"]].drop_duplicates()\n",
    "    mapping_to_item_id = dict(zip(ratings.mapped_item_id, ratings.item_id))\n",
    "\n",
    "    submission = []\n",
    "\n",
    "    rec_users_arr = users_ids_and_mappings.mapped_user_id.to_numpy()\n",
    "    recommendations = recommender.recommend(user_id_array= rec_users_arr, cutoff=recommendation_length)\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for idx, row in users_ids_and_mappings.iterrows():\n",
    "        user_id = row.user_id\n",
    "        mapped_user_id = row.mapped_user_id\n",
    "\n",
    "        submission.append((user_id, [mapping_to_item_id[item_id] for item_id in recommendations[i]]))\n",
    "        i+=1\n",
    "\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_to_recommend = target_dataframe.to_numpy().flatten()\n",
    "users_to_recommend.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_to_item_id = dict(zip(ratings.mapped_item_id, ratings.item_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urm_ids = np.unique(ratings.user_id)\n",
    "missing_users = set([i for i in users_to_recommend]) - set([i for i in urm_ids])\n",
    "missing_users = np.array([x for x in missing_users])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission(submissions, name):\n",
    "    with open(f\"/kaggle/working/Results/{name}.csv\", \"w\") as f:\n",
    "        f.write(\"user_id,item_list\\n\")\n",
    "        for user_id, items in submissions:\n",
    "            f.write(f\"{user_id},{' '.join([str(item) for item in items])}\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = prepare_submission(ratings, users_to_recommend, urm_full, hybrid, recommendation_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_missing = top_pop_final.recommend(missing_users, cutoff=10, remove_seen_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_id in missing_users:\n",
    "  submission.append((user_id, [mapping_to_item_id[item_id] for item_id in rec_missing[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(submission), len(users_to_recommend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission(submission, \"submission_hybrid_4-fold_slim_nmf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4086250,
     "sourceId": 7091045,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4092853,
     "sourceId": 7100247,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4108263,
     "sourceId": 7122350,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
