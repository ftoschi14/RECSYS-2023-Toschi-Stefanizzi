{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting-up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:46:43.293389Z",
     "iopub.status.busy": "2023-12-04T17:46:43.292832Z",
     "iopub.status.idle": "2023-12-04T17:46:46.718866Z",
     "shell.execute_reply": "2023-12-04T17:46:46.717704Z",
     "shell.execute_reply.started": "2023-12-04T17:46:43.293348Z"
    }
   },
   "outputs": [],
   "source": [
    "!cp -r ../input/updated-code-3/* /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python run_compile_all_cython.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:46:46.721256Z",
     "iopub.status.busy": "2023-12-04T17:46:46.720960Z",
     "iopub.status.idle": "2023-12-04T17:47:08.316962Z",
     "shell.execute_reply": "2023-12-04T17:47:08.315799Z",
     "shell.execute_reply.started": "2023-12-04T17:46:46.721225Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install lightfm tqdm optuna ipykernel matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:47:08.318725Z",
     "iopub.status.busy": "2023-12-04T17:47:08.318413Z",
     "iopub.status.idle": "2023-12-04T17:47:20.348908Z",
     "shell.execute_reply": "2023-12-04T17:47:20.347828Z",
     "shell.execute_reply.started": "2023-12-04T17:47:08.318694Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:47:20.351553Z",
     "iopub.status.busy": "2023-12-04T17:47:20.351220Z",
     "iopub.status.idle": "2023-12-04T17:47:22.544515Z",
     "shell.execute_reply": "2023-12-04T17:47:22.543093Z",
     "shell.execute_reply.started": "2023-12-04T17:47:20.351526Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pyplot\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import loguniform\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score, precision_at_k\n",
    "import time\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:47:22.547920Z",
     "iopub.status.busy": "2023-12-04T17:47:22.545916Z",
     "iopub.status.idle": "2023-12-04T17:47:23.294858Z",
     "shell.execute_reply": "2023-12-04T17:47:23.293862Z",
     "shell.execute_reply.started": "2023-12-04T17:47:22.547878Z"
    }
   },
   "outputs": [],
   "source": [
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "from Recommenders.Similarity.Compute_Similarity_Python import Compute_Similarity_Python\n",
    "from Recommenders.MatrixFactorization.PureSVDRecommender import PureSVDRecommender\n",
    "from Recommenders.MatrixFactorization.NMFRecommender import NMFRecommender\n",
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "from Recommenders.BaseMatrixFactorizationRecommender import BaseMatrixFactorizationRecommender\n",
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "\n",
    "import implicit\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "#----remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:47:23.298191Z",
     "iopub.status.busy": "2023-12-04T17:47:23.297413Z",
     "iopub.status.idle": "2023-12-04T17:47:23.302703Z",
     "shell.execute_reply": "2023-12-04T17:47:23.301724Z",
     "shell.execute_reply.started": "2023-12-04T17:47:23.298152Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 69\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:47:23.304482Z",
     "iopub.status.busy": "2023-12-04T17:47:23.304138Z",
     "iopub.status.idle": "2023-12-04T17:47:26.359316Z",
     "shell.execute_reply": "2023-12-04T17:47:26.358504Z",
     "shell.execute_reply.started": "2023-12-04T17:47:23.304451Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import training data\n",
    "URM_path = \"../input/data-books/data_train.csv\"\n",
    "URM_all_dataframe = pd.read_csv(filepath_or_buffer=URM_path,\n",
    "                                header=0,\n",
    "                                dtype={0:int, 1:int, 2:int},\n",
    "                                engine='python')\n",
    "\n",
    "URM_all_dataframe.columns = [\"user_id\", \"item_id\", \"interaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:47:26.360683Z",
     "iopub.status.busy": "2023-12-04T17:47:26.360390Z",
     "iopub.status.idle": "2023-12-04T17:47:26.418888Z",
     "shell.execute_reply": "2023-12-04T17:47:26.417938Z",
     "shell.execute_reply.started": "2023-12-04T17:47:26.360656Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import target users\n",
    "target_path = \"../input/data-books/data_target_users_test.csv\"\n",
    "target_dataframe= pd.read_csv(filepath_or_buffer=target_path,\n",
    "                                header=0,\n",
    "                                dtype={0:int},\n",
    "                                engine='python')\n",
    "target_dataframe.columns = [\"user_id\"]\n",
    "target_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:47:26.420647Z",
     "iopub.status.busy": "2023-12-04T17:47:26.420127Z",
     "iopub.status.idle": "2023-12-04T17:47:26.429231Z",
     "shell.execute_reply": "2023-12-04T17:47:26.428314Z",
     "shell.execute_reply.started": "2023-12-04T17:47:26.420612Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(ratings: pd.DataFrame):\n",
    "    unique_users = ratings.user_id.unique()\n",
    "    unique_items = ratings.item_id.unique()\n",
    "\n",
    "    num_users, min_user_id, max_user_id = unique_users.size, unique_users.min(), unique_users.max()\n",
    "    num_items, min_item_id, max_item_id = unique_items.size, unique_items.min(), unique_items.max()\n",
    "\n",
    "    print(num_users, min_user_id, max_user_id)\n",
    "    print(num_items, min_item_id, max_item_id)\n",
    "\n",
    "    mapping_user_id = pd.DataFrame({\"mapped_user_id\": np.arange(num_users), \"user_id\": unique_users})\n",
    "    mapping_item_id = pd.DataFrame({\"mapped_item_id\": np.arange(num_items), \"item_id\": unique_items})\n",
    "\n",
    "    ratings = pd.merge(left=ratings,\n",
    "                       right=mapping_user_id,\n",
    "                       how=\"inner\",\n",
    "                       on=\"user_id\")\n",
    "\n",
    "    ratings = pd.merge(left=ratings,\n",
    "                       right=mapping_item_id,\n",
    "                       how=\"inner\",\n",
    "                       on=\"item_id\")\n",
    "\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:47:26.432813Z",
     "iopub.status.busy": "2023-12-04T17:47:26.432435Z",
     "iopub.status.idle": "2023-12-04T17:47:26.567117Z",
     "shell.execute_reply": "2023-12-04T17:47:26.566126Z",
     "shell.execute_reply.started": "2023-12-04T17:47:26.432787Z"
    }
   },
   "outputs": [],
   "source": [
    "# Call preprocess data function\n",
    "ratings = preprocess_data(URM_all_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From DF to Sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:47:26.568553Z",
     "iopub.status.busy": "2023-12-04T17:47:26.568239Z",
     "iopub.status.idle": "2023-12-04T17:47:26.575223Z",
     "shell.execute_reply": "2023-12-04T17:47:26.574234Z",
     "shell.execute_reply.started": "2023-12-04T17:47:26.568526Z"
    }
   },
   "outputs": [],
   "source": [
    "URM = sps.coo_matrix((ratings.interaction.values, (ratings.mapped_user_id.values, ratings.mapped_item_id.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:47:26.576712Z",
     "iopub.status.busy": "2023-12-04T17:47:26.576390Z",
     "iopub.status.idle": "2023-12-04T17:47:28.744165Z",
     "shell.execute_reply": "2023-12-04T17:47:28.743143Z",
     "shell.execute_reply.started": "2023-12-04T17:47:26.576686Z"
    }
   },
   "outputs": [],
   "source": [
    "urm_train, urm_test = split_train_in_two_percentage_global_sample(URM, train_percentage = 0.80)\n",
    "urm_train, urm_validation = split_train_in_two_percentage_global_sample(urm_train, train_percentage = 0.80)\n",
    "\n",
    "evaluator_validation = EvaluatorHoldout(urm_validation, cutoff_list=[10])\n",
    "evaluator_test = EvaluatorHoldout(urm_test, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:47:28.745892Z",
     "iopub.status.busy": "2023-12-04T17:47:28.745525Z",
     "iopub.status.idle": "2023-12-04T17:47:28.753645Z",
     "shell.execute_reply": "2023-12-04T17:47:28.752712Z",
     "shell.execute_reply.started": "2023-12-04T17:47:28.745855Z"
    }
   },
   "outputs": [],
   "source": [
    "class ScoresHybridRecommender(BaseRecommender):\n",
    "    \"\"\" ScoresHybridRecommender\n",
    "    Hybrid of two prediction scores R = R1*alpha + R2*(1-alpha)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"ScoresHybridRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, recommender_1, recommender_2):\n",
    "        super(ScoresHybridRecommender, self).__init__(URM_train)\n",
    "\n",
    "        self.URM_train = sps.csr_matrix(URM_train)\n",
    "        self.recommender_1 = recommender_1\n",
    "        self.recommender_2 = recommender_2\n",
    "\n",
    "\n",
    "    def fit(self, alpha=0.5):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute):\n",
    "\n",
    "        # In a simple extension this could be a loop over a list of pretrained recommender objects\n",
    "        item_weights_1 = self.recommender_1._compute_item_score(user_id_array)\n",
    "        item_weights_2 = self.recommender_2._compute_item_score(user_id_array)\n",
    "\n",
    "        item_weights = item_weights_1*self.alpha + item_weights_2*(1-self.alpha)\n",
    "\n",
    "        return item_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:47:28.755121Z",
     "iopub.status.busy": "2023-12-04T17:47:28.754794Z",
     "iopub.status.idle": "2023-12-04T17:47:28.771178Z",
     "shell.execute_reply": "2023-12-04T17:47:28.770401Z",
     "shell.execute_reply.started": "2023-12-04T17:47:28.755085Z"
    }
   },
   "outputs": [],
   "source": [
    "class LightFMCFRecommender(BaseRecommender):\n",
    "    \"\"\"LightFMCFRecommender\"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"LightFMCFRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train):\n",
    "        super(LightFMCFRecommender, self).__init__(URM_train)\n",
    "    \n",
    "    \n",
    "    def fit(self, epochs = 300, alpha = 1e-6, n_factors = 10, n_threads = 4, max_sampled=3, loss='warp', learning_schedule='adagrad'):\n",
    "        \n",
    "        # Let's fit a WARP model\n",
    "        self.lightFM_model = LightFM(loss=loss,\n",
    "                                     item_alpha=alpha,\n",
    "                                     no_components=n_factors,\n",
    "                                     max_sampled=max_sampled,\n",
    "                                     learning_schedule=learning_schedule)\n",
    "\n",
    "        self.lightFM_model = self.lightFM_model.fit(self.URM_train, \n",
    "                                       epochs=epochs,\n",
    "                                       num_threads=n_threads,\n",
    "                                       verbose=True)\n",
    "\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute = None):\n",
    "        \n",
    "        # Create a single (n_items, ) array with the item score, then copy it for every user\n",
    "        items_to_compute = np.arange(self.n_items)\n",
    "        \n",
    "        item_scores = - np.ones((len(user_id_array), self.n_items)) * np.inf\n",
    "\n",
    "        for user_index, user_id in enumerate(user_id_array):\n",
    "            item_scores[user_index] = self.lightFM_model.predict(int(user_id), \n",
    "                                                                 items_to_compute)\n",
    "\n",
    "        return item_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:47:28.772803Z",
     "iopub.status.busy": "2023-12-04T17:47:28.772442Z",
     "iopub.status.idle": "2023-12-04T17:47:28.787047Z",
     "shell.execute_reply": "2023-12-04T17:47:28.786142Z",
     "shell.execute_reply.started": "2023-12-04T17:47:28.772771Z"
    }
   },
   "outputs": [],
   "source": [
    "# !/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "\n",
    "class GeneralizedLinearHybridRecommender(BaseRecommender):\n",
    "    \"\"\"\n",
    "    This recommender merges N recommendes by weighting their ratings\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"GeneralizedLinearHybridRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, recommenders: list, verbose=True):\n",
    "        self.RECOMMENDER_NAME = ''\n",
    "        for recommender in recommenders:\n",
    "            self.RECOMMENDER_NAME = self.RECOMMENDER_NAME + recommender.RECOMMENDER_NAME[:-11]\n",
    "        self.RECOMMENDER_NAME = self.RECOMMENDER_NAME + 'HybridRecommender'\n",
    "\n",
    "        super(GeneralizedLinearHybridRecommender, self).__init__(URM_train, verbose=verbose)\n",
    "\n",
    "        self.recommenders = recommenders\n",
    "\n",
    "    def fit(self, alphas=None):\n",
    "        self.alphas = alphas\n",
    "\n",
    "    def save_model(self, folder_path, file_name=None):\n",
    "        pass\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute=None):\n",
    "        result = self.alphas[0]*self.recommenders[0]._compute_item_score(user_id_array,items_to_compute)\n",
    "        for index in range(1,len(self.alphas)):\n",
    "            result = result + self.alphas[index]*self.recommenders[index]._compute_item_score(user_id_array,items_to_compute)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:48:29.177081Z",
     "iopub.status.busy": "2023-12-04T17:48:29.176490Z",
     "iopub.status.idle": "2023-12-04T17:48:29.194422Z",
     "shell.execute_reply": "2023-12-04T17:48:29.193518Z",
     "shell.execute_reply.started": "2023-12-04T17:48:29.177046Z"
    }
   },
   "outputs": [],
   "source": [
    "from Recommenders.Recommender_utils import check_matrix\n",
    "from implicit.utils import check_csr\n",
    "\n",
    "class FastIALSRecommender(BaseMatrixFactorizationRecommender):\n",
    "    RECOMMENDER_NAME = \"FastIALSRecommender\"\n",
    "\n",
    "    AVAILABLE_CONFIDENCE_SCALING = [\"linear\", \"log\"]\n",
    "    \n",
    "    def __init__(self, URM_train, verbose=True):\n",
    "        super().__init__(URM_train, verbose=verbose)\n",
    "        \n",
    "    def fit(self,\n",
    "            factors=20,\n",
    "            regularization=1e-3,\n",
    "            iterations=100,\n",
    "            calculate_training_loss=False,\n",
    "            num_threads=0,\n",
    "            confidence_scaling='linear',\n",
    "            alpha=1.0,\n",
    "            epsilon=0,\n",
    "            #---- Do not change\n",
    "            use_native=True,\n",
    "            use_cg=True,\n",
    "            use_gpu=True):\n",
    "        if confidence_scaling not in self.AVAILABLE_CONFIDENCE_SCALING:\n",
    "           raise ValueError(\"Value for 'confidence_scaling' not recognized. Acceptable values are {}, provided was '{}'\".format(self.AVAILABLE_CONFIDENCE_SCALING, confidence_scaling))\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.num_factors = factors\n",
    "        self.reg = regularization\n",
    "        \n",
    "        self.USER_factors = self._init_factors(self.n_users, False)  # don't need values, will compute them\n",
    "        self.ITEM_factors = self._init_factors(self.n_items)\n",
    "        \n",
    "        self.recommender = AlternatingLeastSquares(factors=factors, regularization=regularization,\n",
    "                                                        use_native=use_native, use_cg=use_cg, use_gpu=use_gpu,\n",
    "                                                        iterations=iterations,\n",
    "                                                        calculate_training_loss=calculate_training_loss,\n",
    "                                                        num_threads=num_threads)\n",
    "        \n",
    "        self._build_confidence_matrix(confidence_scaling)\n",
    "        self.recommender.fit(self.C, show_progress=self.verbose)\n",
    "        \n",
    "        self.USER_factors = self.recommender.user_factors.to_numpy()\n",
    "        self.ITEM_factors = self.recommender.item_factors.to_numpy()\n",
    "        \n",
    "    \n",
    "    def _linear_scaling_confidence(self):\n",
    "\n",
    "        C = check_matrix(self.URM_train, format=\"csr\", dtype = np.float32)\n",
    "        C.data = 1.0 + self.alpha*C.data\n",
    "\n",
    "        return C\n",
    "\n",
    "    def _log_scaling_confidence(self):\n",
    "\n",
    "        C = check_matrix(self.URM_train, format=\"csr\", dtype = np.float32)\n",
    "        C.data = 1.0 + self.alpha * np.log(1.0 + C.data / self.epsilon)\n",
    "\n",
    "        return C\n",
    "    \n",
    "    def _build_confidence_matrix(self, confidence_scaling):\n",
    "\n",
    "        if confidence_scaling == 'linear':\n",
    "            self.C = self._linear_scaling_confidence()\n",
    "        else:\n",
    "            self.C = self._log_scaling_confidence()\n",
    "\n",
    "        self.C_csc= check_matrix(self.C.copy(), format=\"csc\", dtype = np.float32)\n",
    "    \n",
    "    def _init_factors(self, num_factors, assign_values=True):\n",
    "\n",
    "        if assign_values:\n",
    "            return self.num_factors**-0.5*np.random.random_sample((num_factors, self.num_factors))\n",
    "\n",
    "        else:\n",
    "            return np.empty((num_factors, self.num_factors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:47:28.808562Z",
     "iopub.status.busy": "2023-12-04T17:47:28.808239Z",
     "iopub.status.idle": "2023-12-04T17:47:28.821388Z",
     "shell.execute_reply": "2023-12-04T17:47:28.820513Z",
     "shell.execute_reply.started": "2023-12-04T17:47:28.808537Z"
    }
   },
   "outputs": [],
   "source": [
    "ItemKNN_params = {\n",
    "    'topK': 11,\n",
    "    'shrink': 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RP3beta_params = {\n",
    "    'alpha': 0.307953246083667, \n",
    "    'beta': 0.3073797221110665, \n",
    "    'topK': 59, \n",
    "    'normalize_similarity': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_itemknn_rp3beta=0.8726915476982722"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserKNN_params = {\n",
    "    'shrink':0,\n",
    "    'topK':313\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LightFM_params = {\n",
    "    'alpha': 9.874597034935863e-05,\n",
    "    'n_factors': 365,\n",
    "    'max_sampled':3,\n",
    "    'loss':'warp',\n",
    "    'learning_schedule':'adagrad'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning IALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:47:28.822887Z",
     "iopub.status.busy": "2023-12-04T17:47:28.822609Z",
     "iopub.status.idle": "2023-12-04T17:47:28.832075Z",
     "shell.execute_reply": "2023-12-04T17:47:28.831151Z",
     "shell.execute_reply.started": "2023-12-04T17:47:28.822863Z"
    }
   },
   "outputs": [],
   "source": [
    "class SaveResults(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.results_df = pd.DataFrame(columns=[\"result\"])\n",
    "\n",
    "    def __call__(self, optuna_study, optuna_trial):\n",
    "        hyperparam_dict = optuna_trial.params.copy()\n",
    "        hyperparam_dict[\"result\"] = optuna_trial.values[0]\n",
    "\n",
    "        # Create a DataFrame from the current trial's results\n",
    "        trial_df = pd.DataFrame([hyperparam_dict])\n",
    "\n",
    "        # Use concat instead of append\n",
    "        self.results_df = pd.concat([self.results_df, trial_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:48:38.777911Z",
     "iopub.status.busy": "2023-12-04T17:48:38.777146Z",
     "iopub.status.idle": "2023-12-04T17:48:38.784391Z",
     "shell.execute_reply": "2023-12-04T17:48:38.783421Z",
     "shell.execute_reply.started": "2023-12-04T17:48:38.777877Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective_function_IALS(optuna_trial):\n",
    "    confidence = optuna_trial.suggest_categorical(\"confidence_scaling\", [\"linear\", \"log\"])\n",
    "    epsilon = 0\n",
    "    if confidence == \"log\":\n",
    "        epsilon = optuna_trial.suggest_float(\"epsilon\", 0, 2)\n",
    "    recommender_instance = FastIALSRecommender(urm_train)\n",
    "    recommender_instance.fit(\n",
    "                             factors = optuna_trial.suggest_int(\"factors\", 5, 800),\n",
    "                             regularization = optuna_trial.suggest_float(\"regularization\", 1e-5, 1e-2),\n",
    "                             confidence_scaling = confidence,\n",
    "                             alpha = optuna_trial.suggest_float(\"alpha\", 0, 2),\n",
    "                             epsilon = epsilon,\n",
    "                             iterations=300\n",
    "                            )\n",
    "\n",
    "    result_df, _ = evaluator_validation.evaluateRecommender(recommender_instance)\n",
    "\n",
    "    return result_df.loc[10][\"MAP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:48:39.222551Z",
     "iopub.status.busy": "2023-12-04T17:48:39.221869Z",
     "iopub.status.idle": "2023-12-04T19:19:00.069635Z",
     "shell.execute_reply": "2023-12-04T19:19:00.068425Z",
     "shell.execute_reply.started": "2023-12-04T17:48:39.222515Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optuna_study_IALS = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "save_results_IALS = SaveResults()\n",
    "\n",
    "optuna_study_IALS.optimize(objective_function_IALS,\n",
    "                      callbacks=[save_results_IALS],\n",
    "                      n_trials = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T19:29:29.866519Z",
     "iopub.status.busy": "2023-12-04T19:29:29.866077Z",
     "iopub.status.idle": "2023-12-04T19:29:30.155221Z",
     "shell.execute_reply": "2023-12-04T19:29:30.154160Z",
     "shell.execute_reply.started": "2023-12-04T19:29:29.866485Z"
    }
   },
   "outputs": [],
   "source": [
    "pruned_trials = [t for t in optuna_study_IALS.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in optuna_study_IALS.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(optuna_study_IALS.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(\"  Value Validation: \", optuna_study_IALS.best_trial.value)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(optuna_study_IALS.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'reg': 0.005734775635120469, 'num_factors': 134, 'beta_loss': 'frobenius', 'init_type': 'nndsvda', 'solver': 'multiplicative_update'}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'confidence_scaling': 'log', 'epsilon': 0.11624415533664904, 'factors': 116, 'regularization': 0.005454427904241962, 'alpha': 1.7221339971074425}"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4086250,
     "sourceId": 7091045,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4092819,
     "sourceId": 7100193,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4106581,
     "sourceId": 7120033,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
