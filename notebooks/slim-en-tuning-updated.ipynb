{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting-up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-20T20:26:59.101375Z",
     "iopub.status.busy": "2023-12-20T20:26:59.100879Z",
     "iopub.status.idle": "2023-12-20T20:27:03.927531Z",
     "shell.execute_reply": "2023-12-20T20:27:03.925783Z",
     "shell.execute_reply.started": "2023-12-20T20:26:59.101313Z"
    }
   },
   "outputs": [],
   "source": [
    "!cp -r ../input/updated-code-3-7/* /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T11:07:57.930928Z",
     "iopub.status.busy": "2023-12-07T11:07:57.930549Z",
     "iopub.status.idle": "2023-12-07T11:08:37.193269Z",
     "shell.execute_reply": "2023-12-07T11:08:37.191774Z",
     "shell.execute_reply.started": "2023-12-07T11:07:57.930893Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:03.930717Z",
     "iopub.status.busy": "2023-12-20T20:27:03.930089Z",
     "iopub.status.idle": "2023-12-20T20:27:33.676489Z",
     "shell.execute_reply": "2023-12-20T20:27:33.675322Z",
     "shell.execute_reply.started": "2023-12-20T20:27:03.930672Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightfm\n",
      "  Downloading lightfm-1.17.tar.gz (316 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.4/316.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.1)\n",
      "Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (3.4.0)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.10/site-packages (6.25.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.3)\n",
      "Collecting implicit\n",
      "  Obtaining dependency information for implicit from https://files.pythonhosted.org/packages/cd/cc/deac70cae8cc32c9885d0cd73bc66e1b3cbea36ae7080b8c83995eaf5322/implicit-0.7.2-cp310-cp310-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading implicit-0.7.2-cp310-cp310-manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from lightfm) (1.24.3)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from lightfm) (1.11.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from lightfm) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from lightfm) (1.2.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.12.1)\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.20)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel) (0.1.4)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel) (1.6.7.post1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel) (8.14.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel) (7.4.9)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel) (5.3.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ipykernel) (1.5.6)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ipykernel) (5.9.3)\n",
      "Requirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.10/site-packages (from ipykernel) (24.0.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel) (6.3.3)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/conda/lib/python3.10/site-packages (from ipykernel) (5.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl in /opt/conda/lib/python3.10/site-packages (from implicit) (3.2.0)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (0.19.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (4.8.0)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel) (0.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->lightfm) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->lightfm) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->lightfm) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->lightfm) (2023.7.22)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->lightfm) (1.3.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.23.1->ipykernel) (0.2.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n",
      "Downloading implicit-0.7.2-cp310-cp310-manylinux2014_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: lightfm\n",
      "  Building wheel for lightfm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lightfm: filename=lightfm-1.17-cp310-cp310-linux_x86_64.whl size=464219 sha256=3ea656005763e80047107ec935aaa0b9ed2cc93c8d0ab9f0d45498797bfea1bb\n",
      "  Stored in directory: /root/.cache/pip/wheels/4f/9b/7e/0b256f2168511d8fa4dae4fae0200fdbd729eb424a912ad636\n",
      "Successfully built lightfm\n",
      "Installing collected packages: implicit, lightfm\n",
      "Successfully installed implicit-0.7.2 lightfm-1.17\n"
     ]
    }
   ],
   "source": [
    "!pip install lightfm tqdm optuna ipykernel matplotlib implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T11:08:52.432089Z",
     "iopub.status.busy": "2023-12-07T11:08:52.431579Z",
     "iopub.status.idle": "2023-12-07T11:08:52.437255Z",
     "shell.execute_reply": "2023-12-07T11:08:52.436196Z",
     "shell.execute_reply.started": "2023-12-07T11:08:52.432039Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!python run_compile_all_cython.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:33.679077Z",
     "iopub.status.busy": "2023-12-20T20:27:33.678181Z",
     "iopub.status.idle": "2023-12-20T20:27:36.284231Z",
     "shell.execute_reply": "2023-12-20T20:27:36.282983Z",
     "shell.execute_reply.started": "2023-12-20T20:27:33.679029Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "from scipy.sparse import vstack, csr_matrix\n",
    "from scipy.stats import loguniform\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score, precision_at_k\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import cpu_count, Lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:36.287889Z",
     "iopub.status.busy": "2023-12-20T20:27:36.287256Z",
     "iopub.status.idle": "2023-12-20T20:27:37.062377Z",
     "shell.execute_reply": "2023-12-20T20:27:37.060960Z",
     "shell.execute_reply.started": "2023-12-20T20:27:36.287850Z"
    }
   },
   "outputs": [],
   "source": [
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "from Recommenders.BaseMatrixFactorizationRecommender import BaseMatrixFactorizationRecommender\n",
    "from Recommenders.NonPersonalizedRecommender import TopPop\n",
    "\n",
    "#---- CF\n",
    "from Recommenders.KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "from Recommenders.KNN.UserKNNCFRecommender import UserKNNCFRecommender\n",
    "from Recommenders.GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "from Recommenders.KNN.ItemKNNCustomSimilarityRecommender import ItemKNNCustomSimilarityRecommender\n",
    "\n",
    "#---- Matrix Factorization\n",
    "from Recommenders.MatrixFactorization.NMFRecommender import NMFRecommender\n",
    "\n",
    "#---- CF w/ ML\n",
    "from Recommenders.SLIM.SLIMElasticNetRecommender import SLIMElasticNetRecommender, MultiThreadSLIM_SLIMElasticNetRecommender\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "#---- Others\n",
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "from Recommenders.Recommender_utils import check_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:37.064495Z",
     "iopub.status.busy": "2023-12-20T20:27:37.063718Z",
     "iopub.status.idle": "2023-12-20T20:27:37.070609Z",
     "shell.execute_reply": "2023-12-20T20:27:37.068564Z",
     "shell.execute_reply.started": "2023-12-20T20:27:37.064456Z"
    }
   },
   "outputs": [],
   "source": [
    "from Recommenders.SLIM.SLIMElasticNetRecommender import SLIMElasticNetRecommender, MultiThreadSLIM_SLIMElasticNetRecommender\n",
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "from Evaluation.Evaluator import EvaluatorHoldout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:37.073465Z",
     "iopub.status.busy": "2023-12-20T20:27:37.072935Z",
     "iopub.status.idle": "2023-12-20T20:27:37.086374Z",
     "shell.execute_reply": "2023-12-20T20:27:37.084387Z",
     "shell.execute_reply.started": "2023-12-20T20:27:37.073418Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 69\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:37.089355Z",
     "iopub.status.busy": "2023-12-20T20:27:37.088748Z",
     "iopub.status.idle": "2023-12-20T20:27:40.708683Z",
     "shell.execute_reply": "2023-12-20T20:27:40.707666Z",
     "shell.execute_reply.started": "2023-12-20T20:27:37.089294Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import training data\n",
    "URM_path = \"../input/data-books/data_train.csv\"\n",
    "URM_all_dataframe = pd.read_csv(filepath_or_buffer=URM_path,\n",
    "                                header=0,\n",
    "                                dtype={0:int, 1:int, 2:int},\n",
    "                                engine='python')\n",
    "\n",
    "URM_all_dataframe.columns = [\"user_id\", \"item_id\", \"interaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:40.710995Z",
     "iopub.status.busy": "2023-12-20T20:27:40.709910Z",
     "iopub.status.idle": "2023-12-20T20:27:40.787805Z",
     "shell.execute_reply": "2023-12-20T20:27:40.786620Z",
     "shell.execute_reply.started": "2023-12-20T20:27:40.710957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10877</th>\n",
       "      <td>13020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10878</th>\n",
       "      <td>13021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10879</th>\n",
       "      <td>13022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10880</th>\n",
       "      <td>13023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10881</th>\n",
       "      <td>13024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10882 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id\n",
       "0            1\n",
       "1            2\n",
       "2            3\n",
       "3            4\n",
       "4            5\n",
       "...        ...\n",
       "10877    13020\n",
       "10878    13021\n",
       "10879    13022\n",
       "10880    13023\n",
       "10881    13024\n",
       "\n",
       "[10882 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import target users\n",
    "target_path = \"../input/data-books/data_target_users_test.csv\"\n",
    "target_dataframe= pd.read_csv(filepath_or_buffer=target_path,\n",
    "                                header=0,\n",
    "                                dtype={0:int},\n",
    "                                engine='python')\n",
    "target_dataframe.columns = [\"user_id\"]\n",
    "target_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:40.789733Z",
     "iopub.status.busy": "2023-12-20T20:27:40.789392Z",
     "iopub.status.idle": "2023-12-20T20:27:40.799479Z",
     "shell.execute_reply": "2023-12-20T20:27:40.798117Z",
     "shell.execute_reply.started": "2023-12-20T20:27:40.789702Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(ratings: pd.DataFrame):\n",
    "    unique_users = ratings.user_id.unique()\n",
    "    unique_items = ratings.item_id.unique()\n",
    "\n",
    "    num_users, min_user_id, max_user_id = unique_users.size, unique_users.min(), unique_users.max()\n",
    "    num_items, min_item_id, max_item_id = unique_items.size, unique_items.min(), unique_items.max()\n",
    "\n",
    "    print(num_users, min_user_id, max_user_id)\n",
    "    print(num_items, min_item_id, max_item_id)\n",
    "\n",
    "    mapping_user_id = pd.DataFrame({\"mapped_user_id\": np.arange(num_users), \"user_id\": unique_users})\n",
    "    mapping_item_id = pd.DataFrame({\"mapped_item_id\": np.arange(num_items), \"item_id\": unique_items})\n",
    "\n",
    "    ratings = pd.merge(left=ratings,\n",
    "                       right=mapping_user_id,\n",
    "                       how=\"inner\",\n",
    "                       on=\"user_id\")\n",
    "\n",
    "    ratings = pd.merge(left=ratings,\n",
    "                       right=mapping_item_id,\n",
    "                       how=\"inner\",\n",
    "                       on=\"item_id\")\n",
    "\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:40.804377Z",
     "iopub.status.busy": "2023-12-20T20:27:40.803901Z",
     "iopub.status.idle": "2023-12-20T20:27:40.959165Z",
     "shell.execute_reply": "2023-12-20T20:27:40.958229Z",
     "shell.execute_reply.started": "2023-12-20T20:27:40.804342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12638 1 13024\n",
      "22222 1 22347\n"
     ]
    }
   ],
   "source": [
    "# Call preprocess data function\n",
    "ratings = preprocess_data(URM_all_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion to Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:40.961782Z",
     "iopub.status.busy": "2023-12-20T20:27:40.960444Z",
     "iopub.status.idle": "2023-12-20T20:27:40.971995Z",
     "shell.execute_reply": "2023-12-20T20:27:40.970280Z",
     "shell.execute_reply.started": "2023-12-20T20:27:40.961735Z"
    }
   },
   "outputs": [],
   "source": [
    "URM = sps.coo_matrix((ratings.interaction.values, (ratings.mapped_user_id.values, ratings.mapped_item_id.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:40.975367Z",
     "iopub.status.busy": "2023-12-20T20:27:40.973874Z",
     "iopub.status.idle": "2023-12-20T20:27:42.486624Z",
     "shell.execute_reply": "2023-12-20T20:27:42.485244Z",
     "shell.execute_reply.started": "2023-12-20T20:27:40.975308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 240 (1.90 %) of 12638 users have no train items\n",
      "Warning: 2127 (16.83 %) of 12638 users have no sampled items\n",
      "EvaluatorHoldout: Ignoring 2127 (16.8%) Users that have less than 1 test interactions\n"
     ]
    }
   ],
   "source": [
    "#urm_train, urm_test = split_train_in_two_percentage_global_sample(URM, train_percentage = 0.80)\n",
    "urm_train, urm_validation = split_train_in_two_percentage_global_sample(URM, train_percentage = 0.80)\n",
    "\n",
    "evaluator_validation = EvaluatorHoldout(urm_validation, cutoff_list=[10])\n",
    "#evaluator_test = EvaluatorHoldout(urm_test, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Custom Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:42.488793Z",
     "iopub.status.busy": "2023-12-20T20:27:42.488449Z",
     "iopub.status.idle": "2023-12-20T20:27:42.497725Z",
     "shell.execute_reply": "2023-12-20T20:27:42.496292Z",
     "shell.execute_reply.started": "2023-12-20T20:27:42.488763Z"
    }
   },
   "outputs": [],
   "source": [
    "class ScoresHybridRecommender(BaseRecommender):\n",
    "    \"\"\" ScoresHybridRecommender\n",
    "    Hybrid of two prediction scores R = R1*alpha + R2*(1-alpha)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"ScoresHybridRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, recommender_1, recommender_2):\n",
    "        super(ScoresHybridRecommender, self).__init__(URM_train)\n",
    "\n",
    "        self.URM_train = sps.csr_matrix(URM_train)\n",
    "        self.recommender_1 = recommender_1\n",
    "        self.recommender_2 = recommender_2\n",
    "\n",
    "\n",
    "    def fit(self, alpha=0.5):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute):\n",
    "\n",
    "        # In a simple extension this could be a loop over a list of pretrained recommender objects\n",
    "        item_weights_1 = self.recommender_1._compute_item_score(user_id_array)\n",
    "        item_weights_2 = self.recommender_2._compute_item_score(user_id_array)\n",
    "\n",
    "        item_weights = item_weights_1*self.alpha + item_weights_2*(1-self.alpha)\n",
    "\n",
    "        return item_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:42.499993Z",
     "iopub.status.busy": "2023-12-20T20:27:42.499640Z",
     "iopub.status.idle": "2023-12-20T20:27:42.512130Z",
     "shell.execute_reply": "2023-12-20T20:27:42.510819Z",
     "shell.execute_reply.started": "2023-12-20T20:27:42.499952Z"
    }
   },
   "outputs": [],
   "source": [
    "class LightFMCFRecommender(BaseRecommender):\n",
    "    \"\"\"LightFMCFRecommender\"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"LightFMCFRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train):\n",
    "        super(LightFMCFRecommender, self).__init__(URM_train)\n",
    "    \n",
    "    \n",
    "    def fit(self, epochs = 300, user_alpha=1e-6, item_alpha = 1e-6, n_factors = 10, n_threads = 4, max_sampled=3, loss='warp', learning_schedule='adagrad'):\n",
    "        \n",
    "        # Let's fit a WARP model\n",
    "        self.lightFM_model = LightFM(loss=loss,\n",
    "                                     user_alpha=user_alpha,\n",
    "                                     item_alpha=item_alpha,\n",
    "                                     no_components=n_factors,\n",
    "                                     max_sampled=max_sampled,\n",
    "                                     learning_schedule=learning_schedule)\n",
    "\n",
    "        self.lightFM_model = self.lightFM_model.fit(self.URM_train, \n",
    "                                       epochs=epochs,\n",
    "                                       num_threads=n_threads,\n",
    "                                       verbose=True)\n",
    "\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute = None):\n",
    "        \n",
    "        # Create a single (n_items, ) array with the item score, then copy it for every user\n",
    "        items_to_compute = np.arange(self.n_items)\n",
    "        \n",
    "        item_scores = - np.ones((len(user_id_array), self.n_items)) * np.inf\n",
    "\n",
    "        for user_index, user_id in enumerate(user_id_array):\n",
    "            item_scores[user_index] = self.lightFM_model.predict(int(user_id), \n",
    "                                                                 items_to_compute)\n",
    "\n",
    "        return item_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:42.514326Z",
     "iopub.status.busy": "2023-12-20T20:27:42.513950Z",
     "iopub.status.idle": "2023-12-20T20:27:42.529631Z",
     "shell.execute_reply": "2023-12-20T20:27:42.528381Z",
     "shell.execute_reply.started": "2023-12-20T20:27:42.514285Z"
    }
   },
   "outputs": [],
   "source": [
    "class GeneralizedLinearHybridRecommender(BaseRecommender):\n",
    "    \"\"\"\n",
    "    This recommender merges N recommendes by weighting their ratings\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"GeneralizedLinearHybridRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, recommenders: list, verbose=True):\n",
    "        self.RECOMMENDER_NAME = ''\n",
    "        for recommender in recommenders:\n",
    "            self.RECOMMENDER_NAME = self.RECOMMENDER_NAME + recommender.RECOMMENDER_NAME[:-11]\n",
    "        self.RECOMMENDER_NAME = self.RECOMMENDER_NAME + 'HybridRecommender'\n",
    "\n",
    "        super(GeneralizedLinearHybridRecommender, self).__init__(URM_train, verbose=verbose)\n",
    "\n",
    "        self.recommenders = recommenders\n",
    "\n",
    "    def fit(self, alphas=None):\n",
    "        self.alphas = alphas\n",
    "\n",
    "    def save_model(self, folder_path, file_name=None):\n",
    "        pass\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute=None):\n",
    "        result = self.alphas[0]*self.recommenders[0]._compute_item_score(user_id_array,items_to_compute)\n",
    "        for index in range(1,len(self.alphas)):\n",
    "            result = result + self.alphas[index]*self.recommenders[index]._compute_item_score(user_id_array,items_to_compute)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:42.531771Z",
     "iopub.status.busy": "2023-12-20T20:27:42.531392Z",
     "iopub.status.idle": "2023-12-20T20:27:42.557862Z",
     "shell.execute_reply": "2023-12-20T20:27:42.556355Z",
     "shell.execute_reply.started": "2023-12-20T20:27:42.531738Z"
    }
   },
   "outputs": [],
   "source": [
    "class FastIALSRecommender(BaseMatrixFactorizationRecommender):\n",
    "    RECOMMENDER_NAME = \"FastIALSRecommender\"\n",
    "\n",
    "    AVAILABLE_CONFIDENCE_SCALING = [\"linear\", \"log\"]\n",
    "    \n",
    "    def __init__(self, URM_train, verbose=True):\n",
    "        super().__init__(URM_train, verbose=verbose)\n",
    "        \n",
    "    def fit(self,\n",
    "            factors=20,\n",
    "            regularization=1e-3,\n",
    "            iterations=100,\n",
    "            calculate_training_loss=False,\n",
    "            num_threads=0,\n",
    "            confidence_scaling='linear',\n",
    "            alpha=1.0,\n",
    "            epsilon=0,\n",
    "            #---- Do not change\n",
    "            use_native=True,\n",
    "            use_cg=True,\n",
    "            use_gpu=True):\n",
    "        if confidence_scaling not in self.AVAILABLE_CONFIDENCE_SCALING:\n",
    "           raise ValueError(\"Value for 'confidence_scaling' not recognized. Acceptable values are {}, provided was '{}'\".format(self.AVAILABLE_CONFIDENCE_SCALING, confidence_scaling))\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.num_factors = factors\n",
    "        self.reg = regularization\n",
    "        \n",
    "        self.USER_factors = self._init_factors(self.n_users, False)  # don't need values, will compute them\n",
    "        self.ITEM_factors = self._init_factors(self.n_items)\n",
    "        \n",
    "        self.recommender = AlternatingLeastSquares(factors=factors, regularization=regularization,\n",
    "                                                        use_native=use_native, use_cg=use_cg, use_gpu=use_gpu,\n",
    "                                                        iterations=iterations,\n",
    "                                                        calculate_training_loss=calculate_training_loss,\n",
    "                                                        num_threads=num_threads)\n",
    "        \n",
    "        self._build_confidence_matrix(confidence_scaling)\n",
    "        self.recommender.fit(self.C, show_progress=self.verbose)\n",
    "        \n",
    "        self.USER_factors = self.recommender.user_factors.to_numpy()\n",
    "        self.ITEM_factors = self.recommender.item_factors.to_numpy()\n",
    "        \n",
    "    \n",
    "    def _linear_scaling_confidence(self):\n",
    "\n",
    "        C = check_matrix(self.URM_train, format=\"csr\", dtype = np.float32)\n",
    "        C.data = 1.0 + self.alpha*C.data\n",
    "\n",
    "        return C\n",
    "\n",
    "    def _log_scaling_confidence(self):\n",
    "\n",
    "        C = check_matrix(self.URM_train, format=\"csr\", dtype = np.float32)\n",
    "        C.data = 1.0 + self.alpha * np.log(1.0 + C.data / self.epsilon)\n",
    "\n",
    "        return C\n",
    "    \n",
    "    def _build_confidence_matrix(self, confidence_scaling):\n",
    "\n",
    "        if confidence_scaling == 'linear':\n",
    "            self.C = self._linear_scaling_confidence()\n",
    "        else:\n",
    "            self.C = self._log_scaling_confidence()\n",
    "\n",
    "        self.C_csc= check_matrix(self.C.copy(), format=\"csc\", dtype = np.float32)\n",
    "    \n",
    "    def _init_factors(self, num_factors, assign_values=True):\n",
    "\n",
    "        if assign_values:\n",
    "            return self.num_factors**-0.5*np.random.random_sample((num_factors, self.num_factors))\n",
    "\n",
    "        else:\n",
    "            return np.empty((num_factors, self.num_factors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Best Model Params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:42.560787Z",
     "iopub.status.busy": "2023-12-20T20:27:42.559503Z",
     "iopub.status.idle": "2023-12-20T20:27:42.573615Z",
     "shell.execute_reply": "2023-12-20T20:27:42.572099Z",
     "shell.execute_reply.started": "2023-12-20T20:27:42.560741Z"
    }
   },
   "outputs": [],
   "source": [
    "ItemKNN_params = {\n",
    "    'topK': 6,\n",
    "    'shrink': 15,\n",
    "    'similarity': 'jaccard',\n",
    "    'normalize': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:42.576110Z",
     "iopub.status.busy": "2023-12-20T20:27:42.575496Z",
     "iopub.status.idle": "2023-12-20T20:27:42.585626Z",
     "shell.execute_reply": "2023-12-20T20:27:42.584234Z",
     "shell.execute_reply.started": "2023-12-20T20:27:42.575994Z"
    }
   },
   "outputs": [],
   "source": [
    "RP3beta_params = {\n",
    "    'alpha': 0.307953246083667, \n",
    "    'beta': 0.3073797221110665, \n",
    "    'topK': 59, \n",
    "    'normalize_similarity': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:42.588520Z",
     "iopub.status.busy": "2023-12-20T20:27:42.587362Z",
     "iopub.status.idle": "2023-12-20T20:27:42.596756Z",
     "shell.execute_reply": "2023-12-20T20:27:42.595868Z",
     "shell.execute_reply.started": "2023-12-20T20:27:42.588472Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha_itemknn_rp3beta=0.7381515719042592"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:42.598932Z",
     "iopub.status.busy": "2023-12-20T20:27:42.597945Z",
     "iopub.status.idle": "2023-12-20T20:27:42.610086Z",
     "shell.execute_reply": "2023-12-20T20:27:42.609073Z",
     "shell.execute_reply.started": "2023-12-20T20:27:42.598862Z"
    }
   },
   "outputs": [],
   "source": [
    "UserKNN_params = {\n",
    "    'topK': 470,\n",
    "    'shrink': 0,\n",
    "    'similarity': 'cosine',\n",
    "    'normalize': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:42.615204Z",
     "iopub.status.busy": "2023-12-20T20:27:42.614797Z",
     "iopub.status.idle": "2023-12-20T20:27:42.621276Z",
     "shell.execute_reply": "2023-12-20T20:27:42.620352Z",
     "shell.execute_reply.started": "2023-12-20T20:27:42.615171Z"
    }
   },
   "outputs": [],
   "source": [
    "LightFM_params = {\n",
    "                  'n_factors': 482,\n",
    "                  'max_sampled': 5,\n",
    "                  'user_alpha': 0.00023989649900734266,\n",
    "                  'item_alpha': 9.740651135253414e-05\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:42.622476Z",
     "iopub.status.busy": "2023-12-20T20:27:42.622146Z",
     "iopub.status.idle": "2023-12-20T20:27:42.632322Z",
     "shell.execute_reply": "2023-12-20T20:27:42.631359Z",
     "shell.execute_reply.started": "2023-12-20T20:27:42.622441Z"
    }
   },
   "outputs": [],
   "source": [
    "SLIM_params = {\n",
    "    'l1_ratio': 0.013752256221164005,\n",
    "    'alpha': 0.0031943927190071775,\n",
    "    'topK': 622\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:42.633523Z",
     "iopub.status.busy": "2023-12-20T20:27:42.633197Z",
     "iopub.status.idle": "2023-12-20T20:27:42.643423Z",
     "shell.execute_reply": "2023-12-20T20:27:42.642440Z",
     "shell.execute_reply.started": "2023-12-20T20:27:42.633494Z"
    }
   },
   "outputs": [],
   "source": [
    "NMF_params = {\n",
    "    'l1_ratio': 0.005734775635120469,\n",
    "    'num_factors': 134,\n",
    "    'beta_loss': 'frobenius',\n",
    "    'init_type': 'nndsvda',\n",
    "    'solver': 'multiplicative_update'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:42.644748Z",
     "iopub.status.busy": "2023-12-20T20:27:42.644421Z",
     "iopub.status.idle": "2023-12-20T20:27:42.656896Z",
     "shell.execute_reply": "2023-12-20T20:27:42.655485Z",
     "shell.execute_reply.started": "2023-12-20T20:27:42.644718Z"
    }
   },
   "outputs": [],
   "source": [
    "IALS_params = {\n",
    "    'confidence_scaling': 'log',\n",
    "    'epsilon': 0.11624415533664904,\n",
    "    'factors': 116,\n",
    "    'regularization': 0.005454427904241962,\n",
    "    'alpha': 1.7221339971074425\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning SlimEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:42.659511Z",
     "iopub.status.busy": "2023-12-20T20:27:42.658282Z",
     "iopub.status.idle": "2023-12-20T20:27:42.668227Z",
     "shell.execute_reply": "2023-12-20T20:27:42.667395Z",
     "shell.execute_reply.started": "2023-12-20T20:27:42.659467Z"
    }
   },
   "outputs": [],
   "source": [
    "class SaveResults(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.results_df = pd.DataFrame(columns=[\"result\"])\n",
    "\n",
    "    def __call__(self, optuna_study, optuna_trial):\n",
    "        hyperparam_dict = optuna_trial.params.copy()\n",
    "        hyperparam_dict[\"result\"] = optuna_trial.values[0]\n",
    "\n",
    "        # Create a DataFrame from the current trial's results\n",
    "        trial_df = pd.DataFrame([hyperparam_dict])\n",
    "\n",
    "        # Use concat instead of append\n",
    "        self.results_df = pd.concat([self.results_df, trial_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:42.670451Z",
     "iopub.status.busy": "2023-12-20T20:27:42.669727Z",
     "iopub.status.idle": "2023-12-20T20:27:42.685252Z",
     "shell.execute_reply": "2023-12-20T20:27:42.683729Z",
     "shell.execute_reply.started": "2023-12-20T20:27:42.670409Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective_function_SLIM(optuna_trial):\n",
    "\n",
    "    recommender_instance = MultiThreadSLIM_SLIMElasticNetRecommender(urm_train)\n",
    "    recommender_instance.fit(\n",
    "                             l1_ratio = optuna_trial.suggest_float(\"l1_ratio\", 1e-7, 0.1),\n",
    "                             alpha = optuna_trial.suggest_float(\"alpha\", 0, 1),\n",
    "                             topK = optuna_trial.suggest_int(\"topK\", 5, 2500),\n",
    "                             workers = int(cpu_count())\n",
    "                             #positive_only = optuna_trial.suggest_categorical(\"positive_only\", [True, False]),\n",
    "                            )\n",
    "\n",
    "    result_df, _ = evaluator_validation.evaluateRecommender(recommender_instance)\n",
    "\n",
    "    return result_df.loc[10][\"RECALL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T20:27:42.687857Z",
     "iopub.status.busy": "2023-12-20T20:27:42.687091Z",
     "iopub.status.idle": "2023-12-21T00:46:57.551897Z",
     "shell.execute_reply": "2023-12-21T00:46:57.549956Z",
     "shell.execute_reply.started": "2023-12-20T20:27:42.687653Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-20 20:27:42,693] A new study created in memory with name: no-name-9720942a-ac53-4fff-94c5-b4dde0662202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [08:03<00:00, 45.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10511 (100.0%) in 9.41 sec. Users per second: 1117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-20 20:35:56,214] Trial 0 finished with value: 0.012246115195107047 and parameters: {'l1_ratio': 0.03058569985023565, 'alpha': 0.6514852683204296, 'topK': 1820}. Best is trial 0 with value: 0.012246115195107047.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [08:13<00:00, 45.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10511 (100.0%) in 9.81 sec. Users per second: 1072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-20 20:44:19,221] Trial 1 finished with value: 0.06373979251201553 and parameters: {'l1_ratio': 0.03379806136246944, 'alpha': 0.2061543867606629, 'topK': 865}. Best is trial 1 with value: 0.06373979251201553.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [08:10<00:00, 45.32it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10511 (100.0%) in 9.08 sec. Users per second: 1157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-20 20:52:38,688] Trial 2 finished with value: 0.00020563109101655896 and parameters: {'l1_ratio': 0.07473846042994049, 'alpha': 0.36248930816359815, 'topK': 1953}. Best is trial 1 with value: 0.06373979251201553.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [08:09<00:00, 45.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10511 (100.0%) in 9.13 sec. Users per second: 1151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-20 21:00:56,960] Trial 3 finished with value: 0.00020563109101655896 and parameters: {'l1_ratio': 0.03856331470095756, 'alpha': 0.71448088856801, 'topK': 2319}. Best is trial 1 with value: 0.06373979251201553.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [08:11<00:00, 45.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10511 (100.0%) in 9.12 sec. Users per second: 1153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-20 21:09:17,565] Trial 4 finished with value: 0.00020563109101655896 and parameters: {'l1_ratio': 0.093735121090958, 'alpha': 0.9289798361593036, 'topK': 1535}. Best is trial 1 with value: 0.06373979251201553.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [08:09<00:00, 45.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10511 (100.0%) in 9.17 sec. Users per second: 1146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-20 21:17:36,800] Trial 5 finished with value: 0.00020563109101655896 and parameters: {'l1_ratio': 0.08672833679013897, 'alpha': 0.37736512138652945, 'topK': 1760}. Best is trial 1 with value: 0.06373979251201553.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [08:33<00:00, 43.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10511 (100.0%) in 9.18 sec. Users per second: 1145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-20 21:26:19,216] Trial 6 finished with value: 0.00020563109101655896 and parameters: {'l1_ratio': 0.04056582880786263, 'alpha': 0.7724756167369239, 'topK': 495}. Best is trial 1 with value: 0.06373979251201553.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [08:37<00:00, 42.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10511 (100.0%) in 9.47 sec. Users per second: 1110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-20 21:35:06,464] Trial 7 finished with value: 0.013736938047648728 and parameters: {'l1_ratio': 0.03960931834063515, 'alpha': 0.48954628669654787, 'topK': 954}. Best is trial 1 with value: 0.06373979251201553.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [09:58<00:00, 37.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10511 (100.0%) in 12.06 sec. Users per second: 872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-20 21:45:16,976] Trial 8 finished with value: 0.00020563109101655896 and parameters: {'l1_ratio': 0.07309429425049914, 'alpha': 0.4462487281623271, 'topK': 1116}. Best is trial 1 with value: 0.06373979251201553.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [11:44<00:00, 31.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10511 (100.0%) in 11.74 sec. Users per second: 895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-20 21:57:13,418] Trial 9 finished with value: 0.00020563109101655896 and parameters: {'l1_ratio': 0.039379607118816176, 'alpha': 0.9724821250261418, 'topK': 396}. Best is trial 1 with value: 0.06373979251201553.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [14:19<00:00, 25.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10511 (100.0%) in 12.64 sec. Users per second: 832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-20 22:11:45,723] Trial 10 finished with value: 0.11585054024773969 and parameters: {'l1_ratio': 0.0052345829272747064, 'alpha': 0.06517302335713027, 'topK': 114}. Best is trial 10 with value: 0.11585054024773969.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [10:07<00:00, 36.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10511 (100.0%) in 11.39 sec. Users per second: 923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-20 22:22:05,120] Trial 11 finished with value: 0.11067296939622623 and parameters: {'l1_ratio': 0.008936551243073314, 'alpha': 0.07014775079405036, 'topK': 52}. Best is trial 10 with value: 0.11585054024773969.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [20:54<00:00, 17.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10511 (100.0%) in 13.83 sec. Users per second: 760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-20 22:43:13,470] Trial 12 finished with value: 0.1222452967126278 and parameters: {'l1_ratio': 0.002150373581018164, 'alpha': 0.049001990127202105, 'topK': 32}. Best is trial 12 with value: 0.1222452967126278.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [26:47<00:00, 13.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10511 (100.0%) in 13.75 sec. Users per second: 764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-20 23:10:15,180] Trial 13 finished with value: 0.13525869678402824 and parameters: {'l1_ratio': 0.0014735833363708289, 'alpha': 0.012855253405195555, 'topK': 47}. Best is trial 13 with value: 0.13525869678402824.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [26:28<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10511 (100.0%) in 17.83 sec. Users per second: 589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-20 23:37:02,479] Trial 14 finished with value: 0.12263288990767875 and parameters: {'l1_ratio': 0.0005296608506302583, 'alpha': 0.049989960816108056, 'topK': 575}. Best is trial 13 with value: 0.13525869678402824.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [08:26<00:00, 43.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10511 (100.0%) in 9.21 sec. Users per second: 1142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-20 23:45:38,589] Trial 15 finished with value: 0.08116720214815562 and parameters: {'l1_ratio': 0.016990170792081677, 'alpha': 0.19426989726829758, 'topK': 575}. Best is trial 13 with value: 0.13525869678402824.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [24:15<00:00, 15.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10511 (100.0%) in 15.79 sec. Users per second: 666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-21 00:10:10,860] Trial 16 finished with value: 0.13921079642329776 and parameters: {'l1_ratio': 0.01998720297988901, 'alpha': 0.0032805805487669745, 'topK': 698}. Best is trial 16 with value: 0.13921079642329776.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [08:15<00:00, 44.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10511 (100.0%) in 9.05 sec. Users per second: 1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-21 00:18:35,100] Trial 17 finished with value: 0.07709939609044787 and parameters: {'l1_ratio': 0.01923637258134462, 'alpha': 0.21090188551263264, 'topK': 1283}. Best is trial 16 with value: 0.13921079642329776.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [08:00<00:00, 46.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10511 (100.0%) in 8.85 sec. Users per second: 1187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-21 00:26:44,178] Trial 18 finished with value: 0.069896772531215 and parameters: {'l1_ratio': 0.02016905456480382, 'alpha': 0.28574768230817266, 'topK': 317}. Best is trial 16 with value: 0.13921079642329776.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [07:57<00:00, 46.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10511 (100.0%) in 8.78 sec. Users per second: 1197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-21 00:34:50,909] Trial 19 finished with value: 0.060261016637621824 and parameters: {'l1_ratio': 0.055762612164654175, 'alpha': 0.14670651635585422, 'topK': 723}. Best is trial 16 with value: 0.13921079642329776.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [11:47<00:00, 31.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 10511 (100.0%) in 11.98 sec. Users per second: 878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-21 00:46:50,283] Trial 20 finished with value: 0.11998517618481742 and parameters: {'l1_ratio': 0.010980473971047941, 'alpha': 0.03443415298193212, 'topK': 267}. Best is trial 16 with value: 0.13921079642329776.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 240 ( 1.9%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 123 ( 0.6%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22222 [00:00<?, ?it/s][W 2023-12-21 00:46:56,221] Trial 21 failed with parameters: {'l1_ratio': 0.0014372648241861802, 'alpha': 0.0031038317509641832, 'topK': 673} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 856, in next\n",
      "    item = self._items.popleft()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_47/547765023.py\", line 4, in objective_function_SLIM\n",
      "    recommender_instance.fit(\n",
      "  File \"/kaggle/working/Recommenders/SLIM/SLIMElasticNetRecommender.py\", line 242, in fit\n",
      "    for values_, rows_, cols_ in pool.imap_unordered(_pfit, itemchunks, pool_chunksize):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 451, in <genexpr>\n",
      "    return (item for chunk in result for item in chunk)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 861, in next\n",
      "    self._cond.wait(timeout)\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 320, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "[W 2023-12-21 00:46:56,228] Trial 21 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_items\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m optuna_study_SLIM \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m save_results_SLIM \u001b[38;5;241m=\u001b[39m SaveResults()\n\u001b[0;32m----> 5\u001b[0m \u001b[43moptuna_study_SLIM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_function_SLIM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msave_results_SLIM\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m, in \u001b[0;36mobjective_function_SLIM\u001b[0;34m(optuna_trial)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective_function_SLIM\u001b[39m(optuna_trial):\n\u001b[1;32m      3\u001b[0m     recommender_instance \u001b[38;5;241m=\u001b[39m MultiThreadSLIM_SLIMElasticNetRecommender(urm_train)\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mrecommender_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                             \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptuna_trial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest_float\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ml1_ratio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                             \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptuna_trial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest_float\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malpha\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mtopK\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptuna_trial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest_int\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtopK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2500\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcpu_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m#positive_only = optuna_trial.suggest_categorical(\"positive_only\", [True, False]),\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m                            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     result_df, _ \u001b[38;5;241m=\u001b[39m evaluator_validation\u001b[38;5;241m.\u001b[39mevaluateRecommender(recommender_instance)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result_df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m10\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRECALL\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/kaggle/working/Recommenders/SLIM/SLIMElasticNetRecommender.py:242\u001b[0m, in \u001b[0;36mMultiThreadSLIM_SLIMElasticNetRecommender.fit\u001b[0;34m(self, alpha, l1_ratio, positive_only, topK, verbose, workers)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# res contains a vector of (values, rows, cols) tuples\u001b[39;00m\n\u001b[1;32m    241\u001b[0m values, rows, cols \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[0;32m--> 242\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m values_, rows_, cols_ \u001b[38;5;129;01min\u001b[39;00m pool\u001b[38;5;241m.\u001b[39mimap_unordered(_pfit, itemchunks, pool_chunksize):\n\u001b[1;32m    243\u001b[0m     values\u001b[38;5;241m.\u001b[39mextend(values_)\n\u001b[1;32m    244\u001b[0m     rows\u001b[38;5;241m.\u001b[39mextend(rows_)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/pool.py:451\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    443\u001b[0m result \u001b[38;5;241m=\u001b[39m IMapUnorderedIterator(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_taskqueue\u001b[38;5;241m.\u001b[39mput(\n\u001b[1;32m    445\u001b[0m     (\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_guarded_task_generation(result\u001b[38;5;241m.\u001b[39m_job,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m         result\u001b[38;5;241m.\u001b[39m_set_length\n\u001b[1;32m    450\u001b[0m     ))\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (item \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m result \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m chunk)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/pool.py:861\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 861\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    863\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optuna_study_SLIM = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "save_results_SLIM = SaveResults()\n",
    "\n",
    "optuna_study_SLIM.optimize(objective_function_SLIM,\n",
    "                      callbacks=[save_results_SLIM],\n",
    "                      n_trials = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T00:47:11.492348Z",
     "iopub.status.busy": "2023-12-21T00:47:11.491877Z",
     "iopub.status.idle": "2023-12-21T00:47:11.497511Z",
     "shell.execute_reply": "2023-12-21T00:47:11.496643Z",
     "shell.execute_reply.started": "2023-12-21T00:47:11.492299Z"
    }
   },
   "outputs": [],
   "source": [
    "#BEST RECALL\n",
    "#Trial 16 finished with value: 0.13921079642329776 and parameters: {'l1_ratio': 0.01998720297988901, 'alpha': 0.0032805805487669745, 'topK': 698}. Best is trial 16 with value: 0.13921079642329776."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'l1_ratio': 0.003120566520870887, 'alpha': 0.07957855829190108, 'topK': 1478}. Best is trial 8 with value: 0.11397645151525244"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_trials = [t for t in optuna_study_SLIM.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in optuna_study_SLIM.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(optuna_study_SLIM.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(\"  Value Validation: \", optuna_study_SLIM.best_trial.value)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(optuna_study_SLIM.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4086250,
     "sourceId": 7091045,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4120115,
     "sourceId": 7139099,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
