{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting-up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T14:19:08.374332Z",
     "iopub.status.busy": "2023-12-01T14:19:08.373851Z",
     "iopub.status.idle": "2023-12-01T14:19:09.580950Z",
     "shell.execute_reply": "2023-12-01T14:19:09.579602Z",
     "shell.execute_reply.started": "2023-12-01T14:19:08.374237Z"
    }
   },
   "outputs": [],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:45:56.673219Z",
     "iopub.status.busy": "2023-12-03T08:45:56.672785Z",
     "iopub.status.idle": "2023-12-03T08:46:01.569955Z",
     "shell.execute_reply": "2023-12-03T08:46:01.568418Z",
     "shell.execute_reply.started": "2023-12-03T08:45:56.673129Z"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/MaurizioFD/RecSys_Course_AT_PoliMi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:46:01.574308Z",
     "iopub.status.busy": "2023-12-03T08:46:01.572075Z",
     "iopub.status.idle": "2023-12-03T08:46:02.605456Z",
     "shell.execute_reply": "2023-12-03T08:46:02.603716Z",
     "shell.execute_reply.started": "2023-12-03T08:46:01.574256Z"
    }
   },
   "outputs": [],
   "source": [
    "!mv RecSys_Course_AT_PoliMi/* /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:46:02.608206Z",
     "iopub.status.busy": "2023-12-03T08:46:02.607795Z",
     "iopub.status.idle": "2023-12-03T08:49:17.010183Z",
     "shell.execute_reply": "2023-12-03T08:49:17.009051Z",
     "shell.execute_reply.started": "2023-12-03T08:46:02.608161Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:49:17.014080Z",
     "iopub.status.busy": "2023-12-03T08:49:17.013660Z",
     "iopub.status.idle": "2023-12-03T08:52:14.357556Z",
     "shell.execute_reply": "2023-12-03T08:52:14.355105Z",
     "shell.execute_reply.started": "2023-12-03T08:49:17.014036Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python run_compile_all_cython.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:52:14.362460Z",
     "iopub.status.busy": "2023-12-03T08:52:14.361965Z",
     "iopub.status.idle": "2023-12-03T08:52:32.196279Z",
     "shell.execute_reply": "2023-12-03T08:52:32.194834Z",
     "shell.execute_reply.started": "2023-12-03T08:52:14.362406Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install lightfm tqdm optuna ipykernel matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:52:32.198745Z",
     "iopub.status.busy": "2023-12-03T08:52:32.198299Z",
     "iopub.status.idle": "2023-12-03T08:52:33.292022Z",
     "shell.execute_reply": "2023-12-03T08:52:33.291113Z",
     "shell.execute_reply.started": "2023-12-03T08:52:32.198703Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pyplot\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import loguniform\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score, precision_at_k\n",
    "import time\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:52:33.294040Z",
     "iopub.status.busy": "2023-12-03T08:52:33.293355Z",
     "iopub.status.idle": "2023-12-03T08:52:33.455268Z",
     "shell.execute_reply": "2023-12-03T08:52:33.453322Z",
     "shell.execute_reply.started": "2023-12-03T08:52:33.294002Z"
    }
   },
   "outputs": [],
   "source": [
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "from Recommenders.Similarity.Compute_Similarity_Python import Compute_Similarity_Python\n",
    "from Recommenders.KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "from Recommenders.NonPersonalizedRecommender import TopPop\n",
    "from Recommenders.KNN.UserKNNCFRecommender import UserKNNCFRecommender\n",
    "from Recommenders.GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "from Recommenders.KNN.UserKNNCFRecommender import UserKNNCFRecommender\n",
    "from Recommenders.KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "from Recommenders.KNN.ItemKNNCustomSimilarityRecommender import ItemKNNCustomSimilarityRecommender\n",
    "#----remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:52:33.458130Z",
     "iopub.status.busy": "2023-12-03T08:52:33.457381Z",
     "iopub.status.idle": "2023-12-03T08:52:33.465144Z",
     "shell.execute_reply": "2023-12-03T08:52:33.463627Z",
     "shell.execute_reply.started": "2023-12-03T08:52:33.458079Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 69\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:52:33.468943Z",
     "iopub.status.busy": "2023-12-03T08:52:33.468565Z",
     "iopub.status.idle": "2023-12-03T08:52:35.786657Z",
     "shell.execute_reply": "2023-12-03T08:52:35.785404Z",
     "shell.execute_reply.started": "2023-12-03T08:52:33.468909Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import training data\n",
    "URM_path = \"../input/data-books/data_train.csv\"\n",
    "URM_all_dataframe = pd.read_csv(filepath_or_buffer=URM_path,\n",
    "                                header=0,\n",
    "                                dtype={0:int, 1:int, 2:int},\n",
    "                                engine='python')\n",
    "\n",
    "URM_all_dataframe.columns = [\"user_id\", \"item_id\", \"interaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:52:35.790804Z",
     "iopub.status.busy": "2023-12-03T08:52:35.790440Z",
     "iopub.status.idle": "2023-12-03T08:52:35.849204Z",
     "shell.execute_reply": "2023-12-03T08:52:35.848025Z",
     "shell.execute_reply.started": "2023-12-03T08:52:35.790772Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import target users\n",
    "target_path = \"../input/data-books/data_target_users_test.csv\"\n",
    "target_dataframe= pd.read_csv(filepath_or_buffer=target_path,\n",
    "                                header=0,\n",
    "                                dtype={0:int},\n",
    "                                engine='python')\n",
    "target_dataframe.columns = [\"user_id\"]\n",
    "target_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:52:35.852076Z",
     "iopub.status.busy": "2023-12-03T08:52:35.851319Z",
     "iopub.status.idle": "2023-12-03T08:52:35.862082Z",
     "shell.execute_reply": "2023-12-03T08:52:35.860755Z",
     "shell.execute_reply.started": "2023-12-03T08:52:35.851981Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(ratings: pd.DataFrame):\n",
    "    unique_users = ratings.user_id.unique()\n",
    "    unique_items = ratings.item_id.unique()\n",
    "\n",
    "    num_users, min_user_id, max_user_id = unique_users.size, unique_users.min(), unique_users.max()\n",
    "    num_items, min_item_id, max_item_id = unique_items.size, unique_items.min(), unique_items.max()\n",
    "\n",
    "    print(num_users, min_user_id, max_user_id)\n",
    "    print(num_items, min_item_id, max_item_id)\n",
    "\n",
    "    mapping_user_id = pd.DataFrame({\"mapped_user_id\": np.arange(num_users), \"user_id\": unique_users})\n",
    "    mapping_item_id = pd.DataFrame({\"mapped_item_id\": np.arange(num_items), \"item_id\": unique_items})\n",
    "\n",
    "    ratings = pd.merge(left=ratings,\n",
    "                       right=mapping_user_id,\n",
    "                       how=\"inner\",\n",
    "                       on=\"user_id\")\n",
    "\n",
    "    ratings = pd.merge(left=ratings,\n",
    "                       right=mapping_item_id,\n",
    "                       how=\"inner\",\n",
    "                       on=\"item_id\")\n",
    "\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:52:35.864593Z",
     "iopub.status.busy": "2023-12-03T08:52:35.864042Z",
     "iopub.status.idle": "2023-12-03T08:52:36.026844Z",
     "shell.execute_reply": "2023-12-03T08:52:36.025559Z",
     "shell.execute_reply.started": "2023-12-03T08:52:35.864547Z"
    }
   },
   "outputs": [],
   "source": [
    "# Call preprocess data function\n",
    "ratings = preprocess_data(URM_all_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From DF to Sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:52:36.029449Z",
     "iopub.status.busy": "2023-12-03T08:52:36.028309Z",
     "iopub.status.idle": "2023-12-03T08:52:36.041839Z",
     "shell.execute_reply": "2023-12-03T08:52:36.040657Z",
     "shell.execute_reply.started": "2023-12-03T08:52:36.029403Z"
    }
   },
   "outputs": [],
   "source": [
    "URM = sps.coo_matrix((ratings.interaction.values, (ratings.mapped_user_id.values, ratings.mapped_item_id.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:52:36.044340Z",
     "iopub.status.busy": "2023-12-03T08:52:36.043822Z",
     "iopub.status.idle": "2023-12-03T08:52:37.648046Z",
     "shell.execute_reply": "2023-12-03T08:52:37.646790Z",
     "shell.execute_reply.started": "2023-12-03T08:52:36.044292Z"
    }
   },
   "outputs": [],
   "source": [
    "urm_train, urm_test = split_train_in_two_percentage_global_sample(URM, train_percentage = 0.80)\n",
    "urm_train, urm_validation = split_train_in_two_percentage_global_sample(urm_train, train_percentage = 0.80)\n",
    "\n",
    "evaluator_validation = EvaluatorHoldout(urm_validation, cutoff_list=[10])\n",
    "evaluator_test = EvaluatorHoldout(urm_test, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:52:37.650388Z",
     "iopub.status.busy": "2023-12-03T08:52:37.649709Z",
     "iopub.status.idle": "2023-12-03T08:52:37.660076Z",
     "shell.execute_reply": "2023-12-03T08:52:37.658878Z",
     "shell.execute_reply.started": "2023-12-03T08:52:37.650344Z"
    }
   },
   "outputs": [],
   "source": [
    "class ScoresHybridRecommender(BaseRecommender):\n",
    "    \"\"\" ScoresHybridRecommender\n",
    "    Hybrid of two prediction scores R = R1*alpha + R2*(1-alpha)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"ScoresHybridRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, recommender_1, recommender_2):\n",
    "        super(ScoresHybridRecommender, self).__init__(URM_train)\n",
    "\n",
    "        self.URM_train = sps.csr_matrix(URM_train)\n",
    "        self.recommender_1 = recommender_1\n",
    "        self.recommender_2 = recommender_2\n",
    "\n",
    "\n",
    "    def fit(self, alpha=0.5):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute):\n",
    "\n",
    "        # In a simple extension this could be a loop over a list of pretrained recommender objects\n",
    "        item_weights_1 = self.recommender_1._compute_item_score(user_id_array)\n",
    "        item_weights_2 = self.recommender_2._compute_item_score(user_id_array)\n",
    "\n",
    "        item_weights = item_weights_1*self.alpha + item_weights_2*(1-self.alpha)\n",
    "\n",
    "        return item_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:52:37.662451Z",
     "iopub.status.busy": "2023-12-03T08:52:37.661898Z",
     "iopub.status.idle": "2023-12-03T08:52:37.672913Z",
     "shell.execute_reply": "2023-12-03T08:52:37.671825Z",
     "shell.execute_reply.started": "2023-12-03T08:52:37.662381Z"
    }
   },
   "outputs": [],
   "source": [
    "class LightFMCFRecommender(BaseRecommender):\n",
    "    \"\"\"LightFMCFRecommender\"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"LightFMCFRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train):\n",
    "        super(LightFMCFRecommender, self).__init__(URM_train)\n",
    "    \n",
    "    \n",
    "    def fit(self, epochs = 300, alpha = 1e-6, n_factors = 10, n_threads = 4, max_sampled=3, loss='warp', learning_schedule='adagrad'):\n",
    "        \n",
    "        # Let's fit a WARP model\n",
    "        self.lightFM_model = LightFM(loss=loss,\n",
    "                                     item_alpha=alpha,\n",
    "                                     no_components=n_factors,\n",
    "                                     max_sampled=max_sampled,\n",
    "                                     learning_schedule=learning_schedule)\n",
    "\n",
    "        self.lightFM_model = self.lightFM_model.fit(self.URM_train, \n",
    "                                       epochs=epochs,\n",
    "                                       num_threads=n_threads,\n",
    "                                       verbose=True)\n",
    "\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute = None):\n",
    "        \n",
    "        # Create a single (n_items, ) array with the item score, then copy it for every user\n",
    "        items_to_compute = np.arange(self.n_items)\n",
    "        \n",
    "        item_scores = - np.ones((len(user_id_array), self.n_items)) * np.inf\n",
    "\n",
    "        for user_index, user_id in enumerate(user_id_array):\n",
    "            item_scores[user_index] = self.lightFM_model.predict(int(user_id), \n",
    "                                                                 items_to_compute)\n",
    "\n",
    "        return item_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:52:37.674720Z",
     "iopub.status.busy": "2023-12-03T08:52:37.674363Z",
     "iopub.status.idle": "2023-12-03T08:52:37.686477Z",
     "shell.execute_reply": "2023-12-03T08:52:37.685455Z",
     "shell.execute_reply.started": "2023-12-03T08:52:37.674689Z"
    }
   },
   "outputs": [],
   "source": [
    "# !/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "\n",
    "class GeneralizedLinearHybridRecommender(BaseRecommender):\n",
    "    \"\"\"\n",
    "    This recommender merges N recommendes by weighting their ratings\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"GeneralizedLinearHybridRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, recommenders: list, verbose=True):\n",
    "        self.RECOMMENDER_NAME = ''\n",
    "        for recommender in recommenders:\n",
    "            self.RECOMMENDER_NAME = self.RECOMMENDER_NAME + recommender.RECOMMENDER_NAME[:-11]\n",
    "        self.RECOMMENDER_NAME = self.RECOMMENDER_NAME + 'HybridRecommender'\n",
    "\n",
    "        super(GeneralizedLinearHybridRecommender, self).__init__(URM_train, verbose=verbose)\n",
    "\n",
    "        self.recommenders = recommenders\n",
    "\n",
    "    def fit(self, alphas=None):\n",
    "        self.alphas = alphas\n",
    "\n",
    "    def save_model(self, folder_path, file_name=None):\n",
    "        pass\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute=None):\n",
    "        result = self.alphas[0]*self.recommenders[0]._compute_item_score(user_id_array,items_to_compute)\n",
    "        for index in range(1,len(self.alphas)):\n",
    "            result = result + self.alphas[index]*self.recommenders[index]._compute_item_score(user_id_array,items_to_compute)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:52:37.688320Z",
     "iopub.status.busy": "2023-12-03T08:52:37.687842Z",
     "iopub.status.idle": "2023-12-03T08:52:37.697787Z",
     "shell.execute_reply": "2023-12-03T08:52:37.696586Z",
     "shell.execute_reply.started": "2023-12-03T08:52:37.688276Z"
    }
   },
   "outputs": [],
   "source": [
    "ItemKNN_params = {\n",
    "    'topK': 11,\n",
    "    'shrink': 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:52:37.700140Z",
     "iopub.status.busy": "2023-12-03T08:52:37.699248Z",
     "iopub.status.idle": "2023-12-03T08:52:37.707910Z",
     "shell.execute_reply": "2023-12-03T08:52:37.706485Z",
     "shell.execute_reply.started": "2023-12-03T08:52:37.700089Z"
    }
   },
   "outputs": [],
   "source": [
    "RP3beta_params = {\n",
    "    'alpha': 0.307953246083667, \n",
    "    'beta': 0.3073797221110665, \n",
    "    'topK': 59, \n",
    "    'normalize_similarity': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:52:37.709519Z",
     "iopub.status.busy": "2023-12-03T08:52:37.709199Z",
     "iopub.status.idle": "2023-12-03T08:52:37.716049Z",
     "shell.execute_reply": "2023-12-03T08:52:37.715074Z",
     "shell.execute_reply.started": "2023-12-03T08:52:37.709469Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha_itemknn_rp3beta=0.8726915476982722"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:52:37.718722Z",
     "iopub.status.busy": "2023-12-03T08:52:37.717566Z",
     "iopub.status.idle": "2023-12-03T08:52:37.724410Z",
     "shell.execute_reply": "2023-12-03T08:52:37.723602Z",
     "shell.execute_reply.started": "2023-12-03T08:52:37.718678Z"
    }
   },
   "outputs": [],
   "source": [
    "UserKNN_params = {\n",
    "    'shrink':0,\n",
    "    'topK':313\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:55:33.567323Z",
     "iopub.status.busy": "2023-12-03T08:55:33.566857Z",
     "iopub.status.idle": "2023-12-03T08:55:33.573321Z",
     "shell.execute_reply": "2023-12-03T08:55:33.571987Z",
     "shell.execute_reply.started": "2023-12-03T08:55:33.567285Z"
    }
   },
   "outputs": [],
   "source": [
    "LightFM_params = {\n",
    "                  'no_components': 482,\n",
    "                  'max_sampled': 5,\n",
    "                  'user_alpha': 0.00023989649900734266,\n",
    "                  'item_alpha': 9.740651135253414e-05\n",
    "                 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightFM Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T14:27:07.873857Z",
     "iopub.status.busy": "2023-12-01T14:27:07.873041Z",
     "iopub.status.idle": "2023-12-01T14:27:07.886245Z",
     "shell.execute_reply": "2023-12-01T14:27:07.885179Z",
     "shell.execute_reply.started": "2023-12-01T14:27:07.873806Z"
    }
   },
   "outputs": [],
   "source": [
    "class SaveResults(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.results_df = pd.DataFrame(columns=[\"result\"])\n",
    "\n",
    "    def __call__(self, optuna_study, optuna_trial):\n",
    "        hyperparam_dict = optuna_trial.params.copy()\n",
    "        hyperparam_dict[\"result\"] = optuna_trial.values[0]\n",
    "\n",
    "        # Create a DataFrame from the current trial's results\n",
    "        trial_df = pd.DataFrame([hyperparam_dict])\n",
    "\n",
    "        # Use concat instead of append\n",
    "        self.results_df = pd.concat([self.results_df, trial_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T14:27:07.888913Z",
     "iopub.status.busy": "2023-12-01T14:27:07.888105Z",
     "iopub.status.idle": "2023-12-01T14:27:07.906661Z",
     "shell.execute_reply": "2023-12-01T14:27:07.905584Z",
     "shell.execute_reply.started": "2023-12-01T14:27:07.888863Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective_function_lightfm(optuna_trial):\n",
    "    recommender_instance = LightFM(no_components=optuna_trial.suggest_int(\"no_components\", 150, 500),\n",
    "                                    max_sampled=optuna_trial.suggest_int(\"max_sampled\", 3, 7),\n",
    "                                    loss='warp',\n",
    "                                    learning_schedule='adagrad',\n",
    "                                    user_alpha=optuna_trial.suggest_float(\"l2_user\", 1e-6, 1e-3),\n",
    "                                    item_alpha=optuna_trial.suggest_float(\"l2_item\", 1e-7, 1e-4)) # Lower for better training\n",
    "    recommender_instance.fit(\n",
    "                             interactions=urm_train,\n",
    "                             epochs=60,\n",
    "                             verbose=True\n",
    "                            )\n",
    "\n",
    "    result_df = precision_at_k(recommender_instance, urm_validation, train_interactions=urm_train, k=10).mean()\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T14:27:07.909261Z",
     "iopub.status.busy": "2023-12-01T14:27:07.908408Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optuna_study_lightfm = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "save_results_lightfm = SaveResults()\n",
    "\n",
    "optuna_study_lightfm.optimize(objective_function_lightfm,\n",
    "                      callbacks=[save_results_lightfm],\n",
    "                      n_trials = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_trials = [t for t in optuna_study_lightfm.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in optuna_study_lightfm.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(optuna_study_lightfm.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(\"  Value Validation: \", optuna_study_lightfm.best_trial.value)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(optuna_study_lightfm.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting curve eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T08:56:24.208962Z",
     "iopub.status.busy": "2023-12-03T08:56:24.208478Z",
     "iopub.status.idle": "2023-12-03T11:23:16.886680Z",
     "shell.execute_reply": "2023-12-03T11:23:16.885209Z",
     "shell.execute_reply.started": "2023-12-03T08:56:24.208917Z"
    }
   },
   "outputs": [],
   "source": [
    "warp_model = LightFM(**LightFM_params)\n",
    "\n",
    "warp_duration = []\n",
    "warp_auc = []\n",
    "epochs=100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"{epoch}/{epochs}\")\n",
    "    start = time.time()\n",
    "    warp_model.fit_partial(urm_train, epochs=1)\n",
    "    warp_duration.append(time.time() - start)\n",
    "    warp_auc.append(auc_score(warp_model, urm_test, train_interactions=urm_train).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T11:23:16.889122Z",
     "iopub.status.busy": "2023-12-03T11:23:16.888746Z",
     "iopub.status.idle": "2023-12-03T11:23:17.123290Z",
     "shell.execute_reply": "2023-12-03T11:23:17.122132Z",
     "shell.execute_reply.started": "2023-12-03T11:23:16.889087Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(epochs)\n",
    "plt.plot(x, np.array(warp_auc))\n",
    "plt.legend(['WARP AUC'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4086250,
     "sourceId": 7091045,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30350,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
