{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:54:01.144045Z",
     "iopub.status.busy": "2024-01-08T13:54:01.143427Z",
     "iopub.status.idle": "2024-01-08T13:54:01.181234Z",
     "shell.execute_reply": "2024-01-08T13:54:01.180040Z",
     "shell.execute_reply.started": "2024-01-08T13:54:01.143990Z"
    }
   },
   "outputs": [],
   "source": [
    "LOAD_MODELS = False\n",
    "RUN_NUM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T21:50:39.483389Z",
     "iopub.status.busy": "2023-12-30T21:50:39.482674Z",
     "iopub.status.idle": "2023-12-30T21:50:43.157070Z",
     "shell.execute_reply": "2023-12-30T21:50:43.155790Z",
     "shell.execute_reply.started": "2023-12-30T21:50:39.483353Z"
    }
   },
   "outputs": [],
   "source": [
    "!cp -r ../input/updated-code-3-7/* /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:54:04.041599Z",
     "iopub.status.busy": "2024-01-08T13:54:04.041145Z",
     "iopub.status.idle": "2024-01-08T13:54:46.378803Z",
     "shell.execute_reply": "2024-01-08T13:54:46.376493Z",
     "shell.execute_reply.started": "2024-01-08T13:54:04.041568Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Cython in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (3.9.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (3.2.4)\n",
      "Requirement already satisfied: nose in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.3.7)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (1.2.2)\n",
      "Requirement already satisfied: scikit-optimize in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.9.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.11.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (4.66.1)\n",
      "Collecting lightfm (from -r requirements.txt (line 10))\n",
      "  Downloading lightfm-1.17.tar.gz (316 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.4/316.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting RISE (from -r requirements.txt (line 11))\n",
      "  Downloading rise-5.7.1-py2.py3-none-any.whl (4.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (2.0.0+cpu)\n",
      "Collecting jupyter-contrib-nbextensions (from -r requirements.txt (line 13))\n",
      "  Downloading jupyter_contrib_nbextensions-0.7.0.tar.gz (23.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (2.13.0)\n",
      "Requirement already satisfied: tables in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (3.9.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 6)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 6)) (3.2.0)\n",
      "Requirement already satisfied: pyaml>=16.9 in /opt/conda/lib/python3.10/site-packages (from scikit-optimize->-r requirements.txt (line 7)) (23.9.7)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from lightfm->-r requirements.txt (line 10)) (2.31.0)\n",
      "Requirement already satisfied: notebook>=6.0 in /opt/conda/lib/python3.10/site-packages (from RISE->-r requirements.txt (line 11)) (6.5.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 12)) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 12)) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 12)) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 12)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 12)) (3.1.2)\n",
      "Requirement already satisfied: ipython_genutils in /opt/conda/lib/python3.10/site-packages (from jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (0.2.0)\n",
      "Collecting jupyter_contrib_core>=0.3.3 (from jupyter-contrib-nbextensions->-r requirements.txt (line 13))\n",
      "  Downloading jupyter_contrib_core-0.4.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: jupyter_core in /opt/conda/lib/python3.10/site-packages (from jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (5.3.1)\n",
      "Collecting jupyter_highlight_selected_word>=0.1.1 (from jupyter-contrib-nbextensions->-r requirements.txt (line 13))\n",
      "  Downloading jupyter_highlight_selected_word-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting jupyter_nbextensions_configurator>=0.4.0 (from jupyter-contrib-nbextensions->-r requirements.txt (line 13))\n",
      "  Downloading jupyter_nbextensions_configurator-0.6.3-py2.py3-none-any.whl (466 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.9/466.9 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nbconvert>=6.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (6.4.5)\n",
      "Requirement already satisfied: tornado in /opt/conda/lib/python3.10/site-packages (from jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (6.3.3)\n",
      "Requirement already satisfied: traitlets>=4.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (5.9.0)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (4.9.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 14)) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 14)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 14)) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 14)) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 14)) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 14)) (1.57.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 14)) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 14)) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 14)) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 14)) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 14)) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 14)) (68.1.2)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 14)) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 14)) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 14)) (2.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 14)) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->-r requirements.txt (line 14)) (0.34.0)\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /opt/conda/lib/python3.10/site-packages (from tables->-r requirements.txt (line 15)) (2.8.8)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from tables->-r requirements.txt (line 15)) (9.0.0)\n",
      "Requirement already satisfied: blosc2>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from tables->-r requirements.txt (line 15)) (2.3.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 14)) (0.41.2)\n",
      "Requirement already satisfied: ndindex>=1.4 in /opt/conda/lib/python3.10/site-packages (from blosc2>=2.3.0->tables->-r requirements.txt (line 15)) (1.7)\n",
      "Requirement already satisfied: msgpack in /opt/conda/lib/python3.10/site-packages (from blosc2>=2.3.0->tables->-r requirements.txt (line 15)) (1.0.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from jupyter_nbextensions_configurator>=0.4.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (6.0.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (0.8.4)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (2.16.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (0.2.2)\n",
      "Requirement already satisfied: nbformat>=4.4 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (5.9.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (0.4)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (6.0.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (1.5.0)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (0.6.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (0.7.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (4.12.2)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (0.5.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (2.1.3)\n",
      "Requirement already satisfied: pyzmq<25,>=17 in /opt/conda/lib/python3.10/site-packages (from notebook>=6.0->RISE->-r requirements.txt (line 11)) (24.0.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from notebook>=6.0->RISE->-r requirements.txt (line 11)) (21.3.0)\n",
      "Requirement already satisfied: jupyter-client<8,>=5.3.4 in /opt/conda/lib/python3.10/site-packages (from notebook>=6.0->RISE->-r requirements.txt (line 11)) (7.4.9)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.10/site-packages (from notebook>=6.0->RISE->-r requirements.txt (line 11)) (1.5.6)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.10/site-packages (from notebook>=6.0->RISE->-r requirements.txt (line 11)) (6.25.1)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from notebook>=6.0->RISE->-r requirements.txt (line 11)) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from notebook>=6.0->RISE->-r requirements.txt (line 11)) (0.17.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from notebook>=6.0->RISE->-r requirements.txt (line 11)) (0.17.1)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.10/site-packages (from notebook>=6.0->RISE->-r requirements.txt (line 11)) (1.0.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter_core->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (4.1.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 14)) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 14)) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 14)) (3.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 14)) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 14)) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->lightfm->-r requirements.txt (line 10)) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->lightfm->-r requirements.txt (line 10)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->lightfm->-r requirements.txt (line 10)) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->lightfm->-r requirements.txt (line 10)) (2023.11.17)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow->-r requirements.txt (line 14)) (3.0.9)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 12)) (1.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 14)) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 14)) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 14)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 14)) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from jupyter-client<8,>=5.3.4->notebook>=6.0->RISE->-r requirements.txt (line 11)) (2.8.2)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=6.0->RISE->-r requirements.txt (line 11)) (2.12.1)\n",
      "Requirement already satisfied: notebook-shim>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=6.0->RISE->-r requirements.txt (line 11)) (0.2.3)\n",
      "Requirement already satisfied: fastjsonschema in /opt/conda/lib/python3.10/site-packages (from nbformat>=4.4->nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (2.18.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.10/site-packages (from nbformat>=4.4->nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (4.19.0)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/lib/python3.10/site-packages (from terminado>=0.8.3->notebook>=6.0->RISE->-r requirements.txt (line 11)) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->notebook>=6.0->RISE->-r requirements.txt (line 11)) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (0.5.1)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel->notebook>=6.0->RISE->-r requirements.txt (line 11)) (0.1.4)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel->notebook>=6.0->RISE->-r requirements.txt (line 11)) (1.6.7.post1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel->notebook>=6.0->RISE->-r requirements.txt (line 11)) (8.14.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel->notebook>=6.0->RISE->-r requirements.txt (line 11)) (0.1.6)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ipykernel->notebook>=6.0->RISE->-r requirements.txt (line 11)) (5.9.3)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->notebook>=6.0->RISE->-r requirements.txt (line 11)) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->notebook>=6.0->RISE->-r requirements.txt (line 11)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->notebook>=6.0->RISE->-r requirements.txt (line 11)) (0.19.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->notebook>=6.0->RISE->-r requirements.txt (line 11)) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->notebook>=6.0->RISE->-r requirements.txt (line 11)) (3.0.39)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->notebook>=6.0->RISE->-r requirements.txt (line 11)) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->notebook>=6.0->RISE->-r requirements.txt (line 11)) (4.8.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (0.9.2)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=6.0->RISE->-r requirements.txt (line 11)) (3.7.1)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=6.0->RISE->-r requirements.txt (line 11)) (0.9.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=6.0->RISE->-r requirements.txt (line 11)) (0.4.4)\n",
      "Requirement already satisfied: overrides in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=6.0->RISE->-r requirements.txt (line 11)) (6.5.0)\n",
      "Requirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=6.0->RISE->-r requirements.txt (line 11)) (1.6.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 14)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow->-r requirements.txt (line 14)) (3.2.2)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=6.0->RISE->-r requirements.txt (line 11)) (1.15.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=6.0->RISE->-r requirements.txt (line 11)) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=6.0->RISE->-r requirements.txt (line 11)) (1.1.3)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=6.0->RISE->-r requirements.txt (line 11)) (2.21)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->notebook>=6.0->RISE->-r requirements.txt (line 11)) (0.8.3)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=6.0->RISE->-r requirements.txt (line 11)) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=6.0->RISE->-r requirements.txt (line 11)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=6.0->RISE->-r requirements.txt (line 11)) (0.1.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.23.1->ipykernel->notebook>=6.0->RISE->-r requirements.txt (line 11)) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->notebook>=6.0->RISE->-r requirements.txt (line 11)) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->notebook>=6.0->RISE->-r requirements.txt (line 11)) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->notebook>=6.0->RISE->-r requirements.txt (line 11)) (0.2.2)\n",
      "Requirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (2.0)\n",
      "Requirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (1.13)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema>=2.6->nbformat>=4.4->nbconvert>=6.0->jupyter-contrib-nbextensions->-r requirements.txt (line 13)) (1.2.3)\n",
      "Building wheels for collected packages: lightfm, jupyter-contrib-nbextensions, jupyter_contrib_core\n",
      "  Building wheel for lightfm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lightfm: filename=lightfm-1.17-cp310-cp310-linux_x86_64.whl size=464219 sha256=b60bbf59a91199c2d801f5f00bc165d87489867df1b023947938504bbead4681\n",
      "  Stored in directory: /root/.cache/pip/wheels/4f/9b/7e/0b256f2168511d8fa4dae4fae0200fdbd729eb424a912ad636\n",
      "  Building wheel for jupyter-contrib-nbextensions (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jupyter-contrib-nbextensions: filename=jupyter_contrib_nbextensions-0.7.0-py2.py3-none-any.whl size=23428781 sha256=67bc91f17646b81814d328ee017e5b6a1b7b5705b2f3c149adad6e708cbea478\n",
      "  Stored in directory: /root/.cache/pip/wheels/ea/cc/7d/99ef154f984726b1201c0f72cfe9c9d7c5132c1a2ae4d8677f\n",
      "  Building wheel for jupyter_contrib_core (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jupyter_contrib_core: filename=jupyter_contrib_core-0.4.2-py2.py3-none-any.whl size=17484 sha256=329421f7d6df0163fd9a49f64c9b9db101acc77cebc4d996483eb219be6dc8a8\n",
      "  Stored in directory: /root/.cache/pip/wheels/a9/52/88/e0643cdfd68f0562087918c37dd583378648dbc3df68b907f7\n",
      "Successfully built lightfm jupyter-contrib-nbextensions jupyter_contrib_core\n",
      "Installing collected packages: jupyter_highlight_selected_word, lightfm, RISE, jupyter_contrib_core, jupyter_nbextensions_configurator, jupyter-contrib-nbextensions\n",
      "Successfully installed RISE-5.7.1 jupyter-contrib-nbextensions-0.7.0 jupyter_contrib_core-0.4.2 jupyter_highlight_selected_word-0.2.0 jupyter_nbextensions_configurator-0.6.3 lightfm-1.17\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:54:46.384369Z",
     "iopub.status.busy": "2024-01-08T13:54:46.382197Z",
     "iopub.status.idle": "2024-01-08T13:55:03.175749Z",
     "shell.execute_reply": "2024-01-08T13:55:03.174259Z",
     "shell.execute_reply.started": "2024-01-08T13:54:46.384296Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightfm in /opt/conda/lib/python3.10/site-packages (1.17)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.1)\n",
      "Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (3.5.0)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.10/site-packages (6.25.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.4)\n",
      "Collecting implicit\n",
      "  Obtaining dependency information for implicit from https://files.pythonhosted.org/packages/cd/cc/deac70cae8cc32c9885d0cd73bc66e1b3cbea36ae7080b8c83995eaf5322/implicit-0.7.2-cp310-cp310-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading implicit-0.7.2-cp310-cp310-manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from lightfm) (1.24.3)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from lightfm) (1.11.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from lightfm) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from lightfm) (1.2.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.13.0)\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.20)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel) (0.1.4)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel) (1.6.7.post1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel) (8.14.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel) (7.4.9)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel) (5.3.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ipykernel) (1.5.6)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ipykernel) (5.9.3)\n",
      "Requirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.10/site-packages (from ipykernel) (24.0.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel) (6.3.3)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/conda/lib/python3.10/site-packages (from ipykernel) (5.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl in /opt/conda/lib/python3.10/site-packages (from implicit) (3.2.0)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (0.19.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (4.8.0)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel) (0.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->lightfm) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->lightfm) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->lightfm) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->lightfm) (2023.11.17)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->lightfm) (1.3.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.23.1->ipykernel) (0.2.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n",
      "Downloading implicit-0.7.2-cp310-cp310-manylinux2014_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: implicit\n",
      "Successfully installed implicit-0.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install lightfm tqdm optuna ipykernel matplotlib implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-31T16:40:39.533010Z",
     "iopub.status.busy": "2023-12-31T16:40:39.532565Z",
     "iopub.status.idle": "2023-12-31T16:42:01.495780Z",
     "shell.execute_reply": "2023-12-31T16:42:01.494178Z",
     "shell.execute_reply.started": "2023-12-31T16:40:39.532965Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_compile_all_cython: Found 10 Cython files in 4 folders...\n",
      "run_compile_all_cython: All files will be compiled using your current python environment: '/opt/conda/bin/python'\n",
      "Compiling [1/10]: MatrixFactorization_Cython_Epoch.pyx... \n",
      "/opt/conda/lib/python3.10/site-packages/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /kaggle/working/Recommenders/MatrixFactorization/Cython/MatrixFactorization_Cython_Epoch.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "Compiling [1/10]: MatrixFactorization_Cython_Epoch.pyx... PASS\n",
      "\n",
      "Compiling [2/10]: MatrixFactorizationImpressions_Cython_Epoch.pyx... \n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.10/site-packages/numpy/core/include/numpy/ndarraytypes.h:1940\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.10/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.10/site-packages/numpy/core/include/numpy/arrayobject.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:1084\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.10/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:\u001b[m\u001b[K In function '\u001b[01m\u001b[K__pyx_f_43MatrixFactorizationImpressions_Cython_Epoch_32MatrixFactorization_Cython_Epoch_sampleBPR_Cython\u001b[m\u001b[K':\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:29420:17:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[K__pyx_v_start_pos_impression_items\u001b[m\u001b[K' may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "29420 |       \u001b[01;35m\u001b[K__pyx_t_4 = (__pyx_v_start_pos_impression_items + __pyx_v_index)\u001b[m\u001b[K;\n",
      "      |       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:\u001b[m\u001b[K In function '\u001b[01m\u001b[K__pyx_pf_43MatrixFactorizationImpressions_Cython_Epoch_32MatrixFactorization_Cython_Epoch_10epochIteration_Cython_ASY_SVD_SGD\u001b[m\u001b[K':\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:25256:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[K__pyx_v_end_pos_seen_items\u001b[m\u001b[K' may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "25256 |       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K (__pyx_t_20 = __pyx_v_start_pos_seen_items; __pyx_t_20 < __pyx_t_19; __pyx_t_20+=1) {\n",
      "      |       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:25256:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[K__pyx_v_start_pos_seen_items\u001b[m\u001b[K' may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "/opt/conda/lib/python3.10/site-packages/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /kaggle/working/Recommenders/MatrixFactorization/Cython/MatrixFactorizationImpressions_Cython_Epoch.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "Compiling [2/10]: MatrixFactorizationImpressions_Cython_Epoch.pyx... PASS\n",
      "\n",
      "Compiling [3/10]: Compute_Similarity_Cython.pyx... \n",
      "/opt/conda/lib/python3.10/site-packages/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /kaggle/working/Recommenders/Similarity/Cython/Compute_Similarity_Cython.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "Compiling [3/10]: Compute_Similarity_Cython.pyx... PASS\n",
      "\n",
      "Compiling [4/10]: Triangular_Matrix.pyx... \n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.10/site-packages/numpy/core/include/numpy/ndarraytypes.h:1940\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.10/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.10/site-packages/numpy/core/include/numpy/arrayobject.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[KTriangular_Matrix.c:1109\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.10/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "/opt/conda/lib/python3.10/site-packages/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /kaggle/working/Recommenders/SLIM/Cython/Triangular_Matrix.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "Compiling [4/10]: Triangular_Matrix.pyx... PASS\n",
      "\n",
      "Compiling [5/10]: SLIM_BPR_Cython_Epoch.pyx... \n",
      "/opt/conda/lib/python3.10/site-packages/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /kaggle/working/Recommenders/SLIM/Cython/SLIM_BPR_Cython_Epoch.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:626:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:626:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:811:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:811:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:910:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:910:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:910:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1045:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1045:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1046:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1046:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "Compiling [5/10]: SLIM_BPR_Cython_Epoch.pyx... PASS\n",
      "\n",
      "Compiling [6/10]: Sparse_Matrix_Tree_CSR.pyx... \n",
      "/opt/conda/lib/python3.10/site-packages/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /kaggle/working/Recommenders/SLIM/Cython/Sparse_Matrix_Tree_CSR.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "Compiling [6/10]: Sparse_Matrix_Tree_CSR.pyx... PASS\n",
      "\n",
      "Compiling [7/10]: HP3_Similarity_Cython_SGD.pyx... \n",
      "warning: HP3_Similarity_Cython_SGD.pyx:113:40: Index should be typed for more efficient access\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.10/site-packages/numpy/core/include/numpy/ndarraytypes.h:1940\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.10/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.10/site-packages/numpy/core/include/numpy/arrayobject.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[KHP3_Similarity_Cython_SGD.c:1109\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.10/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[KHP3_Similarity_Cython_SGD.c:\u001b[m\u001b[K In function '\u001b[01m\u001b[K__pyx_pf_25HP3_Similarity_Cython_SGD_25HP3_Similarity_Cython_SGD_4fit\u001b[m\u001b[K':\n",
      "\u001b[01m\u001b[KHP3_Similarity_Cython_SGD.c:22910:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[K__pyx_v_sample_num\u001b[m\u001b[K' may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "22910 |   __pyx_t_2 = PyFloat_FromDouble((__pyx_v_cum_loss / \u001b[01;35m\u001b[K((double)__pyx_v_sample_num)\u001b[m\u001b[K)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 291, __pyx_L1_error)\n",
      "      |                                                      \u001b[01;35m\u001b[K~^~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "/opt/conda/lib/python3.10/site-packages/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/HP3_Similarity_Cython_SGD.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "warning: HP3_Similarity_Cython_SGD.pyx:113:40: Index should be typed for more efficient access\n",
      "Compiling [7/10]: HP3_Similarity_Cython_SGD.pyx... PASS\n",
      "\n",
      "Compiling [8/10]: FBSM_Rating_Cython_SGD.pyx... \n",
      "/opt/conda/lib/python3.10/site-packages/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/FBSM_Rating_Cython_SGD.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "Compiling [8/10]: FBSM_Rating_Cython_SGD.pyx... PASS\n",
      "\n",
      "Compiling [9/10]: CFW_DVV_Similarity_Cython_SGD.pyx... \n",
      "/opt/conda/lib/python3.10/site-packages/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/CFW_DVV_Similarity_Cython_SGD.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "Compiling [9/10]: CFW_DVV_Similarity_Cython_SGD.pyx... PASS\n",
      "\n",
      "Compiling [10/10]: CFW_D_Similarity_Cython_SGD.pyx... \n",
      "/opt/conda/lib/python3.10/site-packages/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/CFW_D_Similarity_Cython_SGD.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "Compiling [10/10]: CFW_D_Similarity_Cython_SGD.pyx... PASS\n",
      "\n",
      "run_compile_all_cython: Compilation finished. SUCCESS.\n",
      "Compilation log can be found here: './result_experiments/run_compile_all_cython.txt'\n"
     ]
    }
   ],
   "source": [
    "!python run_compile_all_cython.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:03.178121Z",
     "iopub.status.busy": "2024-01-08T13:55:03.177671Z",
     "iopub.status.idle": "2024-01-08T13:55:05.973082Z",
     "shell.execute_reply": "2024-01-08T13:55:05.971868Z",
     "shell.execute_reply.started": "2024-01-08T13:55:03.178083Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "from scipy.sparse import vstack, csr_matrix\n",
    "from scipy.stats import loguniform\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score, precision_at_k\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import cpu_count\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "seed = 69\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:05.976656Z",
     "iopub.status.busy": "2024-01-08T13:55:05.975751Z",
     "iopub.status.idle": "2024-01-08T13:55:07.019743Z",
     "shell.execute_reply": "2024-01-08T13:55:07.018240Z",
     "shell.execute_reply.started": "2024-01-08T13:55:05.976615Z"
    }
   },
   "outputs": [],
   "source": [
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "from Recommenders.BaseMatrixFactorizationRecommender import BaseMatrixFactorizationRecommender\n",
    "from Recommenders.NonPersonalizedRecommender import TopPop\n",
    "\n",
    "#---- CF\n",
    "from Recommenders.KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "from Recommenders.KNN.UserKNNCFRecommender import UserKNNCFRecommender\n",
    "from Recommenders.GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "from Recommenders.KNN.ItemKNNCustomSimilarityRecommender import ItemKNNCustomSimilarityRecommender\n",
    "\n",
    "#---- Matrix Factorization\n",
    "from Recommenders.MatrixFactorization.NMFRecommender import NMFRecommender\n",
    "\n",
    "#---- CF w/ ML\n",
    "from Recommenders.SLIM.SLIMElasticNetRecommender import SLIMElasticNetRecommender, MultiThreadSLIM_SLIMElasticNetRecommender\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "#---- Gradient Boosting\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRanker\n",
    "\n",
    "#---- Others\n",
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "from Recommenders.Recommender_utils import check_matrix\n",
    "from implicit.utils import check_csr\n",
    "from Recommenders.DataIO import DataIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Versioning (For Model + Split saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.022565Z",
     "iopub.status.busy": "2024-01-08T13:55:07.021680Z",
     "iopub.status.idle": "2024-01-08T13:55:07.029670Z",
     "shell.execute_reply": "2024-01-08T13:55:07.028352Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.022512Z"
    }
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"Runs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T14:18:37.189383Z",
     "iopub.status.busy": "2024-01-07T14:18:37.189059Z",
     "iopub.status.idle": "2024-01-07T14:18:37.198290Z",
     "shell.execute_reply": "2024-01-07T14:18:37.197427Z",
     "shell.execute_reply.started": "2024-01-07T14:18:37.189354Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_next_folder_number(base_dir):\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "\n",
    "    existing_folders = [f for f in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, f))]\n",
    "    existing_numbers = [int(f[1:]) for f in existing_folders if f.startswith('#') and f[1:].isdigit()]\n",
    "\n",
    "    next_number = 1\n",
    "    if existing_numbers:\n",
    "        next_number = max(existing_numbers) + 1\n",
    "\n",
    "    return f\"#{next_number}\"\n",
    "\n",
    "def create_versioned_folder(base_dir):\n",
    "    folder_name = get_next_folder_number(base_dir)\n",
    "    new_folder_path = os.path.join(base_dir, folder_name)\n",
    "    os.makedirs(new_folder_path)\n",
    "    return new_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T23:25:53.484431Z",
     "iopub.status.busy": "2024-01-03T23:25:53.484102Z",
     "iopub.status.idle": "2024-01-03T23:25:53.498831Z",
     "shell.execute_reply": "2024-01-03T23:25:53.497550Z",
     "shell.execute_reply.started": "2024-01-03T23:25:53.484395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New folder created: Runs/#2\n"
     ]
    }
   ],
   "source": [
    "run_folder = create_versioned_folder(BASE_DIR)\n",
    "print(f\"New folder created: {run_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T23:25:53.500195Z",
     "iopub.status.busy": "2024-01-03T23:25:53.499878Z",
     "iopub.status.idle": "2024-01-03T23:25:56.519621Z",
     "shell.execute_reply": "2024-01-03T23:25:56.518833Z",
     "shell.execute_reply.started": "2024-01-03T23:25:53.500171Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import training data\n",
    "URM_path = \"../input/data-books/data_train.csv\"\n",
    "URM_all_dataframe = pd.read_csv(filepath_or_buffer=URM_path,\n",
    "                                header=0,\n",
    "                                dtype={0:int, 1:int, 2:int},\n",
    "                                engine='python')\n",
    "\n",
    "URM_all_dataframe.columns = [\"user_id\", \"item_id\", \"interaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T23:25:56.521039Z",
     "iopub.status.busy": "2024-01-03T23:25:56.520761Z",
     "iopub.status.idle": "2024-01-03T23:25:56.574460Z",
     "shell.execute_reply": "2024-01-03T23:25:56.573561Z",
     "shell.execute_reply.started": "2024-01-03T23:25:56.521015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10877</th>\n",
       "      <td>13020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10878</th>\n",
       "      <td>13021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10879</th>\n",
       "      <td>13022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10880</th>\n",
       "      <td>13023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10881</th>\n",
       "      <td>13024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10882 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id\n",
       "0            1\n",
       "1            2\n",
       "2            3\n",
       "3            4\n",
       "4            5\n",
       "...        ...\n",
       "10877    13020\n",
       "10878    13021\n",
       "10879    13022\n",
       "10880    13023\n",
       "10881    13024\n",
       "\n",
       "[10882 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import target users\n",
    "target_path = \"../input/data-books/data_target_users_test.csv\"\n",
    "target_dataframe= pd.read_csv(filepath_or_buffer=target_path,\n",
    "                                header=0,\n",
    "                                dtype={0:int},\n",
    "                                engine='python')\n",
    "target_dataframe.columns = [\"user_id\"]\n",
    "target_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T23:25:56.579067Z",
     "iopub.status.busy": "2024-01-03T23:25:56.578792Z",
     "iopub.status.idle": "2024-01-03T23:25:56.586601Z",
     "shell.execute_reply": "2024-01-03T23:25:56.585634Z",
     "shell.execute_reply.started": "2024-01-03T23:25:56.579043Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(ratings: pd.DataFrame):\n",
    "    unique_users = ratings.user_id.unique()\n",
    "    unique_items = ratings.item_id.unique()\n",
    "\n",
    "    num_users, min_user_id, max_user_id = unique_users.size, unique_users.min(), unique_users.max()\n",
    "    num_items, min_item_id, max_item_id = unique_items.size, unique_items.min(), unique_items.max()\n",
    "\n",
    "    print(num_users, min_user_id, max_user_id)\n",
    "    print(num_items, min_item_id, max_item_id)\n",
    "\n",
    "    mapping_user_id = pd.DataFrame({\"mapped_user_id\": np.arange(num_users), \"user_id\": unique_users})\n",
    "    mapping_item_id = pd.DataFrame({\"mapped_item_id\": np.arange(num_items), \"item_id\": unique_items})\n",
    "\n",
    "    ratings = pd.merge(left=ratings,\n",
    "                       right=mapping_user_id,\n",
    "                       how=\"inner\",\n",
    "                       on=\"user_id\")\n",
    "\n",
    "    ratings = pd.merge(left=ratings,\n",
    "                       right=mapping_item_id,\n",
    "                       how=\"inner\",\n",
    "                       on=\"item_id\")\n",
    "\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T23:25:56.587962Z",
     "iopub.status.busy": "2024-01-03T23:25:56.587634Z",
     "iopub.status.idle": "2024-01-03T23:25:56.724743Z",
     "shell.execute_reply": "2024-01-03T23:25:56.723805Z",
     "shell.execute_reply.started": "2024-01-03T23:25:56.587938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12638 1 13024\n",
      "22222 1 22347\n"
     ]
    }
   ],
   "source": [
    "# Call preprocess data function\n",
    "ratings = preprocess_data(URM_all_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion to Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T23:25:56.726740Z",
     "iopub.status.busy": "2024-01-03T23:25:56.726171Z",
     "iopub.status.idle": "2024-01-03T23:25:56.732832Z",
     "shell.execute_reply": "2024-01-03T23:25:56.731868Z",
     "shell.execute_reply.started": "2024-01-03T23:25:56.726713Z"
    }
   },
   "outputs": [],
   "source": [
    "URM = sps.coo_matrix((ratings.interaction.values, (ratings.mapped_user_id.values, ratings.mapped_item_id.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T23:25:56.734193Z",
     "iopub.status.busy": "2024-01-03T23:25:56.733930Z",
     "iopub.status.idle": "2024-01-03T23:25:56.743122Z",
     "shell.execute_reply": "2024-01-03T23:25:56.742053Z",
     "shell.execute_reply.started": "2024-01-03T23:25:56.734169Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_urm_in_k_folds(URM_all, k):\n",
    "    from Data_manager.IncrementalSparseMatrix import IncrementalSparseMatrix\n",
    "    num_users, num_items = URM_all.shape\n",
    "\n",
    "    URM_train = sps.coo_matrix(URM_all)\n",
    "\n",
    "    indices_for_sampling = np.arange(0, URM_all.nnz, dtype=int)\n",
    "    np.random.shuffle(indices_for_sampling)\n",
    "\n",
    "    indices_for_sampling = np.array_split(indices_for_sampling, k)\n",
    "    np.random.shuffle(indices_for_sampling)\n",
    "    k_URM = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        URM_builder = IncrementalSparseMatrix(n_rows=num_users, n_cols=num_items, auto_create_col_mapper=False, auto_create_row_mapper=False)\n",
    "        URM_builder.add_data_lists(URM_train.row[indices_for_sampling[i]],\n",
    "                                             URM_train.col[indices_for_sampling[i]],\n",
    "                                             URM_train.data[indices_for_sampling[i]])\n",
    "\n",
    "        k_URM.append(sps.csr_matrix(URM_builder.get_SparseMatrix()))\n",
    "\n",
    "    #verify that the sum of the URM_train_matrices is equal to the original URM\n",
    "    k_URM_sum = sps.csr_matrix((num_users, num_items))\n",
    "    for URM_train_matrices_single in k_URM:\n",
    "        k_URM_sum += URM_train_matrices_single\n",
    "    \n",
    "    assert k_URM_sum.nnz == URM_all.nnz, \"split_train_in_k_percentage_global_sample: URM_train_matrices_sum doesn't match URM_all\"\n",
    "\n",
    "\n",
    "    return k_URM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T23:25:56.744783Z",
     "iopub.status.busy": "2024-01-03T23:25:56.744433Z",
     "iopub.status.idle": "2024-01-03T23:25:56.756586Z",
     "shell.execute_reply": "2024-01-03T23:25:56.755728Z",
     "shell.execute_reply.started": "2024-01-03T23:25:56.744750Z"
    }
   },
   "outputs": [],
   "source": [
    "#urm_train, urm_test = split_train_in_two_percentage_global_sample(URM, train_percentage = 0.80)\n",
    "#urm_train, urm_validation = split_train_in_two_percentage_global_sample(URM, train_percentage = 0.80)\n",
    "\n",
    "#evaluator_validation = EvaluatorHoldout(urm_validation, cutoff_list=[10])\n",
    "#evaluator_test = EvaluatorHoldout(urm_test, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T23:25:56.758200Z",
     "iopub.status.busy": "2024-01-03T23:25:56.757859Z",
     "iopub.status.idle": "2024-01-03T23:25:58.076496Z",
     "shell.execute_reply": "2024-01-03T23:25:58.075516Z",
     "shell.execute_reply.started": "2024-01-03T23:25:56.758167Z"
    }
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "splits = split_urm_in_k_folds(URM, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T23:25:58.078142Z",
     "iopub.status.busy": "2024-01-03T23:25:58.077792Z",
     "iopub.status.idle": "2024-01-03T23:25:58.104649Z",
     "shell.execute_reply": "2024-01-03T23:25:58.103623Z",
     "shell.execute_reply.started": "2024-01-03T23:25:58.078105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Ignoring 3623 (28.7%) Users that have less than 1 test interactions\n"
     ]
    }
   ],
   "source": [
    "urm_train = sum(splits[:7])\n",
    "urm_val = sum(splits[7:9])\n",
    "urm_test = splits[9]\n",
    "evaluator_test = EvaluatorHoldout(urm_test, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-03T23:25:58.106298Z",
     "iopub.status.busy": "2024-01-03T23:25:58.105933Z",
     "iopub.status.idle": "2024-01-03T23:25:58.432165Z",
     "shell.execute_reply": "2024-01-03T23:25:58.431187Z",
     "shell.execute_reply.started": "2024-01-03T23:25:58.106264Z"
    }
   },
   "outputs": [],
   "source": [
    "sps.save_npz(f\"{run_folder}/URM_train.npz\", urm_train)\n",
    "sps.save_npz(f\"{run_folder}/URM_val.npz\", urm_val)\n",
    "sps.save_npz(f\"{run_folder}/URM_test.npz\", urm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data (Pre-split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.033042Z",
     "iopub.status.busy": "2024-01-08T13:55:07.031656Z",
     "iopub.status.idle": "2024-01-08T13:55:07.047034Z",
     "shell.execute_reply": "2024-01-08T13:55:07.045325Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.032984Z"
    }
   },
   "outputs": [],
   "source": [
    "run_folder = f\"{BASE_DIR}#{RUN_NUM}\" # Runs/#1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.049478Z",
     "iopub.status.busy": "2024-01-08T13:55:07.049047Z",
     "iopub.status.idle": "2024-01-08T13:55:07.115682Z",
     "shell.execute_reply": "2024-01-08T13:55:07.114294Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.049444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Ignoring 3623 (28.7%) Users that have less than 1 test interactions\n"
     ]
    }
   ],
   "source": [
    "urm_train = sps.load_npz(f\"{run_folder}/URM_train.npz\")\n",
    "urm_val = sps.load_npz(f\"{run_folder}/URM_val.npz\")\n",
    "urm_test = sps.load_npz(f\"{run_folder}/URM_test.npz\")\n",
    "evaluator_test = EvaluatorHoldout(urm_test, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom XGRecommender Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.117766Z",
     "iopub.status.busy": "2024-01-08T13:55:07.117404Z",
     "iopub.status.idle": "2024-01-08T13:55:07.130511Z",
     "shell.execute_reply": "2024-01-08T13:55:07.129271Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.117735Z"
    }
   },
   "outputs": [],
   "source": [
    "class Recommender():\n",
    "    def __init__(self, recommender_name, recommender_class, params_dict):\n",
    "        self.recommender_name = recommender_name\n",
    "        self.recommender_class = recommender_class\n",
    "        self.params_dict = params_dict\n",
    "        self.recommender_instance = None\n",
    "    \n",
    "    def fit(self, URM):\n",
    "        self.recommender_instance = self.recommender_class(URM)\n",
    "        self.recommender_instance.fit(**self.params_dict)\n",
    "        \n",
    "    def load(self, URM, run_dir, metadata=\"\"):\n",
    "        models_path = f\"{run_dir}/Models/\"\n",
    "        file_name = f\"{self.recommender_name}_{metadata}.zip\"\n",
    "        self.recommender_instance = self.recommender_class(URM)\n",
    "        if os.path.exists(models_path+file_name):\n",
    "            self.recommender_instance.load_model(models_path, file_name)\n",
    "        else:\n",
    "            print(f\"Model {file_name} not found at {models_path}, re-training...\")\n",
    "            self.fit(URM)\n",
    "            self.save(run_dir, metadata)\n",
    "        \n",
    "    def save(self, run_dir, metadata):\n",
    "        self.recommender_instance.save_model(f\"{run_dir}/Models/\", f\"{self.recommender_name}_{metadata}.zip\")\n",
    "        \n",
    "    def __copy__(self):\n",
    "        self.normalizeArgs()\n",
    "        return Recommender(self.recommender_name, self.recommender_class, self.params_dict)\n",
    "    \n",
    "    def normalizeArgs(self):\n",
    "        if not hasattr(self, \"recommender_name\"):\n",
    "            self.recommender_name = \"Unknown\"\n",
    "        if not hasattr(self, \"recommender_class\"):\n",
    "            raise ValueError(\"Recommender has no attribute recommender_class. Aborting copy operation.\")\n",
    "        if not hasattr(self, \"params_dict\"):\n",
    "            raise ValueError(\"Recommender has no attribute params_dict. Aborting copy operation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.132856Z",
     "iopub.status.busy": "2024-01-08T13:55:07.132454Z",
     "iopub.status.idle": "2024-01-08T13:55:07.169809Z",
     "shell.execute_reply": "2024-01-08T13:55:07.168156Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.132810Z"
    }
   },
   "outputs": [],
   "source": [
    "class XGRecommender(BaseRecommender):\n",
    "    global run_folder\n",
    "    \"\"\" XGRecommender\n",
    "    Gradient boosting recommender\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"XGRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, URM_val, recommenders, load_models=False):\n",
    "        super(XGRecommender, self).__init__(URM_train)\n",
    "        self.URM_train = sps.csr_matrix(URM_train)\n",
    "        self.URM_val = sps.csr_matrix(URM_val)\n",
    "        self.recommenders = recommenders\n",
    "        self.recommenders_train = []\n",
    "        self.recommenders_val = []\n",
    "        if load_models:\n",
    "            for rid in tqdm(range(len(recommenders))):\n",
    "                recommender_train = recommenders[rid]\n",
    "                recommender_val = recommender_train.__copy__()\n",
    "\n",
    "                recommender_train.load(self.URM_train, run_folder, \"train\")\n",
    "                self.recommenders_train.append(recommender_train)\n",
    "\n",
    "                recommender_val.load(self.URM_train, run_folder, \"val\")\n",
    "                self.recommenders_val.append(recommender_val)\n",
    "        else:\n",
    "            for rid in tqdm(range(len(recommenders))):\n",
    "                recommender_train = recommenders[rid]\n",
    "                recommender_val = recommender_train.__copy__()\n",
    "\n",
    "                recommender_train.fit(self.URM_train)\n",
    "                recommender_train.save(run_folder, \"train\")\n",
    "                self.recommenders_train.append(recommender_train)\n",
    "\n",
    "                recommender_val.fit(self.URM_train + self.URM_val)\n",
    "                recommender_val.save(run_folder, \"val\")\n",
    "                self.recommenders_val.append(recommender_val)\n",
    "            \n",
    "    def recommender_lookup(self, name, collection):\n",
    "        result = None\n",
    "        for recommender in collection:\n",
    "            if recommender.recommender_name.lower() == name:\n",
    "                result = recommender\n",
    "                break\n",
    "        if result == None:\n",
    "            print(f\"No recommender {name} found\")\n",
    "        return result\n",
    "            \n",
    "    def get_recommender_train(self, name):\n",
    "        return self.recommender_lookup(name, self.recommenders_train)\n",
    "    \n",
    "    def get_recommender_train_val(self, name):\n",
    "        return self.recommender_lookup(name, self.recommenders_val)\n",
    "\n",
    "    def fit(self, training_dataframe,\n",
    "            n_estimators = 50,\n",
    "            learning_rate = 1e-1,\n",
    "            reg_alpha = 1e-1,\n",
    "            reg_lambda = 1e-1,\n",
    "            max_depth = 5,\n",
    "            max_leaves = 0,\n",
    "            grow_policy = \"depthwise\",\n",
    "            objective = \"pairwise\",\n",
    "            booster = \"gbtree\",\n",
    "            use_user_profile = False,\n",
    "            random_seed = None,\n",
    "            tree_method = \"hist\",  # Supported tree methods are `gpu_hist`, `approx`, and `hist`.\n",
    "            colsample_bytree = 1,\n",
    "            gamma = 0,\n",
    "            min_child_weight = 0\n",
    "           ):\n",
    "        training_dataframe = training_dataframe.set_index('UserID')\n",
    "\n",
    "        for user_id in tqdm(range(self.n_users)):  \n",
    "            for recommender in self.recommenders_train:\n",
    "                rec_instance = recommender.recommender_instance\n",
    "                rec_label = recommender.recommender_name\n",
    "\n",
    "                item_list = training_dataframe.loc[user_id, \"ItemID\"].values.tolist()\n",
    "\n",
    "                all_item_scores = rec_instance._compute_item_score([user_id], items_to_compute = item_list)\n",
    "\n",
    "                training_dataframe.loc[user_id, rec_label] = all_item_scores[0, item_list] \n",
    "\n",
    "        training_dataframe = training_dataframe.reset_index()\n",
    "        training_dataframe = training_dataframe.rename(columns = {\"index\": \"UserID\"})\n",
    "        \n",
    "        self.XGB_model = XGBRanker(objective='rank:{}'.format(objective),\n",
    "                          n_estimators = int(n_estimators),\n",
    "                          random_state = random_seed,\n",
    "                          learning_rate = learning_rate,\n",
    "                          reg_alpha = reg_alpha,\n",
    "                          reg_lambda = reg_lambda,\n",
    "                          max_depth = int(max_depth),\n",
    "                          max_leaves = int(max_leaves),\n",
    "                          grow_policy = grow_policy,\n",
    "                          verbosity = 0, # 2 if self.verbose else 0,\n",
    "                          booster = booster,\n",
    "                          enable_categorical = True,\n",
    "                          tree_method = tree_method,  # Supported tree methods are `gpu_hist`, `approx`, and `hist`.\n",
    "                          colsample_bytree = colsample_bytree,\n",
    "                          gamma = gamma,\n",
    "                          min_child_weight = min_child_weight\n",
    "                      )\n",
    "        groups = training_dataframe.groupby(\"UserID\").size().values\n",
    "        \n",
    "        y_train = training_dataframe[\"Label\"]\n",
    "        X_train = training_dataframe.drop(columns=[\"Label\"])\n",
    "\n",
    "        #in order to prevent the algorithm to split user groups according to whether their ID is of a certain value\n",
    "        X_train[\"UserID\"] = X_train[\"UserID\"].astype(\"category\")\n",
    "        X_train[\"ItemID\"] = X_train[\"ItemID\"].astype(\"category\")\n",
    "        \n",
    "        print(\"Training...\")\n",
    "        self.XGB_model.fit(\n",
    "          X_train,\n",
    "          y_train,\n",
    "          group=groups,\n",
    "          verbose=True)\n",
    "        \n",
    "        #xgb.plot_importance(self.XGB_model, importance_type='weight', title='Weight (Frequence)')\n",
    "        \n",
    "    def prepare_validation_dataframe(self, base_validation_dataframe):\n",
    "        print(\"Setting-up val_df...\")\n",
    "        self.validation_dataframe = base_validation_dataframe\n",
    "        validation_dataframe_tmp = self.validation_dataframe.set_index('UserID')\n",
    "\n",
    "        for user_id in tqdm(range(self.n_users)):  \n",
    "            for recommender in self.recommenders_val:\n",
    "                rec_instance = recommender.recommender_instance\n",
    "                rec_label = recommender.recommender_name\n",
    "\n",
    "                item_list = validation_dataframe_tmp.loc[user_id, \"ItemID\"].values.tolist()\n",
    "\n",
    "                all_item_scores = rec_instance._compute_item_score([user_id], items_to_compute = item_list)\n",
    "\n",
    "                validation_dataframe_tmp.loc[user_id, rec_label] = all_item_scores[0, item_list] \n",
    "\n",
    "        validation_dataframe_tmp = validation_dataframe_tmp.reset_index()\n",
    "        self.validation_dataframe = validation_dataframe_tmp.rename(columns = {\"index\": \"UserID\"})\n",
    "        self.prepare_rankings()\n",
    "        \n",
    "    def prepare_rankings(self):\n",
    "        print(\"Predicting...\")\n",
    "        predictions = self.XGB_model.predict(self.validation_dataframe)\n",
    "        self.validation_dataframe['rating_xgb'] = pd.Series(predictions, index=self.validation_dataframe.index)\n",
    "        self.validation_dataframe = self.validation_dataframe.sort_values(['UserID','rating_xgb'], ascending=[True, False])\n",
    "        print(\"Evaluating...\")\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute):\n",
    "        item_scores = - np.ones((len(user_id_array), self.n_items)) * np.inf\n",
    "        for user_index, user_id in enumerate(user_id_array):\n",
    "            item_scores[user_index, self.validation_dataframe.loc[self.validation_dataframe['UserID'] == user_id].ItemID] = self.validation_dataframe.loc[self.validation_dataframe['UserID'] == user_id].rating_xgb.values\n",
    "        return item_scores\n",
    "    \n",
    "    def show_importance(self):\n",
    "        print(\"Importance: \")\n",
    "        plot_importance(self.XGB_model, importance_type='weight', title='Weight (Frequence)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Custom Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.175060Z",
     "iopub.status.busy": "2024-01-08T13:55:07.174480Z",
     "iopub.status.idle": "2024-01-08T13:55:07.195354Z",
     "shell.execute_reply": "2024-01-08T13:55:07.193779Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.175017Z"
    }
   },
   "outputs": [],
   "source": [
    "class FastIALSRecommender(BaseMatrixFactorizationRecommender):\n",
    "    RECOMMENDER_NAME = \"FastIALSRecommender\"\n",
    "\n",
    "    AVAILABLE_CONFIDENCE_SCALING = [\"linear\", \"log\"]\n",
    "    \n",
    "    def __init__(self, URM_train, verbose=True):\n",
    "        super().__init__(URM_train, verbose=verbose)\n",
    "        \n",
    "    def fit(self,\n",
    "            factors=20,\n",
    "            regularization=1e-3,\n",
    "            iterations=100,\n",
    "            calculate_training_loss=False,\n",
    "            num_threads=0,\n",
    "            confidence_scaling='linear',\n",
    "            alpha=1.0,\n",
    "            epsilon=0,\n",
    "            #---- Do not change\n",
    "            use_native=True,\n",
    "            use_cg=True,\n",
    "            use_gpu=True):\n",
    "        if confidence_scaling not in self.AVAILABLE_CONFIDENCE_SCALING:\n",
    "           raise ValueError(\"Value for 'confidence_scaling' not recognized. Acceptable values are {}, provided was '{}'\".format(self.AVAILABLE_CONFIDENCE_SCALING, confidence_scaling))\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.num_factors = factors\n",
    "        self.reg = regularization\n",
    "        \n",
    "        self.USER_factors = self._init_factors(self.n_users, False)  # don't need values, will compute them\n",
    "        self.ITEM_factors = self._init_factors(self.n_items)\n",
    "        \n",
    "        self.recommender = AlternatingLeastSquares(factors=factors, regularization=regularization,\n",
    "                                                        use_native=use_native, use_cg=use_cg, use_gpu=use_gpu,\n",
    "                                                        iterations=iterations,\n",
    "                                                        calculate_training_loss=calculate_training_loss,\n",
    "                                                        num_threads=num_threads)\n",
    "        \n",
    "        self._build_confidence_matrix(confidence_scaling)\n",
    "        self.recommender.fit(self.C, show_progress=self.verbose)\n",
    "        \n",
    "        self.USER_factors = self.recommender.user_factors.to_numpy()\n",
    "        self.ITEM_factors = self.recommender.item_factors.to_numpy()\n",
    "        \n",
    "    \n",
    "    def _linear_scaling_confidence(self):\n",
    "\n",
    "        C = check_matrix(self.URM_train, format=\"csr\", dtype = np.float32)\n",
    "        C.data = 1.0 + self.alpha*C.data\n",
    "\n",
    "        return C\n",
    "\n",
    "    def _log_scaling_confidence(self):\n",
    "\n",
    "        C = check_matrix(self.URM_train, format=\"csr\", dtype = np.float32)\n",
    "        C.data = 1.0 + self.alpha * np.log(1.0 + C.data / self.epsilon)\n",
    "\n",
    "        return C\n",
    "    \n",
    "    def _build_confidence_matrix(self, confidence_scaling):\n",
    "\n",
    "        if confidence_scaling == 'linear':\n",
    "            self.C = self._linear_scaling_confidence()\n",
    "        else:\n",
    "            self.C = self._log_scaling_confidence()\n",
    "\n",
    "        self.C_csc= check_matrix(self.C.copy(), format=\"csc\", dtype = np.float32)\n",
    "        \n",
    "    def carrefour(self, numpy_array):\n",
    "        rows, cols = numpy_array.nonzero()\n",
    "        data_values = numpy_array[rows, cols]\n",
    "        return sps.coo_matrix((data_values, (rows, cols)), shape=numpy_array.shape).tocsr()\n",
    "    \n",
    "    def _init_factors(self, num_factors, assign_values=True):\n",
    "\n",
    "        if assign_values:\n",
    "            return self.num_factors**-0.5*np.random.random_sample((num_factors, self.num_factors))\n",
    "\n",
    "        else:\n",
    "            return np.empty((num_factors, self.num_factors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.198320Z",
     "iopub.status.busy": "2024-01-08T13:55:07.197725Z",
     "iopub.status.idle": "2024-01-08T13:55:07.219126Z",
     "shell.execute_reply": "2024-01-08T13:55:07.217917Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.198268Z"
    }
   },
   "outputs": [],
   "source": [
    "class LightFMCFRecommender(BaseRecommender):\n",
    "    \"\"\"LightFMCFRecommender\"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"LightFMCFRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train):\n",
    "        super(LightFMCFRecommender, self).__init__(URM_train)\n",
    "    \n",
    "    \n",
    "    def fit(self, epochs = 200, user_alpha=1e-6, item_alpha = 1e-6, n_factors = 10, n_threads = 4, max_sampled=3, loss='warp', learning_schedule='adagrad'):\n",
    "        \n",
    "        # Let's fit a WARP model\n",
    "        self.lightFM_model = LightFM(loss=loss,\n",
    "                                     user_alpha=user_alpha,\n",
    "                                     item_alpha=item_alpha,\n",
    "                                     no_components=n_factors,\n",
    "                                     max_sampled=max_sampled,\n",
    "                                     learning_schedule=learning_schedule)\n",
    "\n",
    "        self.lightFM_model = self.lightFM_model.fit(self.URM_train, \n",
    "                                       epochs=epochs,\n",
    "                                       num_threads=n_threads,\n",
    "                                       verbose=True)\n",
    "\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute = None):\n",
    "        \n",
    "        # Create a single (n_items, ) array with the item score, then copy it for every user\n",
    "        items_to_compute = np.arange(self.n_items)\n",
    "        \n",
    "        item_scores = - np.ones((len(user_id_array), self.n_items)) * np.inf\n",
    "\n",
    "        for user_index, user_id in enumerate(user_id_array):\n",
    "            item_scores[user_index] = self.lightFM_model.predict(int(user_id), \n",
    "                                                                 items_to_compute)\n",
    "\n",
    "        return item_scores\n",
    "    \n",
    "    def save_model(self, folder_path, file_name = None):\n",
    "\n",
    "        if file_name is None:\n",
    "            file_name = self.RECOMMENDER_NAME\n",
    "\n",
    "        self._print(\"Saving model in file '{}'\".format(folder_path + file_name))\n",
    "\n",
    "        data_dict_to_save = {\n",
    "                            \"item_embeddings\": self.lightFM_model.item_embeddings,\n",
    "                            \"item_embedding_gradients\": self.lightFM_model.item_embedding_gradients,\n",
    "                            \"item_embedding_momentum\": self.lightFM_model.item_embedding_momentum,\n",
    "                            \"item_biases\": self.lightFM_model.item_biases,\n",
    "                            \"item_bias_gradients\": self.lightFM_model.item_bias_gradients,\n",
    "                            \"item_bias_momentum\": self.lightFM_model.item_bias_momentum,\n",
    "                            \"user_embeddings\": self.lightFM_model.user_embeddings,\n",
    "                            \"user_embedding_gradients\": self.lightFM_model.user_embedding_gradients,\n",
    "                            \"user_embedding_momentum\": self.lightFM_model.user_embedding_momentum,\n",
    "                            \"user_biases\": self.lightFM_model.user_biases,\n",
    "                            \"user_bias_gradients\": self.lightFM_model.user_bias_gradients,\n",
    "                            \"user_bias_momentum\": self.lightFM_model.user_bias_momentum,\n",
    "                            }\n",
    "\n",
    "\n",
    "        dataIO = DataIO(folder_path=folder_path)\n",
    "        dataIO.save_data(file_name=file_name, data_dict_to_save = data_dict_to_save)\n",
    "\n",
    "        self._print(\"Saving complete\")\n",
    "        \n",
    "        \n",
    "    def load_model(self, folder_path, file_name = None):\n",
    "\n",
    "        if file_name is None:\n",
    "            file_name = self.RECOMMENDER_NAME\n",
    "\n",
    "        self._print(\"Loading model from file '{}'\".format(folder_path + file_name))\n",
    "\n",
    "        dataIO = DataIO(folder_path=folder_path)\n",
    "        data_dict = dataIO.load_data(file_name=file_name)\n",
    "\n",
    "        self.lightFM_model = LightFM()\n",
    "\n",
    "        for attrib_name in data_dict.keys():\n",
    "             self.lightFM_model.__setattr__(attrib_name, data_dict[attrib_name])\n",
    "\n",
    "        self._print(\"Loading complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Model params (MAP-Optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.221812Z",
     "iopub.status.busy": "2024-01-08T13:55:07.221202Z",
     "iopub.status.idle": "2024-01-08T13:55:07.236112Z",
     "shell.execute_reply": "2024-01-08T13:55:07.234551Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.221768Z"
    }
   },
   "outputs": [],
   "source": [
    "SLIM_params = {\n",
    " 'l1_ratio': 0.04324773367371399,\n",
    " 'alpha': 0.001220701931267383,\n",
    " 'topK': 971\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.239381Z",
     "iopub.status.busy": "2024-01-08T13:55:07.238594Z",
     "iopub.status.idle": "2024-01-08T13:55:07.246906Z",
     "shell.execute_reply": "2024-01-08T13:55:07.245927Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.239325Z"
    }
   },
   "outputs": [],
   "source": [
    "RP3Beta_params = {\n",
    " 'alpha': 0.3302958327908062,\n",
    " 'beta': 0.14271386569051958,\n",
    " 'topK': 29,\n",
    " 'normalize_similarity': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.248938Z",
     "iopub.status.busy": "2024-01-08T13:55:07.248281Z",
     "iopub.status.idle": "2024-01-08T13:55:07.259164Z",
     "shell.execute_reply": "2024-01-08T13:55:07.257849Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.248905Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha_slim_rp3beta = 0.5356582511094522"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model params (RECALL-Optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.261602Z",
     "iopub.status.busy": "2024-01-08T13:55:07.261205Z",
     "iopub.status.idle": "2024-01-08T13:55:07.270133Z",
     "shell.execute_reply": "2024-01-08T13:55:07.269158Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.261571Z"
    }
   },
   "outputs": [],
   "source": [
    "ItemKNN_params = {\n",
    "    'topK': 90,\n",
    "    'shrink': 1168,\n",
    "    'similarity': 'jaccard',\n",
    "    'normalize': False,\n",
    "    'feature_weighting': 'BM25'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.272355Z",
     "iopub.status.busy": "2024-01-08T13:55:07.271414Z",
     "iopub.status.idle": "2024-01-08T13:55:07.288138Z",
     "shell.execute_reply": "2024-01-08T13:55:07.285440Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.272323Z"
    }
   },
   "outputs": [],
   "source": [
    "UserKNN_params = {\n",
    "    'topK': 331,\n",
    "    'shrink': 315,\n",
    "    'similarity': 'cosine',\n",
    "    'normalize': True,\n",
    "    'feature_weighting': 'TF-IDF'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.290375Z",
     "iopub.status.busy": "2024-01-08T13:55:07.289953Z",
     "iopub.status.idle": "2024-01-08T13:55:07.300885Z",
     "shell.execute_reply": "2024-01-08T13:55:07.299515Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.290331Z"
    }
   },
   "outputs": [],
   "source": [
    "IALS_params = {\n",
    "    'confidence_scaling': 'log',\n",
    "    'epsilon': 0.0028130992083797435,\n",
    "    'factors': 302,\n",
    "    'regularization': 0.009832686029765005,\n",
    "    'alpha': 1.7031521523379438\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.303307Z",
     "iopub.status.busy": "2024-01-08T13:55:07.302656Z",
     "iopub.status.idle": "2024-01-08T13:55:07.313362Z",
     "shell.execute_reply": "2024-01-08T13:55:07.312338Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.303117Z"
    }
   },
   "outputs": [],
   "source": [
    "RP3Beta_params_rec = {\n",
    "    'alpha': 0.3535736692428584,\n",
    "    'beta': 0.23632895406841348,\n",
    "    'topK': 60,\n",
    "    'normalize_similarity': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.315110Z",
     "iopub.status.busy": "2024-01-08T13:55:07.314709Z",
     "iopub.status.idle": "2024-01-08T13:55:07.326438Z",
     "shell.execute_reply": "2024-01-08T13:55:07.325296Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.315077Z"
    }
   },
   "outputs": [],
   "source": [
    "SLIM_params_rec = {\n",
    "    'l1_ratio': 0.01998720297988901,\n",
    "    'alpha': 0.0032805805487669745,\n",
    "    'topK': 698\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.328245Z",
     "iopub.status.busy": "2024-01-08T13:55:07.327873Z",
     "iopub.status.idle": "2024-01-08T13:55:07.338142Z",
     "shell.execute_reply": "2024-01-08T13:55:07.336860Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.328215Z"
    }
   },
   "outputs": [],
   "source": [
    "LightFM_params = {\n",
    "                  'n_factors': 482,\n",
    "                  'max_sampled': 5,\n",
    "                  'user_alpha': 0.00023989649900734266,\n",
    "                  'item_alpha': 9.740651135253414e-05\n",
    "                 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Custom XGBoost Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.340798Z",
     "iopub.status.busy": "2024-01-08T13:55:07.339767Z",
     "iopub.status.idle": "2024-01-08T13:55:07.350954Z",
     "shell.execute_reply": "2024-01-08T13:55:07.349914Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.340761Z"
    }
   },
   "outputs": [],
   "source": [
    "cutoff = 30\n",
    "top_pop_cutoff = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.353094Z",
     "iopub.status.busy": "2024-01-08T13:55:07.352349Z",
     "iopub.status.idle": "2024-01-08T13:55:07.367583Z",
     "shell.execute_reply": "2024-01-08T13:55:07.366308Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.353060Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_train_dataframe(rec, urm_train, urm_val, top_pop=None):\n",
    "    global cutoff\n",
    "    n_users, n_items = urm_train.shape\n",
    "\n",
    "    # Initialize lists to store the data\n",
    "    user_ids = []\n",
    "    item_ids = []\n",
    "    top_pop_flags = []\n",
    "    \n",
    "    for user_id in tqdm(range(n_users)):    \n",
    "        # Get recommendations from the main recommender\n",
    "        recommendations = rec.recommend(user_id, cutoff=cutoff)\n",
    "        user_ids.extend([user_id] * len(recommendations))\n",
    "        item_ids.extend(recommendations)\n",
    "        top_pop_flags.extend([False] * len(recommendations))  # False for main recommender\n",
    "        \n",
    "        if top_pop is not None:\n",
    "            # Get top-pop recommendations\n",
    "            top_pop_recommendations = top_pop.recommend(user_id, cutoff=cutoff)\n",
    "            user_ids.extend([user_id] * len(top_pop_recommendations))\n",
    "            item_ids.extend(top_pop_recommendations)\n",
    "            top_pop_flags.extend([True] * len(top_pop_recommendations))  # True for top-pop recommendations\n",
    "    \n",
    "    # Create the training dataframe from the lists\n",
    "    training_dataframe = pd.DataFrame({\n",
    "        'UserID': user_ids,\n",
    "        'ItemID': item_ids,\n",
    "        'TopPop': top_pop_flags\n",
    "    })\n",
    "    \n",
    "    urm_validation_coo = sps.coo_matrix(urm_val)\n",
    "    correct_recommendations = pd.DataFrame({\n",
    "        \"UserID\": urm_validation_coo.row, \n",
    "        \"ItemID\": urm_validation_coo.col\n",
    "    })\n",
    "    # Merge to find out which recommendations are correct\n",
    "    training_dataframe = pd.merge(training_dataframe, correct_recommendations, \n",
    "                                  on=['UserID', 'ItemID'], \n",
    "                                  how='left', indicator='Exist')\n",
    "    # Create the label column\n",
    "    training_dataframe[\"Label\"] = training_dataframe[\"Exist\"] == \"both\"\n",
    "    training_dataframe.drop(columns=['Exist'], inplace=True)\n",
    "    \n",
    "    #adding item popularity to the df\n",
    "    item_popularity = np.ediff1d(sps.csc_matrix(urm_train).indptr)\n",
    "    training_dataframe['item_popularity'] = item_popularity[training_dataframe[\"ItemID\"].values.astype(int)]\n",
    "\n",
    "    #adding user profile length to the df\n",
    "    user_popularity = np.ediff1d(sps.csr_matrix(urm_train).indptr)\n",
    "    training_dataframe['user_profile_len'] = user_popularity[training_dataframe[\"UserID\"].values.astype(int)]\n",
    "    \n",
    "    return training_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.370434Z",
     "iopub.status.busy": "2024-01-08T13:55:07.369050Z",
     "iopub.status.idle": "2024-01-08T13:55:07.386280Z",
     "shell.execute_reply": "2024-01-08T13:55:07.384908Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.370383Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_val_dataframe(rec, urm, top_pop=None):\n",
    "    global cutoff\n",
    "    # Initialize lists to store the data\n",
    "    user_ids = []\n",
    "    item_ids = []\n",
    "    top_pop_flags = []\n",
    "\n",
    "    for user_id in tqdm(range(urm.shape[0])):    \n",
    "        # Get recommendations from the main recommender\n",
    "        recommendations = rec.recommend(user_id, cutoff=cutoff)\n",
    "        user_ids.extend([user_id] * len(recommendations))\n",
    "        item_ids.extend(recommendations)\n",
    "        top_pop_flags.extend([False] * len(recommendations))  # False for main recommender\n",
    "        \n",
    "        if top_pop is not None:\n",
    "            # Get top-pop recommendations\n",
    "            top_pop_recommendations = top_pop.recommend(user_id, cutoff=cutoff)\n",
    "            user_ids.extend([user_id] * len(top_pop_recommendations))\n",
    "            item_ids.extend(top_pop_recommendations)\n",
    "            top_pop_flags.extend([True] * len(top_pop_recommendations))  # True for top-pop recommendations\n",
    "    \n",
    "    # Create the validation dataframe from the lists\n",
    "    val_dataframe = pd.DataFrame({\n",
    "        'UserID': user_ids,\n",
    "        'ItemID': item_ids,\n",
    "        'TopPop': top_pop_flags\n",
    "    })\n",
    "    \n",
    "    #adding item popularity to the df\n",
    "    item_popularity = np.ediff1d(sps.csc_matrix(urm).indptr)\n",
    "    val_dataframe['item_popularity'] = item_popularity[training_dataframe[\"ItemID\"].values.astype(int)]\n",
    "\n",
    "    #adding user profile length to the df\n",
    "    user_popularity = np.ediff1d(sps.csr_matrix(urm).indptr)\n",
    "    val_dataframe['user_profile_len'] = user_popularity[training_dataframe[\"UserID\"].values.astype(int)]\n",
    "    \n",
    "    return val_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building main model (SLIM+RP3Beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.388570Z",
     "iopub.status.busy": "2024-01-08T13:55:07.387952Z",
     "iopub.status.idle": "2024-01-08T13:55:07.404405Z",
     "shell.execute_reply": "2024-01-08T13:55:07.402954Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.388536Z"
    }
   },
   "outputs": [],
   "source": [
    "base_model = \"SLIM_RP3Beta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.406934Z",
     "iopub.status.busy": "2024-01-08T13:55:07.406491Z",
     "iopub.status.idle": "2024-01-08T13:55:07.416495Z",
     "shell.execute_reply": "2024-01-08T13:55:07.415352Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.406895Z"
    }
   },
   "outputs": [],
   "source": [
    "base_model_train_path = f\"{run_folder}/Models/\"\n",
    "base_model_filename = f\"base_{base_model}_train.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:07.419086Z",
     "iopub.status.busy": "2024-01-08T13:55:07.418364Z",
     "iopub.status.idle": "2024-01-08T13:55:08.178802Z",
     "shell.execute_reply": "2024-01-08T13:55:08.177559Z",
     "shell.execute_reply.started": "2024-01-08T13:55:07.419050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ItemKNNCustomSimilarityRecommender: URM Detected 408 ( 3.2%) users with no interactions.\n",
      "ItemKNNCustomSimilarityRecommender: URM Detected 230 ( 1.0%) items with no interactions.\n",
      "ItemKNNCustomSimilarityRecommender: Loading model from file 'Runs/#4/Models/base_SLIM_RP3Beta_train.zip'\n",
      "ItemKNNCustomSimilarityRecommender: Loading complete\n"
     ]
    }
   ],
   "source": [
    "slim_rp3beta = ItemKNNCustomSimilarityRecommender(urm_train)\n",
    "slim_rp3beta.load_model(base_model_train_path, base_model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T10:07:00.654568Z",
     "iopub.status.busy": "2024-01-08T10:07:00.654041Z",
     "iopub.status.idle": "2024-01-08T10:07:07.053768Z",
     "shell.execute_reply": "2024-01-08T10:07:07.052844Z",
     "shell.execute_reply.started": "2024-01-08T10:07:00.654523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RP3betaRecommender: URM Detected 408 ( 3.2%) users with no interactions.\n",
      "RP3betaRecommender: URM Detected 230 ( 1.0%) items with no interactions.\n",
      "RP3betaRecommender: Similarity column 22222 (100.0%), 3960.48 column/sec. Elapsed time 5.61 sec\n"
     ]
    }
   ],
   "source": [
    "rp3beta = RP3betaRecommender(urm_train)\n",
    "rp3beta.fit(**RP3Beta_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T10:07:07.055387Z",
     "iopub.status.busy": "2024-01-08T10:07:07.054958Z",
     "iopub.status.idle": "2024-01-08T10:22:21.788920Z",
     "shell.execute_reply": "2024-01-08T10:22:21.787993Z",
     "shell.execute_reply.started": "2024-01-08T10:07:07.055364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 408 ( 3.2%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 230 ( 1.0%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [15:14<00:00, 24.29it/s]\n"
     ]
    }
   ],
   "source": [
    "slim = MultiThreadSLIM_SLIMElasticNetRecommender(urm_train)\n",
    "slim.fit(**SLIM_params, workers = int(cpu_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T10:22:21.790680Z",
     "iopub.status.busy": "2024-01-08T10:22:21.790409Z",
     "iopub.status.idle": "2024-01-08T10:22:21.838694Z",
     "shell.execute_reply": "2024-01-08T10:22:21.837854Z",
     "shell.execute_reply.started": "2024-01-08T10:22:21.790656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ItemKNNCustomSimilarityRecommender: URM Detected 408 ( 3.2%) users with no interactions.\n",
      "ItemKNNCustomSimilarityRecommender: URM Detected 230 ( 1.0%) items with no interactions.\n"
     ]
    }
   ],
   "source": [
    "new_similarity = (1 - alpha_slim_rp3beta) * slim.W_sparse + alpha_slim_rp3beta * rp3beta.W_sparse\n",
    "    \n",
    "slim_rp3beta = ItemKNNCustomSimilarityRecommender(urm_train)\n",
    "slim_rp3beta.fit(new_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building other models for construction of DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:08.181686Z",
     "iopub.status.busy": "2024-01-08T13:55:08.180940Z",
     "iopub.status.idle": "2024-01-08T13:55:08.212109Z",
     "shell.execute_reply": "2024-01-08T13:55:08.210600Z",
     "shell.execute_reply.started": "2024-01-08T13:55:08.181640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TopPopRecommender: URM Detected 408 ( 3.2%) users with no interactions.\n",
      "TopPopRecommender: URM Detected 230 ( 1.0%) items with no interactions.\n"
     ]
    }
   ],
   "source": [
    "top_pop = TopPop(urm_train)\n",
    "top_pop.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:08.220243Z",
     "iopub.status.busy": "2024-01-08T13:55:08.219768Z",
     "iopub.status.idle": "2024-01-08T13:55:25.960637Z",
     "shell.execute_reply": "2024-01-08T13:55:25.959340Z",
     "shell.execute_reply.started": "2024-01-08T13:55:08.220209Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12638/12638 [00:16<00:00, 772.98it/s]\n"
     ]
    }
   ],
   "source": [
    "training_dataframe = build_train_dataframe(slim_rp3beta, urm_train, urm_val, top_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:25.963384Z",
     "iopub.status.busy": "2024-01-08T13:55:25.962816Z",
     "iopub.status.idle": "2024-01-08T13:55:25.971417Z",
     "shell.execute_reply": "2024-01-08T13:55:25.970109Z",
     "shell.execute_reply.started": "2024-01-08T13:55:25.963336Z"
    }
   },
   "outputs": [],
   "source": [
    "itemKNN_rec = Recommender('ItemKNN', ItemKNNCFRecommender, ItemKNN_params)\n",
    "userKNN_rec = Recommender('UserKNN', UserKNNCFRecommender, UserKNN_params)\n",
    "rp3beta_rec = Recommender('RP3Beta', RP3betaRecommender, RP3Beta_params_rec)\n",
    "slim_rec = Recommender(\"SLIM\", MultiThreadSLIM_SLIMElasticNetRecommender, SLIM_params_rec)\n",
    "IALS = Recommender('IALS', FastIALSRecommender, IALS_params)\n",
    "lightFM = Recommender('lightFM', LightFMCFRecommender, LightFM_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:25.973356Z",
     "iopub.status.busy": "2024-01-08T13:55:25.972954Z",
     "iopub.status.idle": "2024-01-08T13:55:25.990585Z",
     "shell.execute_reply": "2024-01-08T13:55:25.989202Z",
     "shell.execute_reply.started": "2024-01-08T13:55:25.973322Z"
    }
   },
   "outputs": [],
   "source": [
    "recommenders = [itemKNN_rec, userKNN_rec, rp3beta_rec, slim_rec, IALS, lightFM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:25.993084Z",
     "iopub.status.busy": "2024-01-08T13:55:25.992475Z",
     "iopub.status.idle": "2024-01-08T13:55:36.293000Z",
     "shell.execute_reply": "2024-01-08T13:55:36.291760Z",
     "shell.execute_reply.started": "2024-01-08T13:55:25.993012Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGRecommender: URM Detected 408 ( 3.2%) users with no interactions.\n",
      "XGRecommender: URM Detected 230 ( 1.0%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ItemKNNCFRecommender: URM Detected 408 ( 3.2%) users with no interactions.\n",
      "ItemKNNCFRecommender: URM Detected 230 ( 1.0%) items with no interactions.\n",
      "ItemKNNCFRecommender: Loading model from file 'Runs/#4/Models/ItemKNN_train.zip'\n",
      "ItemKNNCFRecommender: Loading complete\n",
      "ItemKNNCFRecommender: URM Detected 408 ( 3.2%) users with no interactions.\n",
      "ItemKNNCFRecommender: URM Detected 230 ( 1.0%) items with no interactions.\n",
      "ItemKNNCFRecommender: Loading model from file 'Runs/#4/Models/ItemKNN_val.zip'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:02,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ItemKNNCFRecommender: Loading complete\n",
      "UserKNNCFRecommender: URM Detected 408 ( 3.2%) users with no interactions.\n",
      "UserKNNCFRecommender: URM Detected 230 ( 1.0%) items with no interactions.\n",
      "UserKNNCFRecommender: Loading model from file 'Runs/#4/Models/UserKNN_train.zip'\n",
      "UserKNNCFRecommender: Loading complete\n",
      "UserKNNCFRecommender: URM Detected 408 ( 3.2%) users with no interactions.\n",
      "UserKNNCFRecommender: URM Detected 230 ( 1.0%) items with no interactions.\n",
      "UserKNNCFRecommender: Loading model from file 'Runs/#4/Models/UserKNN_val.zip'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:03,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserKNNCFRecommender: Loading complete\n",
      "RP3betaRecommender: URM Detected 408 ( 3.2%) users with no interactions.\n",
      "RP3betaRecommender: URM Detected 230 ( 1.0%) items with no interactions.\n",
      "RP3betaRecommender: Loading model from file 'Runs/#4/Models/RP3Beta_train.zip'\n",
      "RP3betaRecommender: Loading complete\n",
      "RP3betaRecommender: URM Detected 408 ( 3.2%) users with no interactions.\n",
      "RP3betaRecommender: URM Detected 230 ( 1.0%) items with no interactions.\n",
      "RP3betaRecommender: Loading model from file 'Runs/#4/Models/RP3Beta_val.zip'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RP3betaRecommender: Loading complete\n",
      "SLIMElasticNetRecommender: URM Detected 408 ( 3.2%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 230 ( 1.0%) items with no interactions.\n",
      "SLIMElasticNetRecommender: Loading model from file 'Runs/#4/Models/SLIM_train.zip'\n",
      "SLIMElasticNetRecommender: Loading complete\n",
      "SLIMElasticNetRecommender: URM Detected 408 ( 3.2%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 230 ( 1.0%) items with no interactions.\n",
      "SLIMElasticNetRecommender: Loading model from file 'Runs/#4/Models/SLIM_val.zip'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:03<00:01,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: Loading complete\n",
      "FastIALSRecommender: URM Detected 408 ( 3.2%) users with no interactions.\n",
      "FastIALSRecommender: URM Detected 230 ( 1.0%) items with no interactions.\n",
      "FastIALSRecommender: Loading model from file 'Runs/#4/Models/IALS_train.zip'\n",
      "FastIALSRecommender: Loading complete\n",
      "FastIALSRecommender: URM Detected 408 ( 3.2%) users with no interactions.\n",
      "FastIALSRecommender: URM Detected 230 ( 1.0%) items with no interactions.\n",
      "FastIALSRecommender: Loading model from file 'Runs/#4/Models/IALS_val.zip'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:04<00:01,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastIALSRecommender: Loading complete\n",
      "LightFMCFRecommender: URM Detected 408 ( 3.2%) users with no interactions.\n",
      "LightFMCFRecommender: URM Detected 230 ( 1.0%) items with no interactions.\n",
      "LightFMCFRecommender: Loading model from file 'Runs/#4/Models/lightFM_train.zip'\n",
      "LightFMCFRecommender: Loading complete\n",
      "LightFMCFRecommender: URM Detected 408 ( 3.2%) users with no interactions.\n",
      "LightFMCFRecommender: URM Detected 230 ( 1.0%) items with no interactions.\n",
      "LightFMCFRecommender: Loading model from file 'Runs/#4/Models/lightFM_val.zip'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:10<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightFMCFRecommender: Loading complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xg_rec = XGRecommender(urm_train, urm_val, recommenders, LOAD_MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:36.294706Z",
     "iopub.status.busy": "2024-01-08T13:55:36.294324Z",
     "iopub.status.idle": "2024-01-08T13:55:36.300267Z",
     "shell.execute_reply": "2024-01-08T13:55:36.299203Z",
     "shell.execute_reply.started": "2024-01-08T13:55:36.294675Z"
    }
   },
   "outputs": [],
   "source": [
    "base_model_val_path = f\"{run_folder}/Models/\"\n",
    "base_model_val_file = f\"base_{base_model}_val.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:36.302044Z",
     "iopub.status.busy": "2024-01-08T13:55:36.301587Z",
     "iopub.status.idle": "2024-01-08T13:55:37.086680Z",
     "shell.execute_reply": "2024-01-08T13:55:37.085190Z",
     "shell.execute_reply.started": "2024-01-08T13:55:36.302003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ItemKNNCustomSimilarityRecommender: URM Detected 129 ( 1.0%) users with no interactions.\n",
      "ItemKNNCustomSimilarityRecommender: URM Detected 35 ( 0.2%) items with no interactions.\n",
      "ItemKNNCustomSimilarityRecommender: Loading model from file 'Runs/#4/Models/base_SLIM_RP3Beta_val.zip'\n",
      "ItemKNNCustomSimilarityRecommender: Loading complete\n"
     ]
    }
   ],
   "source": [
    "slim_rp3beta_val = ItemKNNCustomSimilarityRecommender(urm_train + urm_val)\n",
    "slim_rp3beta_val.load_model(base_model_val_path, base_model_val_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T10:22:40.145849Z",
     "iopub.status.busy": "2024-01-08T10:22:40.145497Z",
     "iopub.status.idle": "2024-01-08T10:22:47.535549Z",
     "shell.execute_reply": "2024-01-08T10:22:47.534438Z",
     "shell.execute_reply.started": "2024-01-08T10:22:40.145822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RP3betaRecommender: URM Detected 129 ( 1.0%) users with no interactions.\n",
      "RP3betaRecommender: URM Detected 35 ( 0.2%) items with no interactions.\n",
      "RP3betaRecommender: Similarity column 22222 (100.0%), 3349.49 column/sec. Elapsed time 6.63 sec\n"
     ]
    }
   ],
   "source": [
    "rp3beta_val = RP3betaRecommender(urm_train + urm_val)\n",
    "rp3beta_val.fit(**RP3Beta_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T10:22:47.537569Z",
     "iopub.status.busy": "2024-01-08T10:22:47.537207Z",
     "iopub.status.idle": "2024-01-08T10:38:38.584140Z",
     "shell.execute_reply": "2024-01-08T10:38:38.583170Z",
     "shell.execute_reply.started": "2024-01-08T10:22:47.537508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: URM Detected 129 ( 1.0%) users with no interactions.\n",
      "SLIMElasticNetRecommender: URM Detected 35 ( 0.2%) items with no interactions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 22216/22222 [15:50<00:00, 23.36it/s]\n"
     ]
    }
   ],
   "source": [
    "slim_val = MultiThreadSLIM_SLIMElasticNetRecommender(urm_train + urm_val)\n",
    "slim_val.fit(**SLIM_params, workers = int(cpu_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T10:38:38.586335Z",
     "iopub.status.busy": "2024-01-08T10:38:38.585950Z",
     "iopub.status.idle": "2024-01-08T10:38:38.631607Z",
     "shell.execute_reply": "2024-01-08T10:38:38.630605Z",
     "shell.execute_reply.started": "2024-01-08T10:38:38.586302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ItemKNNCustomSimilarityRecommender: URM Detected 129 ( 1.0%) users with no interactions.\n",
      "ItemKNNCustomSimilarityRecommender: URM Detected 35 ( 0.2%) items with no interactions.\n"
     ]
    }
   ],
   "source": [
    "new_similarity = (1 - alpha_slim_rp3beta) * slim.W_sparse + alpha_slim_rp3beta * rp3beta.W_sparse\n",
    "    \n",
    "slim_rp3beta_val = ItemKNNCustomSimilarityRecommender(urm_train + urm_val)\n",
    "slim_rp3beta_val.fit(new_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Validation DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:37.090310Z",
     "iopub.status.busy": "2024-01-08T13:55:37.088923Z",
     "iopub.status.idle": "2024-01-08T13:55:37.130762Z",
     "shell.execute_reply": "2024-01-08T13:55:37.129398Z",
     "shell.execute_reply.started": "2024-01-08T13:55:37.090257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TopPopRecommender: URM Detected 129 ( 1.0%) users with no interactions.\n",
      "TopPopRecommender: URM Detected 35 ( 0.2%) items with no interactions.\n"
     ]
    }
   ],
   "source": [
    "top_pop_val = TopPop(urm_train + urm_val)\n",
    "top_pop_val.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:37.137329Z",
     "iopub.status.busy": "2024-01-08T13:55:37.132532Z",
     "iopub.status.idle": "2024-01-08T13:55:55.526476Z",
     "shell.execute_reply": "2024-01-08T13:55:55.525169Z",
     "shell.execute_reply.started": "2024-01-08T13:55:37.137284Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12638/12638 [00:17<00:00, 723.72it/s]\n"
     ]
    }
   ],
   "source": [
    "val_dataframe = build_val_dataframe(slim_rp3beta_val, urm_val, top_pop_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T10:38:38.634574Z",
     "iopub.status.busy": "2024-01-08T10:38:38.634245Z",
     "iopub.status.idle": "2024-01-08T10:38:38.638211Z",
     "shell.execute_reply": "2024-01-08T10:38:38.637295Z",
     "shell.execute_reply.started": "2024-01-08T10:38:38.634523Z"
    }
   },
   "outputs": [],
   "source": [
    "base_model = \"SLIM_RP3Beta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T10:39:39.608909Z",
     "iopub.status.busy": "2024-01-08T10:39:39.608521Z",
     "iopub.status.idle": "2024-01-08T10:39:39.615186Z",
     "shell.execute_reply": "2024-01-08T10:39:39.614127Z",
     "shell.execute_reply.started": "2024-01-08T10:39:39.608881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Runs/#4/Models'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_folder+\"/Models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T10:39:43.185029Z",
     "iopub.status.busy": "2024-01-08T10:39:43.184688Z",
     "iopub.status.idle": "2024-01-08T10:39:56.311196Z",
     "shell.execute_reply": "2024-01-08T10:39:56.310336Z",
     "shell.execute_reply.started": "2024-01-08T10:39:43.185002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ItemKNNCustomSimilarityRecommender: Saving model in file 'Runs/#4/Models/base_SLIM_RP3Beta_train.zip'\n",
      "ItemKNNCustomSimilarityRecommender: Saving complete\n",
      "ItemKNNCustomSimilarityRecommender: Saving model in file 'Runs/#4/Models/base_SLIM_RP3Beta_val.zip'\n",
      "ItemKNNCustomSimilarityRecommender: Saving complete\n"
     ]
    }
   ],
   "source": [
    "slim_rp3beta.save_model(f\"{run_folder}/Models/\", f\"base_{base_model}_train.zip\")\n",
    "slim_rp3beta_val.save_model(f\"{run_folder}/Models/\", f\"base_{base_model}_val.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T13:55:55.528411Z",
     "iopub.status.busy": "2024-01-08T13:55:55.528012Z",
     "iopub.status.idle": "2024-01-08T13:55:55.535637Z",
     "shell.execute_reply": "2024-01-08T13:55:55.534686Z",
     "shell.execute_reply.started": "2024-01-08T13:55:55.528376Z"
    }
   },
   "outputs": [],
   "source": [
    "class SaveResults(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.results_df = pd.DataFrame(columns=[\"result\"])\n",
    "\n",
    "    def __call__(self, optuna_study, optuna_trial):\n",
    "        hyperparam_dict = optuna_trial.params.copy()\n",
    "        hyperparam_dict[\"result\"] = optuna_trial.values[0]\n",
    "\n",
    "        # Create a DataFrame from the current trial's results\n",
    "        trial_df = pd.DataFrame([hyperparam_dict])\n",
    "\n",
    "        # Use concat instead of append\n",
    "        self.results_df = pd.concat([self.results_df, trial_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T14:01:01.545562Z",
     "iopub.status.busy": "2024-01-08T14:01:01.545059Z",
     "iopub.status.idle": "2024-01-08T14:01:01.557473Z",
     "shell.execute_reply": "2024-01-08T14:01:01.555878Z",
     "shell.execute_reply.started": "2024-01-08T14:01:01.545528Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective_function_xgranker(optuna_trial):\n",
    "    learning_rate = 1e-2\n",
    "    grow_policy = \"depthwise\"\n",
    "    objective = \"pairwise\"\n",
    "    booster = \"gbtree\"\n",
    "    use_user_profile = False\n",
    "    random_seed = None\n",
    "    tree_method = \"hist\"\n",
    "    \n",
    "    n_estimators = optuna_trial.suggest_int(\"n_estimators\", 100, 3500)\n",
    "    max_depth = optuna_trial.suggest_int(\"max_depth\", 2, 10)\n",
    "    max_leaves = optuna_trial.suggest_int(\"max_leaves\", 0, 10)\n",
    "    reg_alpha = optuna_trial.suggest_float(\"reg_alpha\", 1e-1, 300)\n",
    "    reg_lambda = optuna_trial.suggest_float(\"reg_lambda\", 1e-4, 2)\n",
    "    #colsample_bytree = optuna_trial.suggest_float(\"colsample_bytree\", 0.2, 1)\n",
    "    #gamma = optuna_trial.suggest_float(\"gamma\", 0, 10)\n",
    "    min_child_weight = optuna_trial.suggest_float(\"min_child_weight\", 0, 10)\n",
    "    \n",
    "    xg_rec.fit(training_dataframe,\n",
    "                  learning_rate = learning_rate,\n",
    "                  reg_alpha = reg_alpha,\n",
    "                  reg_lambda = reg_lambda,\n",
    "                  grow_policy = grow_policy,\n",
    "                  objective = objective,\n",
    "                  booster = booster,\n",
    "                  use_user_profile = use_user_profile,\n",
    "                  random_seed = random_seed,\n",
    "                  tree_method = tree_method,\n",
    "                  n_estimators = n_estimators,\n",
    "                  max_depth = max_depth,\n",
    "                  max_leaves = max_leaves,\n",
    "                  #colsample_bytree = colsample_bytree,\n",
    "                  #gamma = gamma,\n",
    "                  min_child_weight = min_child_weight\n",
    "              )\n",
    "    xg_rec.prepare_validation_dataframe(val_dataframe)\n",
    "\n",
    "    result_df, _ = evaluator_test.evaluateRecommender(xg_rec)\n",
    "\n",
    "    return result_df.loc[10][\"MAP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T14:01:01.776188Z",
     "iopub.status.busy": "2024-01-08T14:01:01.775685Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 14:01:01,778] A new study created in memory with name: no-name-a4f34ea7-189e-4f6c-8e05-57c6b107502a\n",
      " 45%|████▌     | 5727/12638 [05:44<06:50, 16.84it/s]"
     ]
    }
   ],
   "source": [
    "optuna_study_xgranker = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "save_results_xgranker = SaveResults()\n",
    "\n",
    "optuna_study_xgranker.optimize(objective_function_xgranker,\n",
    "                      callbacks=[save_results_xgranker],\n",
    "                      n_trials = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'n_estimators': 2689, 'max_depth': 4, 'max_leaves': 0, 'reg_alpha': 23.888878705922945, 'reg_lambda': 0.31381253860663455} - value: 0.027594569016366064"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4086250,
     "sourceId": 7091045,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4120115,
     "sourceId": 7139099,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
